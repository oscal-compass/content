{
  "catalog": {
    "uuid": "1cead03a-d26a-400d-b16b-169816e2e592",
    "metadata": {
      "title": "NIST AI Risk Management Framework Generattive AI Profile",
      "last-modified": "2024-10-16T11:17:59+00:00",
      "version": "1.0.0",
      "oscal-version": "1.1.2"
    },
    "groups": [
      {
        "id": "GV",
        "title": "GOVERN",
        "groups": [
          {
            "id": "GV-1.1",
            "title": "Legal and regulatory requirements involving AI are understood, managed, and documented.",
            "controls": [
              {
                "id": "GV-1.1-001",
                "title": "Align GAI use with applicable laws and policies, including those related to data privacy and the use, publication, or distribution of licensed, patented, trademarked, copyrighted, or trade secret material.",
                "parts": [
                  {
                    "id": "GV-1.1-001_smt",
                    "name": "statement",
                    "prose": "Align GAI use with applicable laws and policies, including those related to data privacy and the use, publication, or distribution of licensed, patented, trademarked, copyrighted, or trade secret material."
                  }
                ]
              },
              {
                "id": "GV-1.1-002",
                "title": "Define and communicate organizational access to GAI through management, legal, and compliance functions.",
                "parts": [
                  {
                    "id": "GV-1.1-002_smt",
                    "name": "statement",
                    "prose": "Define and communicate organizational access to GAI through management, legal, and compliance functions."
                  }
                ]
              },
              {
                "id": "GV-1.1-003",
                "title": "Disclose use of GAI to end users.",
                "parts": [
                  {
                    "id": "GV-1.1-003_smt",
                    "name": "statement",
                    "prose": "Disclose use of GAI to end users."
                  }
                ]
              },
              {
                "id": "GV-1.1-004",
                "title": "Establish policies restricting the use of GAI in regulated dealings or applications across the organization where compliance with applicable laws and regulations may be infeasible.",
                "parts": [
                  {
                    "id": "GV-1.1-004_smt",
                    "name": "statement",
                    "prose": "Establish policies restricting the use of GAI in regulated dealings or applications across the organization where compliance with applicable laws and regulations may be infeasible."
                  }
                ]
              },
              {
                "id": "GV-1.1-005",
                "title": "Establish policies restricting the use of GAI to create child sexual abuse materials (CSAM) or other nonconsensual intimate imagery.",
                "parts": [
                  {
                    "id": "GV-1.1-005_smt",
                    "name": "statement",
                    "prose": "Establish policies restricting the use of GAI to create child sexual abuse materials (CSAM) or other nonconsensual intimate imagery."
                  }
                ]
              },
              {
                "id": "GV-1.1-006",
                "title": "Establish transparent acceptable use policies for GAI that address illegal use or applications of GAI.",
                "parts": [
                  {
                    "id": "GV-1.1-006_smt",
                    "name": "statement",
                    "prose": "Establish transparent acceptable use policies for GAI that address illegal use or applications of GAI."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-1.2",
            "title": "The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.",
            "controls": [
              {
                "id": "GV-1.2-001",
                "title": "Connect new GAI policies, procedures, and processes to existing model, data, and IT governance and to legal, compliance, and risk functions.",
                "parts": [
                  {
                    "id": "GV-1.2-001_smt",
                    "name": "statement",
                    "prose": "Connect new GAI policies, procedures, and processes to existing model, data, and IT governance and to legal, compliance, and risk functions."
                  }
                ]
              },
              {
                "id": "GV-1.2-002",
                "title": "Consider factors such as internal vs. external use, narrow vs. broad application scope, fine-tuning and training data sources (i.e., grounding) when defining risk-based controls.",
                "parts": [
                  {
                    "id": "GV-1.2-002_smt",
                    "name": "statement",
                    "prose": "Consider factors such as internal vs. external use, narrow vs. broad application scope, fine-tuning and training data sources (i.e., grounding) when defining risk-based controls."
                  }
                ]
              },
              {
                "id": "GV-1.2-003",
                "title": "Define acceptable use policies for GAI systems deployed by, used by, and used within the organization.",
                "parts": [
                  {
                    "id": "GV-1.2-003_smt",
                    "name": "statement",
                    "prose": "Define acceptable use policies for GAI systems deployed by, used by, and used within the organization."
                  }
                ]
              },
              {
                "id": "GV-1.2-004",
                "title": "Establish and maintain policies for individual and organizational accountability regarding the use of GAI.",
                "parts": [
                  {
                    "id": "GV-1.2-004_smt",
                    "name": "statement",
                    "prose": "Establish and maintain policies for individual and organizational accountability regarding the use of GAI."
                  }
                ]
              },
              {
                "id": "GV-1.2-005",
                "title": "Establish policies and procedures for ensuring that harmful or illegal content, particularly CBRN information, CSAM, known NCII, nudity, and graphic violence, is not included in training data.",
                "parts": [
                  {
                    "id": "GV-1.2-005_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures for ensuring that harmful or illegal content, particularly CBRN information, CSAM, known NCII, nudity, and graphic violence, is not included in training data."
                  }
                ]
              },
              {
                "id": "GV-1.2-006",
                "title": "Establish policies to define mechanisms for measuring the effectiveness of standard content provenance methodologies (e.g., cryptography, watermarking, steganography, etc.) and testing (including reverse engineering).",
                "parts": [
                  {
                    "id": "GV-1.2-006_smt",
                    "name": "statement",
                    "prose": "Establish policies to define mechanisms for measuring the effectiveness of standard content provenance methodologies (e.g., cryptography, watermarking, steganography, etc.) and testing (including reverse engineering)."
                  }
                ]
              },
              {
                "id": "GV-1.2-007",
                "title": "Establish transparency policies and processes for documenting the origin of training data and generated data for GAI applications, including copyrights, licenses, and data privacy, to advance content provenance.",
                "parts": [
                  {
                    "id": "GV-1.2-007_smt",
                    "name": "statement",
                    "prose": "Establish transparency policies and processes for documenting the origin of training data and generated data for GAI applications, including copyrights, licenses, and data privacy, to advance content provenance."
                  }
                ]
              },
              {
                "id": "GV-1.2-008",
                "title": "Update existing policies, procedures, and processes to control risks unique to or exacerbated by GAI.",
                "parts": [
                  {
                    "id": "GV-1.2-008_smt",
                    "name": "statement",
                    "prose": "Update existing policies, procedures, and processes to control risks unique to or exacerbated by GAI."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-1.3",
            "title": "Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization窶冱 risk tolerance.",
            "controls": [
              {
                "id": "GV-1.3-001",
                "title": "Consider the following, or similar, factors when updating or defining risk tiers for GAI: Abuses and risks to information integrity; Cadence of vendor releases and updates; Data protection requirements; Dependencies between GAI and other IT or data systems; Harm in physical environments; Human review of GAI system outputs; Legal or regulatory requirements; Presentation of obscene, objectionable, toxic, invalid or untruthful output; Psychological impacts to humans (e.g., anthropomorphization, algorithmic aversion, emotional entanglement); Immediate and long term impacts; Internal vs. external use; Unreliable decision making capabilities, validity, adaptability, and variability of GAI system performance over time.",
                "parts": [
                  {
                    "id": "GV-1.3-001_smt",
                    "name": "statement",
                    "prose": "Consider the following, or similar, factors when updating or defining risk tiers for GAI: Abuses and risks to information integrity; Cadence of vendor releases and updates; Data protection requirements; Dependencies between GAI and other IT or data systems; Harm in physical environments; Human review of GAI system outputs; Legal or regulatory requirements; Presentation of obscene, objectionable, toxic, invalid or untruthful output; Psychological impacts to humans (e.g., anthropomorphization, algorithmic aversion, emotional entanglement); Immediate and long term impacts; Internal vs. external use; Unreliable decision making capabilities, validity, adaptability, and variability of GAI system performance over time."
                  }
                ]
              },
              {
                "id": "GV-1.3-002",
                "title": "Define acceptable uses for GAI systems, where some applications may be restricted.",
                "parts": [
                  {
                    "id": "GV-1.3-002_smt",
                    "name": "statement",
                    "prose": "Define acceptable uses for GAI systems, where some applications may be restricted."
                  }
                ]
              },
              {
                "id": "GV-1.3-003",
                "title": "Increase cadence for internal audits to address any unanticipated changes in GAI technologies or applications.",
                "parts": [
                  {
                    "id": "GV-1.3-003_smt",
                    "name": "statement",
                    "prose": "Increase cadence for internal audits to address any unanticipated changes in GAI technologies or applications."
                  }
                ]
              },
              {
                "id": "GV-1.3-004",
                "title": "Maintain an updated hierarchy of identified and expected GAI risks connected to contexts of GAI use, potentially including specialized risk levels for GAI systems that address risks such as model collapse and algorithmic monoculture.",
                "parts": [
                  {
                    "id": "GV-1.3-004_smt",
                    "name": "statement",
                    "prose": "Maintain an updated hierarchy of identified and expected GAI risks connected to contexts of GAI use, potentially including specialized risk levels for GAI systems that address risks such as model collapse and algorithmic monoculture."
                  }
                ]
              },
              {
                "id": "GV-1.3-005",
                "title": "Reevaluate organizational risk tolerances to account for broad GAI risks, including: Immature safety or risk cultures related to AI and GAI design, development and deployment, public information integrity risks, including impacts on democratic processes, unknown long-term performance characteristics of GAI.",
                "parts": [
                  {
                    "id": "GV-1.3-005_smt",
                    "name": "statement",
                    "prose": "Reevaluate organizational risk tolerances to account for broad GAI risks, including: Immature safety or risk cultures related to AI and GAI design, development and deployment, public information integrity risks, including impacts on democratic processes, unknown long-term performance characteristics of GAI."
                  }
                ]
              },
              {
                "id": "GV-1.3-006",
                "title": "Tie expected GAI behavior to trustworthy characteristics.",
                "parts": [
                  {
                    "id": "GV-1.3-006_smt",
                    "name": "statement",
                    "prose": "Tie expected GAI behavior to trustworthy characteristics."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-1.5",
            "title": "Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and organizational roles and responsibilities are clearly defined, including determining the frequency of periodic review.",
            "controls": [
              {
                "id": "GV-1.5-001",
                "title": "Define organizational responsibilities for content provenance monitoring and incident response.",
                "parts": [
                  {
                    "id": "GV-1.5-001_smt",
                    "name": "statement",
                    "prose": "Define organizational responsibilities for content provenance monitoring and incident response."
                  }
                ]
              },
              {
                "id": "GV-1.5-002",
                "title": "Develop or review existing policies for authorization of third-party plug-ins and verify that related procedures are able to be followed.",
                "parts": [
                  {
                    "id": "GV-1.5-002_smt",
                    "name": "statement",
                    "prose": "Develop or review existing policies for authorization of third-party plug-ins and verify that related procedures are able to be followed."
                  }
                ]
              },
              {
                "id": "GV-1.5-003",
                "title": "Establish and maintain policies and procedures for monitoring the effectiveness of content provenance for data and content generated across the AI system lifecycle.",
                "parts": [
                  {
                    "id": "GV-1.5-003_smt",
                    "name": "statement",
                    "prose": "Establish and maintain policies and procedures for monitoring the effectiveness of content provenance for data and content generated across the AI system lifecycle."
                  }
                ]
              },
              {
                "id": "GV-1.5-004",
                "title": "Establish organizational policies and procedures for after action reviews of GAI system incident response and incident disclosures, to identify gaps; Update incident response and incident disclosure processes as required.",
                "parts": [
                  {
                    "id": "GV-1.5-004_smt",
                    "name": "statement",
                    "prose": "Establish organizational policies and procedures for after action reviews of GAI system incident response and incident disclosures, to identify gaps; Update incident response and incident disclosure processes as required."
                  }
                ]
              },
              {
                "id": "GV-1.5-005",
                "title": "Establish policies for periodic review of organizational monitoring and incident response plans based on impacts and in line with organizational risk tolerance.",
                "parts": [
                  {
                    "id": "GV-1.5-005_smt",
                    "name": "statement",
                    "prose": "Establish policies for periodic review of organizational monitoring and incident response plans based on impacts and in line with organizational risk tolerance."
                  }
                ]
              },
              {
                "id": "GV-1.5-006",
                "title": "Maintain a long term document retention policy to keep full history for auditing, investigation, or improving content provenance methods.",
                "parts": [
                  {
                    "id": "GV-1.5-006_smt",
                    "name": "statement",
                    "prose": "Maintain a long term document retention policy to keep full history for auditing, investigation, or improving content provenance methods."
                  }
                ]
              },
              {
                "id": "GV-1.5-007",
                "title": "Verify information sharing and feedback mechanisms among individuals and organizations regarding any negative impact from AI systems due to content provenance issues.",
                "parts": [
                  {
                    "id": "GV-1.5-007_smt",
                    "name": "statement",
                    "prose": "Verify information sharing and feedback mechanisms among individuals and organizations regarding any negative impact from AI systems due to content provenance issues."
                  }
                ]
              },
              {
                "id": "GV-1.5-008",
                "title": "Verify that review procedures include analysis of cascading impacts of GAI system outputs used as inputs to third party plug-ins or other systems.",
                "parts": [
                  {
                    "id": "GV-1.5-008_smt",
                    "name": "statement",
                    "prose": "Verify that review procedures include analysis of cascading impacts of GAI system outputs used as inputs to third party plug-ins or other systems."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-1.6",
            "title": "Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.",
            "controls": [
              {
                "id": "GV-1.6-001",
                "title": "Define any inventory exemptions for GAI systems embedded into application software in organizational policies.",
                "parts": [
                  {
                    "id": "GV-1.6-001_smt",
                    "name": "statement",
                    "prose": "Define any inventory exemptions for GAI systems embedded into application software in organizational policies."
                  }
                ]
              },
              {
                "id": "GV-1.6-002",
                "title": "Enumerate organizational GAI systems for incorporation into AI system inventory and adjust AI system inventory requirements to account for GAI risks.",
                "parts": [
                  {
                    "id": "GV-1.6-002_smt",
                    "name": "statement",
                    "prose": "Enumerate organizational GAI systems for incorporation into AI system inventory and adjust AI system inventory requirements to account for GAI risks."
                  }
                ]
              },
              {
                "id": "GV-1.6-003",
                "title": "In addition to general model, governance, and risk information, consider the following items in GAI system inventory entries: Acceptable use policies and policy exceptions; Application, Assumptions and limitations of use, including enumeration of restricted uses; Business or model owners; Challenges for explainability, interpretability, or transparency; Change management, maintenance, and monitoring plans; Connections or dependencies between other systems; Consent information and notices; Data provenance information; Designation of risk level; Disclosure information or notices; Incident response plans; Known issues; Human oversight roles and responsibilities; Intellectual property considerations; Time frame for valid deployment; Underlying models and access modes; Updated hierarchy of identified and expected risks connected to contexts of use.",
                "parts": [
                  {
                    "id": "GV-1.6-003_smt",
                    "name": "statement",
                    "prose": "In addition to general model, governance, and risk information, consider the following items in GAI system inventory entries: Acceptable use policies and policy exceptions; Application, Assumptions and limitations of use, including enumeration of restricted uses; Business or model owners; Challenges for explainability, interpretability, or transparency; Change management, maintenance, and monitoring plans; Connections or dependencies between other systems; Consent information and notices; Data provenance information; Designation of risk level; Disclosure information or notices; Incident response plans; Known issues; Human oversight roles and responsibilities; Intellectual property considerations; Time frame for valid deployment; Underlying models and access modes; Updated hierarchy of identified and expected risks connected to contexts of use."
                  }
                ]
              },
              {
                "id": "GV-1.6-004",
                "title": "Inventory recently decommissioned systems, systems with imminent deployment plans, and operational systems.",
                "parts": [
                  {
                    "id": "GV-1.6-004_smt",
                    "name": "statement",
                    "prose": "Inventory recently decommissioned systems, systems with imminent deployment plans, and operational systems."
                  }
                ]
              },
              {
                "id": "GV-1.6-005",
                "title": "Update policy definitions for AI systems, models, qualitative tools or similar to account for GAI systems.",
                "parts": [
                  {
                    "id": "GV-1.6-005_smt",
                    "name": "statement",
                    "prose": "Update policy definitions for AI systems, models, qualitative tools or similar to account for GAI systems."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-1.7",
            "title": "Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization窶冱 trustworthiness.",
            "controls": [
              {
                "id": "GV-1.7-001",
                "title": "Allocate time and resources for staged decommissioning for GAI to avoid service disruptions.",
                "parts": [
                  {
                    "id": "GV-1.7-001_smt",
                    "name": "statement",
                    "prose": "Allocate time and resources for staged decommissioning for GAI to avoid service disruptions."
                  }
                ]
              },
              {
                "id": "GV-1.7-002",
                "title": "Communicate decommissioning and support plans for GAI systems to AI actors and users through various channels and maintain communication and associated training protocols.",
                "parts": [
                  {
                    "id": "GV-1.7-002_smt",
                    "name": "statement",
                    "prose": "Communicate decommissioning and support plans for GAI systems to AI actors and users through various channels and maintain communication and associated training protocols."
                  }
                ]
              },
              {
                "id": "GV-1.7-003",
                "title": "Consider the following factors when decommissioning GAI systems: Clear versioning of decommissioned and replacement systems; Contractual, legal, or regulatory requirements; Data retention requirements; Data security, e.g., Containment, protocols, Data leakage after decommissioning; Dependencies between upstream, downstream, or other data, internet of things (IOT) or AI systems; Digital and physical artifacts; Recourse mechanisms for impacted users or communities; Termination of related cloud or vendor services; Users窶 emotional entanglement with GAI functions.",
                "parts": [
                  {
                    "id": "GV-1.7-003_smt",
                    "name": "statement",
                    "prose": "Consider the following factors when decommissioning GAI systems: Clear versioning of decommissioned and replacement systems; Contractual, legal, or regulatory requirements; Data retention requirements; Data security, e.g., Containment, protocols, Data leakage after decommissioning; Dependencies between upstream, downstream, or other data, internet of things (IOT) or AI systems; Digital and physical artifacts; Recourse mechanisms for impacted users or communities; Termination of related cloud or vendor services; Users窶 emotional entanglement with GAI functions."
                  }
                ]
              },
              {
                "id": "GV-1.7-004",
                "title": "Implement data security and privacy controls for stored decommissioned GAI systems.",
                "parts": [
                  {
                    "id": "GV-1.7-004_smt",
                    "name": "statement",
                    "prose": "Implement data security and privacy controls for stored decommissioned GAI systems."
                  }
                ]
              },
              {
                "id": "GV-1.7-005",
                "title": "Update existing policies (e.g., enterprise record retention policies) or establish new policies for the decommissioning of GAI systems.",
                "parts": [
                  {
                    "id": "GV-1.7-005_smt",
                    "name": "statement",
                    "prose": "Update existing policies (e.g., enterprise record retention policies) or establish new policies for the decommissioning of GAI systems."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-2.1",
            "title": "Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.",
            "controls": [
              {
                "id": "GV-2.1-001",
                "title": "Define acceptable use cases and context under which the organization will design, develop, deploy, and use GAI systems.",
                "parts": [
                  {
                    "id": "GV-2.1-001_smt",
                    "name": "statement",
                    "prose": "Define acceptable use cases and context under which the organization will design, develop, deploy, and use GAI systems."
                  }
                ]
              },
              {
                "id": "GV-2.1-002",
                "title": "Establish policies and procedures for GAI risk acceptance to downstream AI actors.",
                "parts": [
                  {
                    "id": "GV-2.1-002_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures for GAI risk acceptance to downstream AI actors."
                  }
                ]
              },
              {
                "id": "GV-2.1-003",
                "title": "Establish policies to identify and disclose GAI system incidents to downstream AI actors, including individuals potentially impacted by GAI outputs.",
                "parts": [
                  {
                    "id": "GV-2.1-003_smt",
                    "name": "statement",
                    "prose": "Establish policies to identify and disclose GAI system incidents to downstream AI actors, including individuals potentially impacted by GAI outputs."
                  }
                ]
              },
              {
                "id": "GV-2.1-004",
                "title": "Establish procedures to engage teams for GAI system incident response with diverse composition and responsibilities based on the particular incident type.",
                "parts": [
                  {
                    "id": "GV-2.1-004_smt",
                    "name": "statement",
                    "prose": "Establish procedures to engage teams for GAI system incident response with diverse composition and responsibilities based on the particular incident type."
                  }
                ]
              },
              {
                "id": "GV-2.1-005",
                "title": "Establish processes to identify GAI system incidents and verify the AI actors conducting these tasks demonstrate and maintain the appropriate skills and training.",
                "parts": [
                  {
                    "id": "GV-2.1-005_smt",
                    "name": "statement",
                    "prose": "Establish processes to identify GAI system incidents and verify the AI actors conducting these tasks demonstrate and maintain the appropriate skills and training."
                  }
                ]
              },
              {
                "id": "GV-2.1-006",
                "title": "Verify that incident disclosure plans include sufficient GAI system context to facilitate remediation actions.",
                "parts": [
                  {
                    "id": "GV-2.1-006_smt",
                    "name": "statement",
                    "prose": "Verify that incident disclosure plans include sufficient GAI system context to facilitate remediation actions."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-3.2",
            "title": "Policies and procedures are in place to define and differentiate roles and responsibilities for human-AI configurations and oversight of AI systems.",
            "controls": [
              {
                "id": "GV-3.2-001",
                "title": "Bolster oversight of GAI systems with independent audits or assessments, or by the application of authoritative external standards.",
                "parts": [
                  {
                    "id": "GV-3.2-001_smt",
                    "name": "statement",
                    "prose": "Bolster oversight of GAI systems with independent audits or assessments, or by the application of authoritative external standards."
                  }
                ]
              },
              {
                "id": "GV-3.2-002",
                "title": "Consider adjustment of organizational roles and components across lifecycle stages of large or complex GAI systems, including: AI actor, user, and community feedback; Audit, validation, and red-teaming of GAI systems; GAI content moderation; Decommissioning GAI systems; Decreasing risks of emotional entanglement and deception; Enhancing explainability; Incident response and containment; Training users on GAI fundamentals and risks.",
                "parts": [
                  {
                    "id": "GV-3.2-002_smt",
                    "name": "statement",
                    "prose": "Consider adjustment of organizational roles and components across lifecycle stages of large or complex GAI systems, including: AI actor, user, and community feedback; Audit, validation, and red-teaming of GAI systems; GAI content moderation; Decommissioning GAI systems; Decreasing risks of emotional entanglement and deception; Enhancing explainability; Incident response and containment; Training users on GAI fundamentals and risks."
                  }
                ]
              },
              {
                "id": "GV-3.2-003",
                "title": "Define acceptable use policies for various categories of GAI interfaces, modalities, and human-AI configurations.",
                "parts": [
                  {
                    "id": "GV-3.2-003_smt",
                    "name": "statement",
                    "prose": "Define acceptable use policies for various categories of GAI interfaces, modalities, and human-AI configurations."
                  }
                ]
              },
              {
                "id": "GV-3.2-004",
                "title": "Define policies for the design of systems that possess human decision-making powers.",
                "parts": [
                  {
                    "id": "GV-3.2-004_smt",
                    "name": "statement",
                    "prose": "Define policies for the design of systems that possess human decision-making powers."
                  }
                ]
              },
              {
                "id": "GV-3.2-005",
                "title": "Establish policies for user feedback mechanisms in GAI systems.",
                "parts": [
                  {
                    "id": "GV-3.2-005_smt",
                    "name": "statement",
                    "prose": "Establish policies for user feedback mechanisms in GAI systems."
                  }
                ]
              },
              {
                "id": "GV-3.2-006",
                "title": "Establish policies to empower accountable executives to oversee GAI system adoption, use, and decommissioning.",
                "parts": [
                  {
                    "id": "GV-3.2-006_smt",
                    "name": "statement",
                    "prose": "Establish policies to empower accountable executives to oversee GAI system adoption, use, and decommissioning."
                  }
                ]
              },
              {
                "id": "GV-3.2-007",
                "title": "Establish processes to include and empower interdisciplinary team member perspectives across the AI lifecycle.",
                "parts": [
                  {
                    "id": "GV-3.2-007_smt",
                    "name": "statement",
                    "prose": "Establish processes to include and empower interdisciplinary team member perspectives across the AI lifecycle."
                  }
                ]
              },
              {
                "id": "GV-3.2-008",
                "title": "Evaluate AI actor teams in consideration of credentials, demographic representation, interdisciplinary diversity, and professional qualifications.",
                "parts": [
                  {
                    "id": "GV-3.2-008_smt",
                    "name": "statement",
                    "prose": "Evaluate AI actor teams in consideration of credentials, demographic representation, interdisciplinary diversity, and professional qualifications."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-4.1",
            "title": "Organizational policies and practices are in place to foster a critical thinking and safety-first mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.",
            "controls": [
              {
                "id": "GV-4.1-001",
                "title": "Establish criteria and acceptable use policies for the use of GAI in decision making tasks in accordance with organizational risk tolerance, and other policies laid out in the Govern function; to include detailed criteria for the kinds of queries GAI models should refuse to respond to.",
                "parts": [
                  {
                    "id": "GV-4.1-001_smt",
                    "name": "statement",
                    "prose": "Establish criteria and acceptable use policies for the use of GAI in decision making tasks in accordance with organizational risk tolerance, and other policies laid out in the Govern function; to include detailed criteria for the kinds of queries GAI models should refuse to respond to."
                  }
                ]
              },
              {
                "id": "GV-4.1-002",
                "title": "Establish policies and procedures that address continual improvement processes for risk measurement: Address general risks associated with a lack of explainability and transparency in GAI systems by using ample documentation and techniques such as: application of gradient-based attributions, occlusion/term reduction, counterfactual prompts and prompt engineering, and analysis of embeddings; Assess and update risk measurement approaches at regular cadences.",
                "parts": [
                  {
                    "id": "GV-4.1-002_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures that address continual improvement processes for risk measurement: Address general risks associated with a lack of explainability and transparency in GAI systems by using ample documentation and techniques such as: application of gradient-based attributions, occlusion/term reduction, counterfactual prompts and prompt engineering, and analysis of embeddings; Assess and update risk measurement approaches at regular cadences."
                  }
                ]
              },
              {
                "id": "GV-4.1-003",
                "title": "Establish policies, procedures, and processes detailing risk measurement in context of use with standardized measurement protocols and structured public feedback exercises such as AI red-teaming or independent external audits.",
                "parts": [
                  {
                    "id": "GV-4.1-003_smt",
                    "name": "statement",
                    "prose": "Establish policies, procedures, and processes detailing risk measurement in context of use with standardized measurement protocols and structured public feedback exercises such as AI red-teaming or independent external audits."
                  }
                ]
              },
              {
                "id": "GV-4.1-004",
                "title": "Establish policies, procedures, and processes for oversight functions (e.g., senior leadership, legal, compliance, and risk) across the GAI lifecycle, from problem formulation and supply chains to system decommission.",
                "parts": [
                  {
                    "id": "GV-4.1-004_smt",
                    "name": "statement",
                    "prose": "Establish policies, procedures, and processes for oversight functions (e.g., senior leadership, legal, compliance, and risk) across the GAI lifecycle, from problem formulation and supply chains to system decommission."
                  }
                ]
              },
              {
                "id": "GV-4.1-005",
                "title": "Establish policies, procedures, and processes that promote effective challenge of AI system design, implementation, and deployment decisions via mechanisms such as three lines of defense, to minimize risks arising from workplace culture (e.g., confirmation bias, funding bias, groupthink, over-reliance on metrics).",
                "parts": [
                  {
                    "id": "GV-4.1-005_smt",
                    "name": "statement",
                    "prose": "Establish policies, procedures, and processes that promote effective challenge of AI system design, implementation, and deployment decisions via mechanisms such as three lines of defense, to minimize risks arising from workplace culture (e.g., confirmation bias, funding bias, groupthink, over-reliance on metrics)."
                  }
                ]
              },
              {
                "id": "GV-4.1-006",
                "title": "Incorporate GAI governance policies into existing incident response, whistleblower, vendor or investment due diligence, acquisition, procurement, reporting or internal audit policies.",
                "parts": [
                  {
                    "id": "GV-4.1-006_smt",
                    "name": "statement",
                    "prose": "Incorporate GAI governance policies into existing incident response, whistleblower, vendor or investment due diligence, acquisition, procurement, reporting or internal audit policies."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-4.2",
            "title": "Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.",
            "controls": [
              {
                "id": "GV-4.2-001",
                "title": "Develop policies, guidelines, and practices for monitoring organizational and third-party impact assessments (data, labels, bias, privacy, models, algorithms, errors, provenance techniques, security, legal compliance, output, etc.) to mitigate risk and harm.",
                "parts": [
                  {
                    "id": "GV-4.2-001_smt",
                    "name": "statement",
                    "prose": "Develop policies, guidelines, and practices for monitoring organizational and third-party impact assessments (data, labels, bias, privacy, models, algorithms, errors, provenance techniques, security, legal compliance, output, etc.) to mitigate risk and harm."
                  }
                ]
              },
              {
                "id": "GV-4.2-002",
                "title": "Establish clear roles and responsibilities for inter-organizational incident response and communication for GAI systems that involve multiple organizations involved in different aspects of the GAI system lifecycle.",
                "parts": [
                  {
                    "id": "GV-4.2-002_smt",
                    "name": "statement",
                    "prose": "Establish clear roles and responsibilities for inter-organizational incident response and communication for GAI systems that involve multiple organizations involved in different aspects of the GAI system lifecycle."
                  }
                ]
              },
              {
                "id": "GV-4.2-003",
                "title": "Establish clearly defined terms of use and terms of service.",
                "parts": [
                  {
                    "id": "GV-4.2-003_smt",
                    "name": "statement",
                    "prose": "Establish clearly defined terms of use and terms of service."
                  }
                ]
              },
              {
                "id": "GV-4.2-004",
                "title": "Establish criteria for ad-hoc impact assessments based on incident reporting or new use cases for the GAI system.",
                "parts": [
                  {
                    "id": "GV-4.2-004_smt",
                    "name": "statement",
                    "prose": "Establish criteria for ad-hoc impact assessments based on incident reporting or new use cases for the GAI system."
                  }
                ]
              },
              {
                "id": "GV-4.2-005",
                "title": "Establish organizational roles, policies, and procedures for communicating and reporting GAI system risks and terms of use or service, relevant for different AI actors.",
                "parts": [
                  {
                    "id": "GV-4.2-005_smt",
                    "name": "statement",
                    "prose": "Establish organizational roles, policies, and procedures for communicating and reporting GAI system risks and terms of use or service, relevant for different AI actors."
                  }
                ]
              },
              {
                "id": "GV-4.2-006",
                "title": "Establish policies and procedures to document new ways AI actors interact with the GAI system.",
                "parts": [
                  {
                    "id": "GV-4.2-006_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures to document new ways AI actors interact with the GAI system."
                  }
                ]
              },
              {
                "id": "GV-4.2-007",
                "title": "Establish policies and procedures to monitor compliance with established terms of service and use.",
                "parts": [
                  {
                    "id": "GV-4.2-007_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures to monitor compliance with established terms of service and use."
                  }
                ]
              },
              {
                "id": "GV-4.2-008",
                "title": "Establish policies to align organizational and third-party assessments with regulatory and legal compliance regarding content provenance.",
                "parts": [
                  {
                    "id": "GV-4.2-008_smt",
                    "name": "statement",
                    "prose": "Establish policies to align organizational and third-party assessments with regulatory and legal compliance regarding content provenance."
                  }
                ]
              },
              {
                "id": "GV-4.2-009",
                "title": "Establish policies to incorporate adversarial examples and other provenance attacks in AI model training processes to enhance resilience against attacks.",
                "parts": [
                  {
                    "id": "GV-4.2-009_smt",
                    "name": "statement",
                    "prose": "Establish policies to incorporate adversarial examples and other provenance attacks in AI model training processes to enhance resilience against attacks."
                  }
                ]
              },
              {
                "id": "GV-4.2-010",
                "title": "Establish processes to monitor and identify misuse, unforeseen use cases, risks of the GAI system and potential impacts of those risks (leveraging GAI system use case inventory).",
                "parts": [
                  {
                    "id": "GV-4.2-010_smt",
                    "name": "statement",
                    "prose": "Establish processes to monitor and identify misuse, unforeseen use cases, risks of the GAI system and potential impacts of those risks (leveraging GAI system use case inventory)."
                  }
                ]
              },
              {
                "id": "GV-4.2-011",
                "title": "Implement standardized documentation of GAI system risks and potential impacts.",
                "parts": [
                  {
                    "id": "GV-4.2-011_smt",
                    "name": "statement",
                    "prose": "Implement standardized documentation of GAI system risks and potential impacts."
                  }
                ]
              },
              {
                "id": "GV-4.2-012",
                "title": "Include relevant AI Actors in the GAI system risk identification process.",
                "parts": [
                  {
                    "id": "GV-4.2-012_smt",
                    "name": "statement",
                    "prose": "Include relevant AI Actors in the GAI system risk identification process."
                  }
                ]
              },
              {
                "id": "GV-4.2-013",
                "title": "Verify that downstream GAI system impacts (such as the use of third-party plug-ins) are included in the impact documentation process.",
                "parts": [
                  {
                    "id": "GV-4.2-013_smt",
                    "name": "statement",
                    "prose": "Verify that downstream GAI system impacts (such as the use of third-party plug-ins) are included in the impact documentation process."
                  }
                ]
              },
              {
                "id": "GV-4.2-014",
                "title": "Verify that the organizational list of risks related to the use of the GAI system are updated based on unforeseen GAI system incidents.",
                "parts": [
                  {
                    "id": "GV-4.2-014_smt",
                    "name": "statement",
                    "prose": "Verify that the organizational list of risks related to the use of the GAI system are updated based on unforeseen GAI system incidents."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-4.3",
            "title": "Organizational practices are in place to enable AI testing, identification of incidents, and information sharing.",
            "controls": [
              {
                "id": "GV-4.3-001",
                "title": "Allocate resources and adjust adoption, development, and implementation timeframes to enable independent measurement, continuous monitoring, and fulsome information sharing for GAI system risks.",
                "parts": [
                  {
                    "id": "GV-4.3-001_smt",
                    "name": "statement",
                    "prose": "Allocate resources and adjust adoption, development, and implementation timeframes to enable independent measurement, continuous monitoring, and fulsome information sharing for GAI system risks."
                  }
                ]
              },
              {
                "id": "GV-4.3-002",
                "title": "Develop standardized documentation templates for efficient review of risk measurement results.",
                "parts": [
                  {
                    "id": "GV-4.3-002_smt",
                    "name": "statement",
                    "prose": "Develop standardized documentation templates for efficient review of risk measurement results."
                  }
                ]
              },
              {
                "id": "GV-4.3-003",
                "title": "Establish minimum thresholds for performance and review as part of deployment approval (窶徃o/no-go窶) policies, procedures, and processes, with reviewed processes and approval thresholds reflecting measurement of GAI capabilities and risks.",
                "parts": [
                  {
                    "id": "GV-4.3-003_smt",
                    "name": "statement",
                    "prose": "Establish minimum thresholds for performance and review as part of deployment approval (窶徃o/no-go窶) policies, procedures, and processes, with reviewed processes and approval thresholds reflecting measurement of GAI capabilities and risks."
                  }
                ]
              },
              {
                "id": "GV-4.3-004",
                "title": "Establish organizational roles, policies, and procedures for communicating GAI system incidents and performance to AI actors and downstream stakeholders, via community or official resources (e.g., AI Incident Database, AVID, AI Litigation Database, CVE, OECD Incident Monitor, or others).",
                "parts": [
                  {
                    "id": "GV-4.3-004_smt",
                    "name": "statement",
                    "prose": "Establish organizational roles, policies, and procedures for communicating GAI system incidents and performance to AI actors and downstream stakeholders, via community or official resources (e.g., AI Incident Database, AVID, AI Litigation Database, CVE, OECD Incident Monitor, or others)."
                  }
                ]
              },
              {
                "id": "GV-4.3-005",
                "title": "Establish policies and procedures for pre-deployment GAI system testing that validates organizational capability to capture GAI system incident reporting criteria.",
                "parts": [
                  {
                    "id": "GV-4.3-005_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures for pre-deployment GAI system testing that validates organizational capability to capture GAI system incident reporting criteria."
                  }
                ]
              },
              {
                "id": "GV-4.3-006",
                "title": "Establish policies, procedures, and processes that bolster independence of risk management and measurement functions (e.g., independent reporting chains, aligned incentives).",
                "parts": [
                  {
                    "id": "GV-4.3-006_smt",
                    "name": "statement",
                    "prose": "Establish policies, procedures, and processes that bolster independence of risk management and measurement functions (e.g., independent reporting chains, aligned incentives)."
                  }
                ]
              },
              {
                "id": "GV-4.3-007",
                "title": "Establish policies, procedures, and processes that enable and incentivize in-context risk measurement via standardized measurement and structured public feedback approaches.",
                "parts": [
                  {
                    "id": "GV-4.3-007_smt",
                    "name": "statement",
                    "prose": "Establish policies, procedures, and processes that enable and incentivize in-context risk measurement via standardized measurement and structured public feedback approaches."
                  }
                ]
              },
              {
                "id": "GV-4.3-008",
                "title": "Organizational procedures identify the minimum set of criteria necessary for GAI system incident reporting such as: System ID (auto-generated most likely), Title, Reporter, System/Source, Data Reported, Date of Incident, Description, Impact(s), Stakeholder(s) Impacted.",
                "parts": [
                  {
                    "id": "GV-4.3-008_smt",
                    "name": "statement",
                    "prose": "Organizational procedures identify the minimum set of criteria necessary for GAI system incident reporting such as: System ID (auto-generated most likely), Title, Reporter, System/Source, Data Reported, Date of Incident, Description, Impact(s), Stakeholder(s) Impacted."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-5.1",
            "title": "Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.",
            "controls": [
              {
                "id": "GV-5.1-001",
                "title": "Allocate time and resources for outreach, feedback, and recourse processes in GAI system development.",
                "parts": [
                  {
                    "id": "GV-5.1-001_smt",
                    "name": "statement",
                    "prose": "Allocate time and resources for outreach, feedback, and recourse processes in GAI system development."
                  }
                ]
              },
              {
                "id": "GV-5.1-002",
                "title": "Disclose interactions with GAI systems to users prior to interactive activities.",
                "parts": [
                  {
                    "id": "GV-5.1-002_smt",
                    "name": "statement",
                    "prose": "Disclose interactions with GAI systems to users prior to interactive activities."
                  }
                ]
              },
              {
                "id": "GV-5.1-003",
                "title": "Establish policy, guidelines and processes that: Engage independent experts to audit models, data sources, licenses, algorithms, and other system components, Consider sponsoring or engaging in community-based exercises (e.g., bug bounties, hackathons, competitions) where AI Actors assess and benchmark the performance of AI systems, including the robustness of content provenance management under various conditions; Document data sources, licenses, training methodologies, and trade-offs considered in the design of AI systems; Establish mechanisms, platforms or channels (e.g., user interfaces, web portals, forums) for independent experts, users, or community members to provide feedback related to AI systems; Adjudicate and implement relevant feedback at a regular cadence, Establish transparency mechanisms to track the origin of data and generated content; Audit and validate these mechanisms.",
                "parts": [
                  {
                    "id": "GV-5.1-003_smt",
                    "name": "statement",
                    "prose": "Establish policy, guidelines and processes that: Engage independent experts to audit models, data sources, licenses, algorithms, and other system components, Consider sponsoring or engaging in community-based exercises (e.g., bug bounties, hackathons, competitions) where AI Actors assess and benchmark the performance of AI systems, including the robustness of content provenance management under various conditions; Document data sources, licenses, training methodologies, and trade-offs considered in the design of AI systems; Establish mechanisms, platforms or channels (e.g., user interfaces, web portals, forums) for independent experts, users, or community members to provide feedback related to AI systems; Adjudicate and implement relevant feedback at a regular cadence, Establish transparency mechanisms to track the origin of data and generated content; Audit and validate these mechanisms."
                  }
                ]
              },
              {
                "id": "GV-5.1-004",
                "title": "Establish processes to bolster internal AI actor culture in alignment with organizational principles and norms and to empower exploration of GAI limitations beyond development settings.",
                "parts": [
                  {
                    "id": "GV-5.1-004_smt",
                    "name": "statement",
                    "prose": "Establish processes to bolster internal AI actor culture in alignment with organizational principles and norms and to empower exploration of GAI limitations beyond development settings."
                  }
                ]
              },
              {
                "id": "GV-5.1-005",
                "title": "Establish the following GAI-specific policies and procedures for independent AI Actors: Continuous improvement processes for increasing explainability and mitigating other risks; Impact assessments, Incentives for internal AI actors to provide feedback and conduct independent risk management activities; Independent management and reporting structures for AI actors engaged in model and system audit, validation, and oversight; TEVV processes for the effectiveness of feedback mechanisms employing participation rates, resolution time, or similar measurements.",
                "parts": [
                  {
                    "id": "GV-5.1-005_smt",
                    "name": "statement",
                    "prose": "Establish the following GAI-specific policies and procedures for independent AI Actors: Continuous improvement processes for increasing explainability and mitigating other risks; Impact assessments, Incentives for internal AI actors to provide feedback and conduct independent risk management activities; Independent management and reporting structures for AI actors engaged in model and system audit, validation, and oversight; TEVV processes for the effectiveness of feedback mechanisms employing participation rates, resolution time, or similar measurements."
                  }
                ]
              },
              {
                "id": "GV-5.1-006",
                "title": "Provide thorough instructions for GAI system users to provide feedback and understand recourse mechanisms.",
                "parts": [
                  {
                    "id": "GV-5.1-006_smt",
                    "name": "statement",
                    "prose": "Provide thorough instructions for GAI system users to provide feedback and understand recourse mechanisms."
                  }
                ]
              },
              {
                "id": "GV-5.1-007",
                "title": "Standardize user feedback about GAI system behavior, risks and limitations for efficient adjudication and incorporation.",
                "parts": [
                  {
                    "id": "GV-5.1-007_smt",
                    "name": "statement",
                    "prose": "Standardize user feedback about GAI system behavior, risks and limitations for efficient adjudication and incorporation."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-6.1",
            "title": "Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party窶冱 intellectual property or other rights.",
            "controls": [
              {
                "id": "GV-6.1-001",
                "title": "Categorize different types of GAI content with associated third party risks (i.e., copyright, intellectual property, data privacy).",
                "parts": [
                  {
                    "id": "GV-6.1-001_smt",
                    "name": "statement",
                    "prose": "Categorize different types of GAI content with associated third party risks (i.e., copyright, intellectual property, data privacy)."
                  }
                ]
              },
              {
                "id": "GV-6.1-002",
                "title": "Conduct due diligence on third-party entities and end-users from those entities before entering into agreements with them (e.g., checking references, reviewing their content handling processes, etc.).",
                "parts": [
                  {
                    "id": "GV-6.1-002_smt",
                    "name": "statement",
                    "prose": "Conduct due diligence on third-party entities and end-users from those entities before entering into agreements with them (e.g., checking references, reviewing their content handling processes, etc.)."
                  }
                ]
              },
              {
                "id": "GV-6.1-003",
                "title": "Conduct joint educational activities and events in collaboration with third-parties to promote content provenance best practices.",
                "parts": [
                  {
                    "id": "GV-6.1-003_smt",
                    "name": "statement",
                    "prose": "Conduct joint educational activities and events in collaboration with third-parties to promote content provenance best practices."
                  }
                ]
              },
              {
                "id": "GV-6.1-004",
                "title": "Conduct regular audits of third-party entities to ensure compliance with contractual agreements.",
                "parts": [
                  {
                    "id": "GV-6.1-004_smt",
                    "name": "statement",
                    "prose": "Conduct regular audits of third-party entities to ensure compliance with contractual agreements."
                  }
                ]
              },
              {
                "id": "GV-6.1-005",
                "title": "Define and communicate organizational roles and responsibilities for GAI acquisition, human resources, procurement, and talent management processes in policies and procedures.",
                "parts": [
                  {
                    "id": "GV-6.1-005_smt",
                    "name": "statement",
                    "prose": "Define and communicate organizational roles and responsibilities for GAI acquisition, human resources, procurement, and talent management processes in policies and procedures."
                  }
                ]
              },
              {
                "id": "GV-6.1-006",
                "title": "Develop an incident response plan for third parties specifically tailored to address content provenance incidents or breaches and regularly test and update the incident response plan with feedback from external and third party stakeholders.",
                "parts": [
                  {
                    "id": "GV-6.1-006_smt",
                    "name": "statement",
                    "prose": "Develop an incident response plan for third parties specifically tailored to address content provenance incidents or breaches and regularly test and update the incident response plan with feedback from external and third party stakeholders."
                  }
                ]
              },
              {
                "id": "GV-6.1-007",
                "title": "Develop and validate approaches for measuring the success of content provenance management efforts with third parties (e.g., incidents detected and response times).",
                "parts": [
                  {
                    "id": "GV-6.1-007_smt",
                    "name": "statement",
                    "prose": "Develop and validate approaches for measuring the success of content provenance management efforts with third parties (e.g., incidents detected and response times)."
                  }
                ]
              },
              {
                "id": "GV-6.1-008",
                "title": "Develop risk tolerance and criteria to quantitatively assess and compare the level of risk associated with different third-party entities (i.e., reputation, track record, security measure, and the sensitivity of the content they handle).",
                "parts": [
                  {
                    "id": "GV-6.1-008_smt",
                    "name": "statement",
                    "prose": "Develop risk tolerance and criteria to quantitatively assess and compare the level of risk associated with different third-party entities (i.e., reputation, track record, security measure, and the sensitivity of the content they handle)."
                  }
                ]
              },
              {
                "id": "GV-6.1-009",
                "title": "Draft and maintain well-defined contracts and service level agreements (SLAs) that specify content ownership, usage rights, quality standards, security requirements, and content provenance expectations.",
                "parts": [
                  {
                    "id": "GV-6.1-009_smt",
                    "name": "statement",
                    "prose": "Draft and maintain well-defined contracts and service level agreements (SLAs) that specify content ownership, usage rights, quality standards, security requirements, and content provenance expectations."
                  }
                ]
              },
              {
                "id": "GV-6.1-010",
                "title": "Establish processes to maintain awareness of evolving risks, technologies, and best practices in content provenance management.",
                "parts": [
                  {
                    "id": "GV-6.1-010_smt",
                    "name": "statement",
                    "prose": "Establish processes to maintain awareness of evolving risks, technologies, and best practices in content provenance management."
                  }
                ]
              },
              {
                "id": "GV-6.1-011",
                "title": "Implement a supplier risk assessment framework to continuously evaluate and monitor third-party entities窶 performance and adherence to content provenance standards and technologies (e.g., digital signatures, watermarks, cryptography, etc.) to detect anomalies and unauthorized changes; services acquisition and supply chain risk management; legal compliance (e.g., copyright, trademarks, and data privacy laws).",
                "parts": [
                  {
                    "id": "GV-6.1-011_smt",
                    "name": "statement",
                    "prose": "Implement a supplier risk assessment framework to continuously evaluate and monitor third-party entities窶 performance and adherence to content provenance standards and technologies (e.g., digital signatures, watermarks, cryptography, etc.) to detect anomalies and unauthorized changes; services acquisition and supply chain risk management; legal compliance (e.g., copyright, trademarks, and data privacy laws)."
                  }
                ]
              },
              {
                "id": "GV-6.1-012",
                "title": "Include audit clauses in contracts that allow the organization to verify compliance with content provenance requirements.",
                "parts": [
                  {
                    "id": "GV-6.1-012_smt",
                    "name": "statement",
                    "prose": "Include audit clauses in contracts that allow the organization to verify compliance with content provenance requirements."
                  }
                ]
              },
              {
                "id": "GV-6.1-013",
                "title": "Inventory all third-party entities with access to organizational content and establish approved GAI technology and service provider lists.",
                "parts": [
                  {
                    "id": "GV-6.1-013_smt",
                    "name": "statement",
                    "prose": "Inventory all third-party entities with access to organizational content and establish approved GAI technology and service provider lists."
                  }
                ]
              },
              {
                "id": "GV-6.1-014",
                "title": "Maintain detailed records of content provenance, including sources, timestamps, metadata, and any changes made by third parties.",
                "parts": [
                  {
                    "id": "GV-6.1-014_smt",
                    "name": "statement",
                    "prose": "Maintain detailed records of content provenance, including sources, timestamps, metadata, and any changes made by third parties."
                  }
                ]
              },
              {
                "id": "GV-6.1-015",
                "title": "Provide proper training to internal employees on content provenance best practices, risks, and reporting procedures.",
                "parts": [
                  {
                    "id": "GV-6.1-015_smt",
                    "name": "statement",
                    "prose": "Provide proper training to internal employees on content provenance best practices, risks, and reporting procedures."
                  }
                ]
              },
              {
                "id": "GV-6.1-016",
                "title": "Update and integrate due diligence processes for GAI acquisition and procurement vendor assessments to include intellectual property, data privacy, security, and other risks. For example, update policies to: Address robotic process automation (RPA), software-as-a-service (SAAS), and other solutions that may rely on embedded GAI technologies; Address ongoing audits, assessments, and alerting, dynamic risk assessments, and real-time reporting tools for monitoring third-party GAI risks; Address accessibility, accommodations, or opt-outs in GAI vendor offerings; Address commercial use of GAI outputs and secondary use of collected data by third parties; Assess vendor risk controls for intellectual property infringements and data privacy; Consider policy adjustments across GAI modeling libraries, tools and APIs, fine-tuned models, and embedded tools; Establish ownership of GAI acquisition and procurement processes; Include relevant organizational functions in evaluations of GAI third parties (e.g., legal, information technology (IT), security, privacy, fair lending); Include instruction on intellectual property infringement and other third-party GAI risks in GAI training for AI actors.",
                "parts": [
                  {
                    "id": "GV-6.1-016_smt",
                    "name": "statement",
                    "prose": "Update and integrate due diligence processes for GAI acquisition and procurement vendor assessments to include intellectual property, data privacy, security, and other risks. For example, update policies to: Address robotic process automation (RPA), software-as-a-service (SAAS), and other solutions that may rely on embedded GAI technologies; Address ongoing audits, assessments, and alerting, dynamic risk assessments, and real-time reporting tools for monitoring third-party GAI risks; Address accessibility, accommodations, or opt-outs in GAI vendor offerings; Address commercial use of GAI outputs and secondary use of collected data by third parties; Assess vendor risk controls for intellectual property infringements and data privacy; Consider policy adjustments across GAI modeling libraries, tools and APIs, fine-tuned models, and embedded tools; Establish ownership of GAI acquisition and procurement processes; Include relevant organizational functions in evaluations of GAI third parties (e.g., legal, information technology (IT), security, privacy, fair lending); Include instruction on intellectual property infringement and other third-party GAI risks in GAI training for AI actors."
                  }
                ]
              },
              {
                "id": "GV-6.1-017",
                "title": "Update GAI acceptable use policies to address proprietary and open-source GAI technologies and data, and contractors, consultants, and other third-party personnel.",
                "parts": [
                  {
                    "id": "GV-6.1-017_smt",
                    "name": "statement",
                    "prose": "Update GAI acceptable use policies to address proprietary and open-source GAI technologies and data, and contractors, consultants, and other third-party personnel."
                  }
                ]
              },
              {
                "id": "GV-6.1-018",
                "title": "Update human resource and talent management standards to address acceptable use of GAI.",
                "parts": [
                  {
                    "id": "GV-6.1-018_smt",
                    "name": "statement",
                    "prose": "Update human resource and talent management standards to address acceptable use of GAI."
                  }
                ]
              },
              {
                "id": "GV-6.1-019",
                "title": "Update third-party contracts, service agreements, and warranties to address GAI risks; Contracts, service agreements, and similar documents may include GAI-specific indemnity clauses, dispute resolution mechanisms, and other risk controls.",
                "parts": [
                  {
                    "id": "GV-6.1-019_smt",
                    "name": "statement",
                    "prose": "Update third-party contracts, service agreements, and warranties to address GAI risks; Contracts, service agreements, and similar documents may include GAI-specific indemnity clauses, dispute resolution mechanisms, and other risk controls."
                  }
                ]
              }
            ]
          },
          {
            "id": "GV-6.2",
            "title": "Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.",
            "controls": [
              {
                "id": "GV-6.2-001",
                "title": "Apply existing organizational risk management policies, procedures, and documentation processes to third-party GAI data and systems, including open source data and software.",
                "parts": [
                  {
                    "id": "GV-6.2-001_smt",
                    "name": "statement",
                    "prose": "Apply existing organizational risk management policies, procedures, and documentation processes to third-party GAI data and systems, including open source data and software."
                  }
                ]
              },
              {
                "id": "GV-6.2-002",
                "title": "Document downstream GAI system impacts (e.g., the use of third-party plug-ins) for third party dependencies.",
                "parts": [
                  {
                    "id": "GV-6.2-002_smt",
                    "name": "statement",
                    "prose": "Document downstream GAI system impacts (e.g., the use of third-party plug-ins) for third party dependencies."
                  }
                ]
              },
              {
                "id": "GV-6.2-003",
                "title": "Document GAI system supply chain risks to identify over-reliance on third party data or GAI systems and to identify fallbacks.",
                "parts": [
                  {
                    "id": "GV-6.2-003_smt",
                    "name": "statement",
                    "prose": "Document GAI system supply chain risks to identify over-reliance on third party data or GAI systems and to identify fallbacks."
                  }
                ]
              },
              {
                "id": "GV-6.2-004",
                "title": "Document incidents involving third-party GAI data and systems, including open source data and software.",
                "parts": [
                  {
                    "id": "GV-6.2-004_smt",
                    "name": "statement",
                    "prose": "Document incidents involving third-party GAI data and systems, including open source data and software."
                  }
                ]
              },
              {
                "id": "GV-6.2-005",
                "title": "Enumerate organizational GAI system risks based on external dependencies on third-party data or GAI systems.",
                "parts": [
                  {
                    "id": "GV-6.2-005_smt",
                    "name": "statement",
                    "prose": "Enumerate organizational GAI system risks based on external dependencies on third-party data or GAI systems."
                  }
                ]
              },
              {
                "id": "GV-6.2-006",
                "title": "Establish acceptable use policies that identify dependencies, potential impacts, and risks associated with third-party data or GAI systems deemed high-risk.",
                "parts": [
                  {
                    "id": "GV-6.2-006_smt",
                    "name": "statement",
                    "prose": "Establish acceptable use policies that identify dependencies, potential impacts, and risks associated with third-party data or GAI systems deemed high-risk."
                  }
                ]
              },
              {
                "id": "GV-6.2-007",
                "title": "Establish contingency and communication plans to support fallback alternatives for downstream users in the event the GAI system is disabled.",
                "parts": [
                  {
                    "id": "GV-6.2-007_smt",
                    "name": "statement",
                    "prose": "Establish contingency and communication plans to support fallback alternatives for downstream users in the event the GAI system is disabled."
                  }
                ]
              },
              {
                "id": "GV-6.2-008",
                "title": "Establish incident response plans for third-party GAI technologies deemed high-risk: Align incident response plans with impacts enumerated in MAP 5.1; Communicate third-party GAI incident response plans to all relevant AI actors; Define ownership of GAI incident response functions; Rehearse third-party GAI incident response plans at a regular cadence; Improve incident response plans based on retrospective learning; Review incident response plans for alignment with relevant breach reporting, data protection, data privacy, or other laws.",
                "parts": [
                  {
                    "id": "GV-6.2-008_smt",
                    "name": "statement",
                    "prose": "Establish incident response plans for third-party GAI technologies deemed high-risk: Align incident response plans with impacts enumerated in MAP 5.1; Communicate third-party GAI incident response plans to all relevant AI actors; Define ownership of GAI incident response functions; Rehearse third-party GAI incident response plans at a regular cadence; Improve incident response plans based on retrospective learning; Review incident response plans for alignment with relevant breach reporting, data protection, data privacy, or other laws."
                  }
                ]
              },
              {
                "id": "GV-6.2-009",
                "title": "Establish organizational roles, policies, and procedures for communicating with data and GAI system providers regarding performance, disclosure of GAI system inputs, and use of third-party data and GAI systems.",
                "parts": [
                  {
                    "id": "GV-6.2-009_smt",
                    "name": "statement",
                    "prose": "Establish organizational roles, policies, and procedures for communicating with data and GAI system providers regarding performance, disclosure of GAI system inputs, and use of third-party data and GAI systems."
                  }
                ]
              },
              {
                "id": "GV-6.2-010",
                "title": "Establish policies and procedures for continuous monitoring of third-party GAI systems in deployment.",
                "parts": [
                  {
                    "id": "GV-6.2-010_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures for continuous monitoring of third-party GAI systems in deployment."
                  }
                ]
              },
              {
                "id": "GV-6.2-011",
                "title": "Establish policies and procedures that address GAI data redundancy, including model weights and other system artifacts.",
                "parts": [
                  {
                    "id": "GV-6.2-011_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures that address GAI data redundancy, including model weights and other system artifacts."
                  }
                ]
              },
              {
                "id": "GV-6.2-012",
                "title": "Establish policies and procedures to test and manage risks related to rollover and fallback technologies for GAI systems, acknowledging that rollover and fallback may include manual processing.",
                "parts": [
                  {
                    "id": "GV-6.2-012_smt",
                    "name": "statement",
                    "prose": "Establish policies and procedures to test and manage risks related to rollover and fallback technologies for GAI systems, acknowledging that rollover and fallback may include manual processing."
                  }
                ]
              },
              {
                "id": "GV-6.2-013",
                "title": "Identify and document high-risk third-party GAI technologies in organizational AI inventories, including open-source GAI software.",
                "parts": [
                  {
                    "id": "GV-6.2-013_smt",
                    "name": "statement",
                    "prose": "Identify and document high-risk third-party GAI technologies in organizational AI inventories, including open-source GAI software."
                  }
                ]
              },
              {
                "id": "GV-6.2-014",
                "title": "Review GAI vendor documentation for thorough instructions, meaningful transparency into data or system mechanisms, ample support and contact information, and alignment with organizational principles.",
                "parts": [
                  {
                    "id": "GV-6.2-014_smt",
                    "name": "statement",
                    "prose": "Review GAI vendor documentation for thorough instructions, meaningful transparency into data or system mechanisms, ample support and contact information, and alignment with organizational principles."
                  }
                ]
              },
              {
                "id": "GV-6.2-015",
                "title": "Review GAI vendor release cadences and roadmaps for irregularities and alignment with organizational principles.",
                "parts": [
                  {
                    "id": "GV-6.2-015_smt",
                    "name": "statement",
                    "prose": "Review GAI vendor release cadences and roadmaps for irregularities and alignment with organizational principles."
                  }
                ]
              },
              {
                "id": "GV-6.2-016",
                "title": "Review vendor contracts and avoid arbitrary or capricious termination of critical GAI technologies or vendor services and Non-standard terms that may amplify or defer liability in unexpected ways and Unauthorized data collection by vendors or third-parties (e.g., secondary data use); Consider: Clear assignment of liability and responsibility for incidents, GAI system changes over time (e.g., fine-tuning, drift, decay); Request: Notification and disclosure for serious incidents arising from third-party data and systems, Service line agreements (SLAs) in vendor contracts that address incident response, response times, and availability of critical support.",
                "parts": [
                  {
                    "id": "GV-6.2-016_smt",
                    "name": "statement",
                    "prose": "Review vendor contracts and avoid arbitrary or capricious termination of critical GAI technologies or vendor services and Non-standard terms that may amplify or defer liability in unexpected ways and Unauthorized data collection by vendors or third-parties (e.g., secondary data use); Consider: Clear assignment of liability and responsibility for incidents, GAI system changes over time (e.g., fine-tuning, drift, decay); Request: Notification and disclosure for serious incidents arising from third-party data and systems, Service line agreements (SLAs) in vendor contracts that address incident response, response times, and availability of critical support."
                  }
                ]
              }
            ]
          }
        ]
      },
      {
        "id": "MG",
        "title": "MANAGE",
        "groups": [
          {
            "id": "MG-1.3",
            "title": "Responses to the AI risks deemed high priority, as identified by the MAP function, are developed, planned, and documented.",
            "controls": [
              {
                "id": "MG-1.3-001",
                "title": "Allocate resources and time for GAI risk management activities, including planning for incident response and other mitigation activities.",
                "parts": [
                  {
                    "id": "MG-1.3-001_smt",
                    "name": "statement",
                    "prose": "Allocate resources and time for GAI risk management activities, including planning for incident response and other mitigation activities."
                  }
                ]
              },
              {
                "id": "MG-1.3-002",
                "title": "Document residual GAI system risks that persist after risk mitigation or transfer.",
                "parts": [
                  {
                    "id": "MG-1.3-002_smt",
                    "name": "statement",
                    "prose": "Document residual GAI system risks that persist after risk mitigation or transfer."
                  }
                ]
              },
              {
                "id": "MG-1.3-003",
                "title": "Document trade-offs, decision processes, and relevant measurement and feedback results for risks that do not surpass organizational risk tolerance.",
                "parts": [
                  {
                    "id": "MG-1.3-003_smt",
                    "name": "statement",
                    "prose": "Document trade-offs, decision processes, and relevant measurement and feedback results for risks that do not surpass organizational risk tolerance."
                  }
                ]
              },
              {
                "id": "MG-1.3-004",
                "title": "Mitigate, transfer, or avoid risks that surpass organizational risk tolerances.",
                "parts": [
                  {
                    "id": "MG-1.3-004_smt",
                    "name": "statement",
                    "prose": "Mitigate, transfer, or avoid risks that surpass organizational risk tolerances."
                  }
                ]
              },
              {
                "id": "MG-1.3-005",
                "title": "Monitor the effectiveness of risk controls (e.g., via field testing, participatory engagements, performance assessments, user feedback mechanisms).",
                "parts": [
                  {
                    "id": "MG-1.3-005_smt",
                    "name": "statement",
                    "prose": "Monitor the effectiveness of risk controls (e.g., via field testing, participatory engagements, performance assessments, user feedback mechanisms)."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-2.2",
            "title": "Mechanisms are in place and applied to sustain the value of deployed AI systems.",
            "controls": [
              {
                "id": "MG-2.2-001",
                "title": "Compare GAI system outputs against pre-defined organization risk tolerance, guidelines, and principles, and review and audit AI-generated content against these guidelines.",
                "parts": [
                  {
                    "id": "MG-2.2-001_smt",
                    "name": "statement",
                    "prose": "Compare GAI system outputs against pre-defined organization risk tolerance, guidelines, and principles, and review and audit AI-generated content against these guidelines."
                  }
                ]
              },
              {
                "id": "MG-2.2-002",
                "title": "Document training data sources to trace the origin and provenance of AI-generated content.",
                "parts": [
                  {
                    "id": "MG-2.2-002_smt",
                    "name": "statement",
                    "prose": "Document training data sources to trace the origin and provenance of AI-generated content."
                  }
                ]
              },
              {
                "id": "MG-2.2-003",
                "title": "Evaluate feedback loops between GAI system content provenance and human reviewers, and update where needed. Implement real-time monitoring systems to detect GAI systems and content provenance drift as it happens.",
                "parts": [
                  {
                    "id": "MG-2.2-003_smt",
                    "name": "statement",
                    "prose": "Evaluate feedback loops between GAI system content provenance and human reviewers, and update where needed. Implement real-time monitoring systems to detect GAI systems and content provenance drift as it happens."
                  }
                ]
              },
              {
                "id": "MG-2.2-004",
                "title": "Evaluate GAI content and data for representational biases and employ techniques such as re-sampling, re-ranking, or adversarial training to mitigate biases in the generated content.",
                "parts": [
                  {
                    "id": "MG-2.2-004_smt",
                    "name": "statement",
                    "prose": "Evaluate GAI content and data for representational biases and employ techniques such as re-sampling, re-ranking, or adversarial training to mitigate biases in the generated content."
                  }
                ]
              },
              {
                "id": "MG-2.2-005",
                "title": "Filter GAI output for harmful or biased content, potential misinformation, and CBRN-related or NCII content.",
                "parts": [
                  {
                    "id": "MG-2.2-005_smt",
                    "name": "statement",
                    "prose": "Filter GAI output for harmful or biased content, potential misinformation, and CBRN-related or NCII content."
                  }
                ]
              },
              {
                "id": "MG-2.2-006",
                "title": "Implement version control for models and datasets to track changes and facilitate rollback if necessary.",
                "parts": [
                  {
                    "id": "MG-2.2-006_smt",
                    "name": "statement",
                    "prose": "Implement version control for models and datasets to track changes and facilitate rollback if necessary."
                  }
                ]
              },
              {
                "id": "MG-2.2-007",
                "title": "Incorporate feedback from users, external experts, and the public to adapt the GAI system and monitoring processes.",
                "parts": [
                  {
                    "id": "MG-2.2-007_smt",
                    "name": "statement",
                    "prose": "Incorporate feedback from users, external experts, and the public to adapt the GAI system and monitoring processes."
                  }
                ]
              },
              {
                "id": "MG-2.2-008",
                "title": "Incorporate human review processes to assess and filter content in accordance with the socio-cultural knowledge and values of the context of use, and to identify limitations and nuances that automated processes might miss; verify that human reviewers are trained on content guidelines and potential biases of the GAI system and its content provenance.",
                "parts": [
                  {
                    "id": "MG-2.2-008_smt",
                    "name": "statement",
                    "prose": "Incorporate human review processes to assess and filter content in accordance with the socio-cultural knowledge and values of the context of use, and to identify limitations and nuances that automated processes might miss; verify that human reviewers are trained on content guidelines and potential biases of the GAI system and its content provenance."
                  }
                ]
              },
              {
                "id": "MG-2.2-009",
                "title": "Integrate information from data management and machine learning security countermeasures like red teaming, differential privacy, and authentication protocols to ensure data and models are protected from potential risks.",
                "parts": [
                  {
                    "id": "MG-2.2-009_smt",
                    "name": "statement",
                    "prose": "Integrate information from data management and machine learning security countermeasures like red teaming, differential privacy, and authentication protocols to ensure data and models are protected from potential risks."
                  }
                ]
              },
              {
                "id": "MG-2.2-010",
                "title": "Use feedback from internal and external AI actors, users, individuals, and communities, to assess the impact of AI-generated content.",
                "parts": [
                  {
                    "id": "MG-2.2-010_smt",
                    "name": "statement",
                    "prose": "Use feedback from internal and external AI actors, users, individuals, and communities, to assess the impact of AI-generated content."
                  }
                ]
              },
              {
                "id": "MG-2.2-011",
                "title": "Use real-time auditing tools such as distributed ledger technology to track and validate the lineage and authenticity of AI-generated data.",
                "parts": [
                  {
                    "id": "MG-2.2-011_smt",
                    "name": "statement",
                    "prose": "Use real-time auditing tools such as distributed ledger technology to track and validate the lineage and authenticity of AI-generated data."
                  }
                ]
              },
              {
                "id": "MG-2.2-012",
                "title": "Use structured feedback mechanisms to solicit and capture user input about AI-generated content to detect subtle shifts in quality or alignment with community and societal values.",
                "parts": [
                  {
                    "id": "MG-2.2-012_smt",
                    "name": "statement",
                    "prose": "Use structured feedback mechanisms to solicit and capture user input about AI-generated content to detect subtle shifts in quality or alignment with community and societal values."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-2.3",
            "title": "Procedures are followed to respond to and recover from a previously unknown risk when it is identified.",
            "controls": [
              {
                "id": "MG-2.3-001",
                "title": "Develop and update GAI system incident response and recovery plans and procedures to address the following: Review and maintenance of policies and procedures to account for newly encountered uses; Review and maintenance of policies and procedures for detection of unanticipated uses; Verify response and recovery plans account for the GAI system supply chain; Verify response and recovery plans are updated for and include necessary details to communicate with downstream GAI system actors.",
                "parts": [
                  {
                    "id": "MG-2.3-001_smt",
                    "name": "statement",
                    "prose": "Develop and update GAI system incident response and recovery plans and procedures to address the following: Review and maintenance of policies and procedures to account for newly encountered uses; Review and maintenance of policies and procedures for detection of unanticipated uses; Verify response and recovery plans account for the GAI system supply chain; Verify response and recovery plans are updated for and include necessary details to communicate with downstream GAI system actors."
                  }
                ]
              },
              {
                "id": "MG-2.3-002",
                "title": "Maintain protocols to log changes made to GAI systems during incident response and recovery.",
                "parts": [
                  {
                    "id": "MG-2.3-002_smt",
                    "name": "statement",
                    "prose": "Maintain protocols to log changes made to GAI systems during incident response and recovery."
                  }
                ]
              },
              {
                "id": "MG-2.3-003",
                "title": "Review, update, and maintain incident response and recovery plans to integrate insights from GAI system use cases and contexts and needs of relevant AI actors.",
                "parts": [
                  {
                    "id": "MG-2.3-003_smt",
                    "name": "statement",
                    "prose": "Review, update, and maintain incident response and recovery plans to integrate insights from GAI system use cases and contexts and needs of relevant AI actors."
                  }
                ]
              },
              {
                "id": "MG-2.3-004",
                "title": "Verify and maintain measurements that GAI systems are operating within organizational risk tolerances post-incident.",
                "parts": [
                  {
                    "id": "MG-2.3-004_smt",
                    "name": "statement",
                    "prose": "Verify and maintain measurements that GAI systems are operating within organizational risk tolerances post-incident."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-2.4",
            "title": "Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.",
            "controls": [
              {
                "id": "MG-2.4-001",
                "title": "Enforce change management processes, and risk and impact assessments across all intended uses and contexts before deploying GAI system updates.",
                "parts": [
                  {
                    "id": "MG-2.4-001_smt",
                    "name": "statement",
                    "prose": "Enforce change management processes, and risk and impact assessments across all intended uses and contexts before deploying GAI system updates."
                  }
                ]
              },
              {
                "id": "MG-2.4-002",
                "title": "Establish and maintain communication plans to inform AI stakeholders as part of the deactivation or disengagement process of a specific GAI system or context of use, including reasons, workarounds, user access removal, alternative processes, contact information, etc.",
                "parts": [
                  {
                    "id": "MG-2.4-002_smt",
                    "name": "statement",
                    "prose": "Establish and maintain communication plans to inform AI stakeholders as part of the deactivation or disengagement process of a specific GAI system or context of use, including reasons, workarounds, user access removal, alternative processes, contact information, etc."
                  }
                ]
              },
              {
                "id": "MG-2.4-003",
                "title": "Establish and maintain procedures for escalating GAI system incidents to the organizational risk authority when specific criteria for deactivation or disengagement is met for a particular context of use or for the GAI system as a whole.",
                "parts": [
                  {
                    "id": "MG-2.4-003_smt",
                    "name": "statement",
                    "prose": "Establish and maintain procedures for escalating GAI system incidents to the organizational risk authority when specific criteria for deactivation or disengagement is met for a particular context of use or for the GAI system as a whole."
                  }
                ]
              },
              {
                "id": "MG-2.4-004",
                "title": "Establish and maintain procedures for the remediation of issues which trigger incident response processes for the use of a GAI system, and provide stakeholders timelines associated with the remediation plan.",
                "parts": [
                  {
                    "id": "MG-2.4-004_smt",
                    "name": "statement",
                    "prose": "Establish and maintain procedures for the remediation of issues which trigger incident response processes for the use of a GAI system, and provide stakeholders timelines associated with the remediation plan."
                  }
                ]
              },
              {
                "id": "MG-2.4-005",
                "title": "Establish and regularly review specific criteria that warrants the deactivation of GAI systems in accordance with set risk tolerances and appetites.",
                "parts": [
                  {
                    "id": "MG-2.4-005_smt",
                    "name": "statement",
                    "prose": "Establish and regularly review specific criteria that warrants the deactivation of GAI systems in accordance with set risk tolerances and appetites."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-3.1",
            "title": "AI risks and benefits from third-party resources are regularly monitored, and risk controls are applied and documented.",
            "controls": [
              {
                "id": "MG-3.1-001",
                "title": "Apply organizational risk tolerances and controls (e.g., acquisition and procurement processes; assessing personnel credentials and qualifications, performing background checks; filtering GAI input and outputs, grounding, fine tuning) to third-party GAI resources: Apply organizational risk tolerance to the utilization of third-party datasets and other GAI resources; Apply organizational risk tolerances to fine-tuned third-party models; Apply organizational risk tolerance to existing third-party models adapted to a new domain; Reassess risk measurements after fine-tuning third-party GAI models.",
                "parts": [
                  {
                    "id": "MG-3.1-001_smt",
                    "name": "statement",
                    "prose": "Apply organizational risk tolerances and controls (e.g., acquisition and procurement processes; assessing personnel credentials and qualifications, performing background checks; filtering GAI input and outputs, grounding, fine tuning) to third-party GAI resources: Apply organizational risk tolerance to the utilization of third-party datasets and other GAI resources; Apply organizational risk tolerances to fine-tuned third-party models; Apply organizational risk tolerance to existing third-party models adapted to a new domain; Reassess risk measurements after fine-tuning third-party GAI models."
                  }
                ]
              },
              {
                "id": "MG-3.1-002",
                "title": "Audit GAI system supply chain risks (e.g., data poisoning, malware, other software and hardware vulnerabilities; labor practices; data privacy and localization compliance; geopolitical alignment).",
                "parts": [
                  {
                    "id": "MG-3.1-002_smt",
                    "name": "statement",
                    "prose": "Audit GAI system supply chain risks (e.g., data poisoning, malware, other software and hardware vulnerabilities; labor practices; data privacy and localization compliance; geopolitical alignment)."
                  }
                ]
              },
              {
                "id": "MG-3.1-003",
                "title": "Decommission third-party systems that exceed organizational risk tolerances.",
                "parts": [
                  {
                    "id": "MG-3.1-003_smt",
                    "name": "statement",
                    "prose": "Decommission third-party systems that exceed organizational risk tolerances."
                  }
                ]
              },
              {
                "id": "MG-3.1-004",
                "title": "Identify and maintain documentation for third-party AI systems, and components, in organizational AI inventories.",
                "parts": [
                  {
                    "id": "MG-3.1-004_smt",
                    "name": "statement",
                    "prose": "Identify and maintain documentation for third-party AI systems, and components, in organizational AI inventories."
                  }
                ]
              },
              {
                "id": "MG-3.1-005",
                "title": "Initiate review of third-party organizations/developers prior to their use of GAI models, and during their use of GAI models for their own applications, to monitor for abuse and policy violations.",
                "parts": [
                  {
                    "id": "MG-3.1-005_smt",
                    "name": "statement",
                    "prose": "Initiate review of third-party organizations/developers prior to their use of GAI models, and during their use of GAI models for their own applications, to monitor for abuse and policy violations."
                  }
                ]
              },
              {
                "id": "MG-3.1-006",
                "title": "Re-assess model risks after fine-tuning and for any third-party GAI models deployed for applications and/or use cases that were not evaluated in initial testing.",
                "parts": [
                  {
                    "id": "MG-3.1-006_smt",
                    "name": "statement",
                    "prose": "Re-assess model risks after fine-tuning and for any third-party GAI models deployed for applications and/or use cases that were not evaluated in initial testing."
                  }
                ]
              },
              {
                "id": "MG-3.1-007",
                "title": "Review GAI training data for CBRN information and intellectual property; scan output for plagiarized, trademarked, patented, licensed, or trade secret material.",
                "parts": [
                  {
                    "id": "MG-3.1-007_smt",
                    "name": "statement",
                    "prose": "Review GAI training data for CBRN information and intellectual property; scan output for plagiarized, trademarked, patented, licensed, or trade secret material."
                  }
                ]
              },
              {
                "id": "MG-3.1-008",
                "title": "Update acquisition and procurement policies, procedures, and processes to address GAI risks and failure modes.",
                "parts": [
                  {
                    "id": "MG-3.1-008_smt",
                    "name": "statement",
                    "prose": "Update acquisition and procurement policies, procedures, and processes to address GAI risks and failure modes."
                  }
                ]
              },
              {
                "id": "MG-3.1-009",
                "title": "Use, review, update, and share various transparency artifacts (e.g., system cards and model cards) for third-party models. Document or retain documentation for: Training data content and provenance, methodology, testing, validation, and clear instructions for use from GAI vendors and suppliers, Information related to third-party information security policies, procedures, and processes.",
                "parts": [
                  {
                    "id": "MG-3.1-009_smt",
                    "name": "statement",
                    "prose": "Use, review, update, and share various transparency artifacts (e.g., system cards and model cards) for third-party models. Document or retain documentation for: Training data content and provenance, methodology, testing, validation, and clear instructions for use from GAI vendors and suppliers, Information related to third-party information security policies, procedures, and processes."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-3.2",
            "title": "Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance.",
            "controls": [
              {
                "id": "MG-3.2-001",
                "title": "Apply explainable AI (XAI) techniques (e.g., analysis of embeddings, model compression/distillation, gradient-based attributions, occlusion/term reduction, counterfactual prompts, word clouds) as part of ongoing continuous improvement processes to mitigate risks related to unexplainable GAI systems.",
                "parts": [
                  {
                    "id": "MG-3.2-001_smt",
                    "name": "statement",
                    "prose": "Apply explainable AI (XAI) techniques (e.g., analysis of embeddings, model compression/distillation, gradient-based attributions, occlusion/term reduction, counterfactual prompts, word clouds) as part of ongoing continuous improvement processes to mitigate risks related to unexplainable GAI systems."
                  }
                ]
              },
              {
                "id": "MG-3.2-002",
                "title": "Document how pre-trained models have been adapted (fine-tuned) for the specific generative task, including any data augmentations, parameter adjustments, or other modifications.",
                "parts": [
                  {
                    "id": "MG-3.2-002_smt",
                    "name": "statement",
                    "prose": "Document how pre-trained models have been adapted (fine-tuned) for the specific generative task, including any data augmentations, parameter adjustments, or other modifications."
                  }
                ]
              },
              {
                "id": "MG-3.2-003",
                "title": "Document sources and types of training data and their origins, potential biases present in the data related to the GAI application and its content provenance, architecture, training process of the pre-trained model including information on hyperparameters, training duration, and any fine-tuning processes applied.",
                "parts": [
                  {
                    "id": "MG-3.2-003_smt",
                    "name": "statement",
                    "prose": "Document sources and types of training data and their origins, potential biases present in the data related to the GAI application and its content provenance, architecture, training process of the pre-trained model including information on hyperparameters, training duration, and any fine-tuning processes applied."
                  }
                ]
              },
              {
                "id": "MG-3.2-004",
                "title": "Evaluate user reported problematic content and integrate feedback into system updates.",
                "parts": [
                  {
                    "id": "MG-3.2-004_smt",
                    "name": "statement",
                    "prose": "Evaluate user reported problematic content and integrate feedback into system updates."
                  }
                ]
              },
              {
                "id": "MG-3.2-005",
                "title": "Implement content filters to prevent the generation of inappropriate, harmful, toxic, false, illegal, or violent content related to the GAI application, including for CSAM and NCII.",
                "parts": [
                  {
                    "id": "MG-3.2-005_smt",
                    "name": "statement",
                    "prose": "Implement content filters to prevent the generation of inappropriate, harmful, toxic, false, illegal, or violent content related to the GAI application, including for CSAM and NCII."
                  }
                ]
              },
              {
                "id": "MG-3.2-006",
                "title": "Implement real-time monitoring processes for analyzing generated content performance and trustworthiness characteristics related to content provenance to identify deviations from the desired standards and trigger alerts for human intervention.",
                "parts": [
                  {
                    "id": "MG-3.2-006_smt",
                    "name": "statement",
                    "prose": "Implement real-time monitoring processes for analyzing generated content performance and trustworthiness characteristics related to content provenance to identify deviations from the desired standards and trigger alerts for human intervention."
                  }
                ]
              },
              {
                "id": "MG-3.2-007",
                "title": "Leverage feedback and recommendations from organizational boards or committees related to the deployment of GAI applications and content provenance when using third-party pre-trained models.",
                "parts": [
                  {
                    "id": "MG-3.2-007_smt",
                    "name": "statement",
                    "prose": "Leverage feedback and recommendations from organizational boards or committees related to the deployment of GAI applications and content provenance when using third-party pre-trained models."
                  }
                ]
              },
              {
                "id": "MG-3.2-008",
                "title": "Maintain awareness of relevant laws and regulations related to content generation, data privacy, and user protections and work in conjunction with legal experts to review and assess the potential liabilities associated with AI-generated content.",
                "parts": [
                  {
                    "id": "MG-3.2-008_smt",
                    "name": "statement",
                    "prose": "Maintain awareness of relevant laws and regulations related to content generation, data privacy, and user protections and work in conjunction with legal experts to review and assess the potential liabilities associated with AI-generated content."
                  }
                ]
              },
              {
                "id": "MG-3.2-009",
                "title": "Provide use case examples as material for training employees and stakeholders about the trustworthiness implications of GAI applications and content provenance and to raise awareness about potential risks in fostering a risk management culture.",
                "parts": [
                  {
                    "id": "MG-3.2-009_smt",
                    "name": "statement",
                    "prose": "Provide use case examples as material for training employees and stakeholders about the trustworthiness implications of GAI applications and content provenance and to raise awareness about potential risks in fostering a risk management culture."
                  }
                ]
              },
              {
                "id": "MG-3.2-010",
                "title": "Use human moderation systems to review generated content in accordance with human-AI configuration policies established in the Govern function, aligned with socio-cultural norms in the context of use, and for settings where AI models are demonstrated to perform poorly.",
                "parts": [
                  {
                    "id": "MG-3.2-010_smt",
                    "name": "statement",
                    "prose": "Use human moderation systems to review generated content in accordance with human-AI configuration policies established in the Govern function, aligned with socio-cultural norms in the context of use, and for settings where AI models are demonstrated to perform poorly."
                  }
                ]
              },
              {
                "id": "MG-3.2-011",
                "title": "Use organizational risk tolerance to evaluate acceptable risks and performance metrics and decommission or retrain pre-trained models that perform outside of defined limits.",
                "parts": [
                  {
                    "id": "MG-3.2-011_smt",
                    "name": "statement",
                    "prose": "Use organizational risk tolerance to evaluate acceptable risks and performance metrics and decommission or retrain pre-trained models that perform outside of defined limits."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-4.1",
            "title": "Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI actors, appeal and override, decommissioning, incident response, recovery, and change management.",
            "controls": [
              {
                "id": "MG-4.1-001",
                "title": "Collaborate with external researchers, industry experts, and community representatives to maintain awareness of emerging best practices and technologies in content provenance.",
                "parts": [
                  {
                    "id": "MG-4.1-001_smt",
                    "name": "statement",
                    "prose": "Collaborate with external researchers, industry experts, and community representatives to maintain awareness of emerging best practices and technologies in content provenance."
                  }
                ]
              },
              {
                "id": "MG-4.1-002",
                "title": "Conduct adversarial testing at a regular cadence; test against various adversarial inputs and scenarios; identify vulnerabilities and assess the AI system窶冱 resilience to content provenance attacks.",
                "parts": [
                  {
                    "id": "MG-4.1-002_smt",
                    "name": "statement",
                    "prose": "Conduct adversarial testing at a regular cadence; test against various adversarial inputs and scenarios; identify vulnerabilities and assess the AI system窶冱 resilience to content provenance attacks."
                  }
                ]
              },
              {
                "id": "MG-4.1-003",
                "title": "Conduct red-teaming exercises to surface failure modes of content provenance mechanisms. Evaluate the effectiveness of red-teaming approaches for uncovering potential vulnerabilities and improving overall content provenance.",
                "parts": [
                  {
                    "id": "MG-4.1-003_smt",
                    "name": "statement",
                    "prose": "Conduct red-teaming exercises to surface failure modes of content provenance mechanisms. Evaluate the effectiveness of red-teaming approaches for uncovering potential vulnerabilities and improving overall content provenance."
                  }
                ]
              },
              {
                "id": "MG-4.1-004",
                "title": "Employ user-friendly channels such as feedback forms, e-mails, or hotlines for users to report issues, concerns, or unexpected GAI outputs to feed into monitoring practices.",
                "parts": [
                  {
                    "id": "MG-4.1-004_smt",
                    "name": "statement",
                    "prose": "Employ user-friendly channels such as feedback forms, e-mails, or hotlines for users to report issues, concerns, or unexpected GAI outputs to feed into monitoring practices."
                  }
                ]
              },
              {
                "id": "MG-4.1-005",
                "title": "Establish, maintain, and evaluate the effectiveness of organizational processes and procedures to monitor GAI systems within context of use.",
                "parts": [
                  {
                    "id": "MG-4.1-005_smt",
                    "name": "statement",
                    "prose": "Establish, maintain, and evaluate the effectiveness of organizational processes and procedures to monitor GAI systems within context of use."
                  }
                ]
              },
              {
                "id": "MG-4.1-006",
                "title": "Evaluate the use of sentiment analysis to gauge user sentiment regarding GAI content performance and impact, and work in collaboration with AI actors experienced in user research and experience.",
                "parts": [
                  {
                    "id": "MG-4.1-006_smt",
                    "name": "statement",
                    "prose": "Evaluate the use of sentiment analysis to gauge user sentiment regarding GAI content performance and impact, and work in collaboration with AI actors experienced in user research and experience."
                  }
                ]
              },
              {
                "id": "MG-4.1-007",
                "title": "Implement active learning techniques to identify instances where the model fails or produces unexpected outputs.",
                "parts": [
                  {
                    "id": "MG-4.1-007_smt",
                    "name": "statement",
                    "prose": "Implement active learning techniques to identify instances where the model fails or produces unexpected outputs."
                  }
                ]
              },
              {
                "id": "MG-4.1-008",
                "title": "Integrate digital watermarks, blockchain technology, cryptographic hash functions, metadata embedding, or other content provenance techniques within AI-generated content to track its source and manipulation history.",
                "parts": [
                  {
                    "id": "MG-4.1-008_smt",
                    "name": "statement",
                    "prose": "Integrate digital watermarks, blockchain technology, cryptographic hash functions, metadata embedding, or other content provenance techniques within AI-generated content to track its source and manipulation history."
                  }
                ]
              },
              {
                "id": "MG-4.1-009",
                "title": "Measure system outputs related to content provenance at a regular cadence and integrate insights into monitoring processes.",
                "parts": [
                  {
                    "id": "MG-4.1-009_smt",
                    "name": "statement",
                    "prose": "Measure system outputs related to content provenance at a regular cadence and integrate insights into monitoring processes."
                  }
                ]
              },
              {
                "id": "MG-4.1-010",
                "title": "Monitor GAI training data for representation of different user groups.",
                "parts": [
                  {
                    "id": "MG-4.1-010_smt",
                    "name": "statement",
                    "prose": "Monitor GAI training data for representation of different user groups."
                  }
                ]
              },
              {
                "id": "MG-4.1-011",
                "title": "Perform periodic review of organizational adherence to GAI system monitoring plans across all contexts of use.",
                "parts": [
                  {
                    "id": "MG-4.1-011_smt",
                    "name": "statement",
                    "prose": "Perform periodic review of organizational adherence to GAI system monitoring plans across all contexts of use."
                  }
                ]
              },
              {
                "id": "MG-4.1-012",
                "title": "Share transparency reports with internal and external stakeholders that detail steps taken to update the AI system to enhance transparency and accountability.",
                "parts": [
                  {
                    "id": "MG-4.1-012_smt",
                    "name": "statement",
                    "prose": "Share transparency reports with internal and external stakeholders that detail steps taken to update the AI system to enhance transparency and accountability."
                  }
                ]
              },
              {
                "id": "MG-4.1-013",
                "title": "Track dataset modifications for content provenance by monitoring data deletions, rectification requests, and other changes that may impact the verifiability of content origins.",
                "parts": [
                  {
                    "id": "MG-4.1-013_smt",
                    "name": "statement",
                    "prose": "Track dataset modifications for content provenance by monitoring data deletions, rectification requests, and other changes that may impact the verifiability of content origins."
                  }
                ]
              },
              {
                "id": "MG-4.1-014",
                "title": "Verify risks associated with gaps in GAI system monitoring plans are accepted at the appropriate organizational level.",
                "parts": [
                  {
                    "id": "MG-4.1-014_smt",
                    "name": "statement",
                    "prose": "Verify risks associated with gaps in GAI system monitoring plans are accepted at the appropriate organizational level."
                  }
                ]
              },
              {
                "id": "MG-4.1-015",
                "title": "Verify that AI actors responsible for monitoring reported issues can effectively evaluate GAI system performance and its content provenance, and promptly escalate issues for response.",
                "parts": [
                  {
                    "id": "MG-4.1-015_smt",
                    "name": "statement",
                    "prose": "Verify that AI actors responsible for monitoring reported issues can effectively evaluate GAI system performance and its content provenance, and promptly escalate issues for response."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-4.2",
            "title": "Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI actors.",
            "controls": [
              {
                "id": "MG-4.2-001",
                "title": "Adopt agile development methodologies, and iterative development and feedback loops to allow for rapid adjustments based on external input related to content provenance.",
                "parts": [
                  {
                    "id": "MG-4.2-001_smt",
                    "name": "statement",
                    "prose": "Adopt agile development methodologies, and iterative development and feedback loops to allow for rapid adjustments based on external input related to content provenance."
                  }
                ]
              },
              {
                "id": "MG-4.2-002",
                "title": "Conduct regular audits of GAI systems and publish reports detailing the performance, feedback received, and improvements made.",
                "parts": [
                  {
                    "id": "MG-4.2-002_smt",
                    "name": "statement",
                    "prose": "Conduct regular audits of GAI systems and publish reports detailing the performance, feedback received, and improvements made."
                  }
                ]
              },
              {
                "id": "MG-4.2-003",
                "title": "Employ explainable AI methods to enhance transparency and interpretability of GAI content provenance to help AI actors and stakeholders understand how and why specific content is generated.",
                "parts": [
                  {
                    "id": "MG-4.2-003_smt",
                    "name": "statement",
                    "prose": "Employ explainable AI methods to enhance transparency and interpretability of GAI content provenance to help AI actors and stakeholders understand how and why specific content is generated."
                  }
                ]
              },
              {
                "id": "MG-4.2-004",
                "title": "Employ stakeholder feedback captured in the Map function to understand user experiences and perceptions about AI-generated content and its provenance; include user interactions and feedback from real-world scenarios.",
                "parts": [
                  {
                    "id": "MG-4.2-004_smt",
                    "name": "statement",
                    "prose": "Employ stakeholder feedback captured in the Map function to understand user experiences and perceptions about AI-generated content and its provenance; include user interactions and feedback from real-world scenarios."
                  }
                ]
              },
              {
                "id": "MG-4.2-005",
                "title": "Form cross-functional teams leveraging expertise from across the AI lifecycle including AI designers and developers, socio-technical experts, and experts in the context of use and identify mechanisms to include end users in consultations.",
                "parts": [
                  {
                    "id": "MG-4.2-005_smt",
                    "name": "statement",
                    "prose": "Form cross-functional teams leveraging expertise from across the AI lifecycle including AI designers and developers, socio-technical experts, and experts in the context of use and identify mechanisms to include end users in consultations."
                  }
                ]
              },
              {
                "id": "MG-4.2-006",
                "title": "Practice and follow incident response plans for addressing the generation of inappropriate or harmful content and adapt processes based on findings to prevent future occurrences. Conduct post-mortem analyses of incidents with relevant AI actors, to understand the root causes and implement preventive measures.",
                "parts": [
                  {
                    "id": "MG-4.2-006_smt",
                    "name": "statement",
                    "prose": "Practice and follow incident response plans for addressing the generation of inappropriate or harmful content and adapt processes based on findings to prevent future occurrences. Conduct post-mortem analyses of incidents with relevant AI actors, to understand the root causes and implement preventive measures."
                  }
                ]
              },
              {
                "id": "MG-4.2-007",
                "title": "Provide external stakeholders with regular updates about the progress, challenges, and improvements made based on their feedback through the use of public venues such as online platforms and communities, and open-source initiatives.",
                "parts": [
                  {
                    "id": "MG-4.2-007_smt",
                    "name": "statement",
                    "prose": "Provide external stakeholders with regular updates about the progress, challenges, and improvements made based on their feedback through the use of public venues such as online platforms and communities, and open-source initiatives."
                  }
                ]
              },
              {
                "id": "MG-4.2-008",
                "title": "Simulate various scenarios to test GAI system responses and verify intended performance across different situations.",
                "parts": [
                  {
                    "id": "MG-4.2-008_smt",
                    "name": "statement",
                    "prose": "Simulate various scenarios to test GAI system responses and verify intended performance across different situations."
                  }
                ]
              },
              {
                "id": "MG-4.2-009",
                "title": "Use visualizations to represent the GAI model behavior to ease non-technical stakeholders understanding of GAI system functionality.",
                "parts": [
                  {
                    "id": "MG-4.2-009_smt",
                    "name": "statement",
                    "prose": "Use visualizations to represent the GAI model behavior to ease non-technical stakeholders understanding of GAI system functionality."
                  }
                ]
              }
            ]
          },
          {
            "id": "MG-4.3",
            "title": "Incidents and errors are communicated to relevant AI actors, including affected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented.",
            "controls": [
              {
                "id": "MG-4.3-001",
                "title": "Conduct after-action assessments for GAI system incidents to verify incident response and recovery processes are followed and effective.",
                "parts": [
                  {
                    "id": "MG-4.3-001_smt",
                    "name": "statement",
                    "prose": "Conduct after-action assessments for GAI system incidents to verify incident response and recovery processes are followed and effective."
                  }
                ]
              },
              {
                "id": "MG-4.3-002",
                "title": "Establish and maintain change management records and procedures for GAI systems, including the reasons for each change, how the change could impact each intended context of use, and step-by-step details of how changes were planned, tested, and deployed.",
                "parts": [
                  {
                    "id": "MG-4.3-002_smt",
                    "name": "statement",
                    "prose": "Establish and maintain change management records and procedures for GAI systems, including the reasons for each change, how the change could impact each intended context of use, and step-by-step details of how changes were planned, tested, and deployed."
                  }
                ]
              },
              {
                "id": "MG-4.3-003",
                "title": "Establish and maintain policies and procedures to record and track GAI system reported errors, near-misses, incidents, and negative impacts.",
                "parts": [
                  {
                    "id": "MG-4.3-003_smt",
                    "name": "statement",
                    "prose": "Establish and maintain policies and procedures to record and track GAI system reported errors, near-misses, incidents, and negative impacts."
                  }
                ]
              },
              {
                "id": "MG-4.3-004",
                "title": "Establish processes and procedures for regular sharing of information about incidents and errors with relevant AI actors, including affected communities.",
                "parts": [
                  {
                    "id": "MG-4.3-004_smt",
                    "name": "statement",
                    "prose": "Establish processes and procedures for regular sharing of information about incidents and errors with relevant AI actors, including affected communities."
                  }
                ]
              }
            ]
          }
        ]
      },
      {
        "id": "MP",
        "title": "MAP",
        "groups": [
          {
            "id": "MP-1.1",
            "title": "Intended purposes, potentially beneficial uses, context specific laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented.",
            "controls": [
              {
                "id": "MP-1.1-001",
                "title": "Apply risk mapping and measurement plans to third-party and open-source systems.",
                "parts": [
                  {
                    "id": "MP-1.1-001_smt",
                    "name": "statement",
                    "prose": "Apply risk mapping and measurement plans to third-party and open-source systems."
                  }
                ]
              },
              {
                "id": "MP-1.1-002",
                "title": "Collaborate with domain experts to explore and document gaps, limitations, and risks in pre-deployment testing and the practical and contextual differences between pre-deployment testing and the anticipated context(s) of use.",
                "parts": [
                  {
                    "id": "MP-1.1-002_smt",
                    "name": "statement",
                    "prose": "Collaborate with domain experts to explore and document gaps, limitations, and risks in pre-deployment testing and the practical and contextual differences between pre-deployment testing and the anticipated context(s) of use."
                  }
                ]
              },
              {
                "id": "MP-1.1-003",
                "title": "Conduct impact assessments or review past known incidents and failure modes to prioritize and inform risk measurement.",
                "parts": [
                  {
                    "id": "MP-1.1-003_smt",
                    "name": "statement",
                    "prose": "Conduct impact assessments or review past known incidents and failure modes to prioritize and inform risk measurement."
                  }
                ]
              },
              {
                "id": "MP-1.1-004",
                "title": "Determine and document the expected and acceptable GAI system context of use in collaboration with socio-cultural and other domain experts, by assessing: Assumptions and limitations; Direct value to the organization; Intended operational environment and observed usage patterns; Potential positive and negative impacts to individuals, public safety, groups, communities, organizations, democratic institutions, and the physical environment; Social norms and expectations.",
                "parts": [
                  {
                    "id": "MP-1.1-004_smt",
                    "name": "statement",
                    "prose": "Determine and document the expected and acceptable GAI system context of use in collaboration with socio-cultural and other domain experts, by assessing: Assumptions and limitations; Direct value to the organization; Intended operational environment and observed usage patterns; Potential positive and negative impacts to individuals, public safety, groups, communities, organizations, democratic institutions, and the physical environment; Social norms and expectations."
                  }
                ]
              },
              {
                "id": "MP-1.1-005",
                "title": "Document GAI system ownership, intended use, direct organizational value, and assumptions and limitations.",
                "parts": [
                  {
                    "id": "MP-1.1-005_smt",
                    "name": "statement",
                    "prose": "Document GAI system ownership, intended use, direct organizational value, and assumptions and limitations."
                  }
                ]
              },
              {
                "id": "MP-1.1-006",
                "title": "Document risk measurement plans that address: Individual and group cognitive biases (e.g., confirmation bias, funding bias, groupthink) for AI actors involved in the design, implementation, and use of GAI systems; Known past GAI system incidents and failure modes; In-context use and foreseeable misuse, abuse, and off-label use; Over-reliance on quantitative metrics and methodologies without sufficient awareness of their limitations in the context(s) of use; Risks associated with trustworthy characteristics across the AI lifecycle; Standard measurement and structured human feedback approaches; Anticipated human-AI configurations.",
                "parts": [
                  {
                    "id": "MP-1.1-006_smt",
                    "name": "statement",
                    "prose": "Document risk measurement plans that address: Individual and group cognitive biases (e.g., confirmation bias, funding bias, groupthink) for AI actors involved in the design, implementation, and use of GAI systems; Known past GAI system incidents and failure modes; In-context use and foreseeable misuse, abuse, and off-label use; Over-reliance on quantitative metrics and methodologies without sufficient awareness of their limitations in the context(s) of use; Risks associated with trustworthy characteristics across the AI lifecycle; Standard measurement and structured human feedback approaches; Anticipated human-AI configurations."
                  }
                ]
              },
              {
                "id": "MP-1.1-007",
                "title": "Document risks related to transparency, accountability, explainability, and interpretability in risk measurement plans, system risk assessments, and deployment approval ('go'/'no-go') decisions.",
                "parts": [
                  {
                    "id": "MP-1.1-007_smt",
                    "name": "statement",
                    "prose": "Document risks related to transparency, accountability, explainability, and interpretability in risk measurement plans, system risk assessments, and deployment approval ('go'/'no-go') decisions."
                  }
                ]
              },
              {
                "id": "MP-1.1-008",
                "title": "Document system requirements, ownership, and AI actor roles and responsibilities for human oversight of GAI systems.",
                "parts": [
                  {
                    "id": "MP-1.1-008_smt",
                    "name": "statement",
                    "prose": "Document system requirements, ownership, and AI actor roles and responsibilities for human oversight of GAI systems."
                  }
                ]
              },
              {
                "id": "MP-1.1-009",
                "title": "Document the extent to which a lack of transparency or explainability impedes risk measurement across the AI lifecycle.",
                "parts": [
                  {
                    "id": "MP-1.1-009_smt",
                    "name": "statement",
                    "prose": "Document the extent to which a lack of transparency or explainability impedes risk measurement across the AI lifecycle."
                  }
                ]
              },
              {
                "id": "MP-1.1-010",
                "title": "Identify and document foreseeable illegal uses or applications that surpass organizational risk tolerances.",
                "parts": [
                  {
                    "id": "MP-1.1-010_smt",
                    "name": "statement",
                    "prose": "Identify and document foreseeable illegal uses or applications that surpass organizational risk tolerances."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-1.2",
            "title": "Interdisciplinary AI actors, competencies, skills, and capacities for establishing context reflect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.",
            "controls": [
              {
                "id": "MP-1.2-001",
                "title": "Document the credentials and qualifications of organizational AI actors and AI actor team composition.",
                "parts": [
                  {
                    "id": "MP-1.2-001_smt",
                    "name": "statement",
                    "prose": "Document the credentials and qualifications of organizational AI actors and AI actor team composition."
                  }
                ]
              },
              {
                "id": "MP-1.2-002",
                "title": "Establish and empower interdisciplinary teams that reflect a wide range of capabilities, competencies, demographic groups, domain expertise, educational backgrounds, lived experiences, professions, and skills across the enterprise to inform and conduct TEVV of GAI technology, and other risk measurement and management functions.",
                "parts": [
                  {
                    "id": "MP-1.2-002_smt",
                    "name": "statement",
                    "prose": "Establish and empower interdisciplinary teams that reflect a wide range of capabilities, competencies, demographic groups, domain expertise, educational backgrounds, lived experiences, professions, and skills across the enterprise to inform and conduct TEVV of GAI technology, and other risk measurement and management functions."
                  }
                ]
              },
              {
                "id": "MP-1.2-003",
                "title": "Establish continuous improvement processes to increase diversity and representativeness in AI actor teams, standard measurement resources, and structured public feedback participants from subgroup populations in-context.",
                "parts": [
                  {
                    "id": "MP-1.2-003_smt",
                    "name": "statement",
                    "prose": "Establish continuous improvement processes to increase diversity and representativeness in AI actor teams, standard measurement resources, and structured public feedback participants from subgroup populations in-context."
                  }
                ]
              },
              {
                "id": "MP-1.2-004",
                "title": "Verify that AI actor team membership includes demographic diversity, applicable domain expertise, varied education backgrounds, and lived experiences.",
                "parts": [
                  {
                    "id": "MP-1.2-004_smt",
                    "name": "statement",
                    "prose": "Verify that AI actor team membership includes demographic diversity, applicable domain expertise, varied education backgrounds, and lived experiences."
                  }
                ]
              },
              {
                "id": "MP-1.2-005",
                "title": "Verify that data or benchmarks used in risk measurement, and users, participants, or subjects involved in structured public feedback exercises are representative of diverse in-context user populations.",
                "parts": [
                  {
                    "id": "MP-1.2-005_smt",
                    "name": "statement",
                    "prose": "Verify that data or benchmarks used in risk measurement, and users, participants, or subjects involved in structured public feedback exercises are representative of diverse in-context user populations."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-2.1",
            "title": "The specific tasks and methods used to implement the tasks that the AI system will support are defined (e.g., classifiers, generative models, recommenders).",
            "controls": [
              {
                "id": "MP-2.1-001",
                "title": "Define GAI system's task(s) that relate to content provenance, such as original content creation, media synthesis, or data augmentation while incorporating tracking measures.",
                "parts": [
                  {
                    "id": "MP-2.1-001_smt",
                    "name": "statement",
                    "prose": "Define GAI system's task(s) that relate to content provenance, such as original content creation, media synthesis, or data augmentation while incorporating tracking measures."
                  }
                ]
              },
              {
                "id": "MP-2.1-002",
                "title": "Establish known assumptions and practices for determining data origin and content lineage, for documentation and evaluation.",
                "parts": [
                  {
                    "id": "MP-2.1-002_smt",
                    "name": "statement",
                    "prose": "Establish known assumptions and practices for determining data origin and content lineage, for documentation and evaluation."
                  }
                ]
              },
              {
                "id": "MP-2.1-003",
                "title": "Identify and document GAI task limitations that might impact the reliability or authenticity of the content provenance.",
                "parts": [
                  {
                    "id": "MP-2.1-003_smt",
                    "name": "statement",
                    "prose": "Identify and document GAI task limitations that might impact the reliability or authenticity of the content provenance."
                  }
                ]
              },
              {
                "id": "MP-2.1-004",
                "title": "Institute audit trails for data and content flows within the system, including but not limited to, original data sources, data transformations, and decision-making criteria.",
                "parts": [
                  {
                    "id": "MP-2.1-004_smt",
                    "name": "statement",
                    "prose": "Institute audit trails for data and content flows within the system, including but not limited to, original data sources, data transformations, and decision-making criteria."
                  }
                ]
              },
              {
                "id": "MP-2.1-005",
                "title": "Review efficacy of content provenance techniques on a regular basis and update protocols as necessary.",
                "parts": [
                  {
                    "id": "MP-2.1-005_smt",
                    "name": "statement",
                    "prose": "Review efficacy of content provenance techniques on a regular basis and update protocols as necessary."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-2.2",
            "title": "Information about the AI system窶冱 knowledge limits and how system output may be utilized and overseen by humans is documented.",
            "controls": [
              {
                "id": "MP-2.2-001",
                "title": "Assess whether the GAI system fulfills its intended purpose within its operational context on a regular basis.",
                "parts": [
                  {
                    "id": "MP-2.2-001_smt",
                    "name": "statement",
                    "prose": "Assess whether the GAI system fulfills its intended purpose within its operational context on a regular basis."
                  }
                ]
              },
              {
                "id": "MP-2.2-002",
                "title": "Evaluate whether GAI operators and end-users can accurately understand content lineage and origin.",
                "parts": [
                  {
                    "id": "MP-2.2-002_smt",
                    "name": "statement",
                    "prose": "Evaluate whether GAI operators and end-users can accurately understand content lineage and origin."
                  }
                ]
              },
              {
                "id": "MP-2.2-003",
                "title": "Identify and document how the system relies on upstream data sources for content provenance and if it serves as an upstream dependency for other systems.",
                "parts": [
                  {
                    "id": "MP-2.2-003_smt",
                    "name": "statement",
                    "prose": "Identify and document how the system relies on upstream data sources for content provenance and if it serves as an upstream dependency for other systems."
                  }
                ]
              },
              {
                "id": "MP-2.2-004",
                "title": "Observe and analyze how the AI system interacts with external networks, and identify any potential for negative externalities, particularly where content provenance might be compromised.",
                "parts": [
                  {
                    "id": "MP-2.2-004_smt",
                    "name": "statement",
                    "prose": "Observe and analyze how the AI system interacts with external networks, and identify any potential for negative externalities, particularly where content provenance might be compromised."
                  }
                ]
              },
              {
                "id": "MP-2.2-005",
                "title": "Specify the environments where GAI systems may not function as intended related to content provenance.",
                "parts": [
                  {
                    "id": "MP-2.2-005_smt",
                    "name": "statement",
                    "prose": "Specify the environments where GAI systems may not function as intended related to content provenance."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-2.3",
            "title": "Scientific integrity and TEVV considerations are identified and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation.",
            "controls": [
              {
                "id": "MP-2.3-001",
                "title": "Assess the accuracy, quality, reliability, and authenticity of the GAI content provenance by comparing it to a set of known ground truth data and by using a variety of evaluation methods (e.g., human oversight and automated evaluation).",
                "parts": [
                  {
                    "id": "MP-2.3-001_smt",
                    "name": "statement",
                    "prose": "Assess the accuracy, quality, reliability, and authenticity of the GAI content provenance by comparing it to a set of known ground truth data and by using a variety of evaluation methods (e.g., human oversight and automated evaluation)."
                  }
                ]
              },
              {
                "id": "MP-2.3-002",
                "title": "Curate and maintain high quality datasets that are accurate, relevant, consistent, and representative as well as be well-documented complying with ethical and legal standards along with diverse data points.",
                "parts": [
                  {
                    "id": "MP-2.3-002_smt",
                    "name": "statement",
                    "prose": "Curate and maintain high quality datasets that are accurate, relevant, consistent, and representative as well as be well-documented complying with ethical and legal standards along with diverse data points."
                  }
                ]
              },
              {
                "id": "MP-2.3-003",
                "title": "Deploy and document fact-checking techniques to verify the accuracy and veracity of information generated by GAI systems, especially when the information comes from multiple (or unknown) sources.",
                "parts": [
                  {
                    "id": "MP-2.3-003_smt",
                    "name": "statement",
                    "prose": "Deploy and document fact-checking techniques to verify the accuracy and veracity of information generated by GAI systems, especially when the information comes from multiple (or unknown) sources."
                  }
                ]
              },
              {
                "id": "MP-2.3-004",
                "title": "Design GAI systems to support content provenance such as tracking the lineage (e.g., data sources used to train the system, parameters used to generate content, etc.) and to verify authenticity (e.g., using digital signatures or watermarks).",
                "parts": [
                  {
                    "id": "MP-2.3-004_smt",
                    "name": "statement",
                    "prose": "Design GAI systems to support content provenance such as tracking the lineage (e.g., data sources used to train the system, parameters used to generate content, etc.) and to verify authenticity (e.g., using digital signatures or watermarks)."
                  }
                ]
              },
              {
                "id": "MP-2.3-005",
                "title": "Develop and implement testing techniques to identify any GAI produced content (e.g., synthetic media) that might be indistinguishable from human-generated content.",
                "parts": [
                  {
                    "id": "MP-2.3-005_smt",
                    "name": "statement",
                    "prose": "Develop and implement testing techniques to identify any GAI produced content (e.g., synthetic media) that might be indistinguishable from human-generated content."
                  }
                ]
              },
              {
                "id": "MP-2.3-006",
                "title": "Document GAI content provenance techniques (including experimental methods), testing, evaluation, performance, and validation metrics throughout the AI lifecycle.",
                "parts": [
                  {
                    "id": "MP-2.3-006_smt",
                    "name": "statement",
                    "prose": "Document GAI content provenance techniques (including experimental methods), testing, evaluation, performance, and validation metrics throughout the AI lifecycle."
                  }
                ]
              },
              {
                "id": "MP-2.3-007",
                "title": "Implement plans for GAI systems to undergo regular adversarial testing to identify vulnerabilities and potential manipulation risks.",
                "parts": [
                  {
                    "id": "MP-2.3-007_smt",
                    "name": "statement",
                    "prose": "Implement plans for GAI systems to undergo regular adversarial testing to identify vulnerabilities and potential manipulation risks."
                  }
                ]
              },
              {
                "id": "MP-2.3-008",
                "title": "Integrate GAI systems with existing content management and version control systems, to enable content provenance to be tracked across the lifecycle.",
                "parts": [
                  {
                    "id": "MP-2.3-008_smt",
                    "name": "statement",
                    "prose": "Integrate GAI systems with existing content management and version control systems, to enable content provenance to be tracked across the lifecycle."
                  }
                ]
              },
              {
                "id": "MP-2.3-009",
                "title": "Test GAI models using known inputs, context, and environment to confirm they produce expected outputs across a variety of methods (e.g., unit tests, integration tests, and system tests) and help to identify and address potential problems.",
                "parts": [
                  {
                    "id": "MP-2.3-009_smt",
                    "name": "statement",
                    "prose": "Test GAI models using known inputs, context, and environment to confirm they produce expected outputs across a variety of methods (e.g., unit tests, integration tests, and system tests) and help to identify and address potential problems."
                  }
                ]
              },
              {
                "id": "MP-2.3-010",
                "title": "Use diverse large-scale and small-scale datasets for testing and evaluation to ensure that the AI system can perform well on a variety of different types of data.",
                "parts": [
                  {
                    "id": "MP-2.3-010_smt",
                    "name": "statement",
                    "prose": "Use diverse large-scale and small-scale datasets for testing and evaluation to ensure that the AI system can perform well on a variety of different types of data."
                  }
                ]
              },
              {
                "id": "MP-2.3-011",
                "title": "Verify that GAI content provenance is accurate and reliable by using cryptographic techniques and performing formal audits to ensure it has not been manipulated.",
                "parts": [
                  {
                    "id": "MP-2.3-011_smt",
                    "name": "statement",
                    "prose": "Verify that GAI content provenance is accurate and reliable by using cryptographic techniques and performing formal audits to ensure it has not been manipulated."
                  }
                ]
              },
              {
                "id": "MP-2.3-012",
                "title": "Verify that the AI system窶冱 content provenance complies with relevant laws and regulations, such as legal infringement, terms and conditions, copyright and intellectual property rights, when using data sources and generating content.",
                "parts": [
                  {
                    "id": "MP-2.3-012_smt",
                    "name": "statement",
                    "prose": "Verify that the AI system窶冱 content provenance complies with relevant laws and regulations, such as legal infringement, terms and conditions, copyright and intellectual property rights, when using data sources and generating content."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-3.4",
            "title": "Processes for operator and practitioner proficiency with AI system performance and trustworthiness 窶 and relevant technical standards and certifications 窶 are defined, assessed, and documented.",
            "controls": [
              {
                "id": "MP-3.4-001",
                "title": "Adapt existing training programs to include modules on content provenance.",
                "parts": [
                  {
                    "id": "MP-3.4-001_smt",
                    "name": "statement",
                    "prose": "Adapt existing training programs to include modules on content provenance."
                  }
                ]
              },
              {
                "id": "MP-3.4-002",
                "title": "Develop certification programs that test proficiency in managing AI risks and interpreting content provenance, relevant to specific industry and context.",
                "parts": [
                  {
                    "id": "MP-3.4-002_smt",
                    "name": "statement",
                    "prose": "Develop certification programs that test proficiency in managing AI risks and interpreting content provenance, relevant to specific industry and context."
                  }
                ]
              },
              {
                "id": "MP-3.4-003",
                "title": "Delineate human proficiency tests from tests of AI capabilities.",
                "parts": [
                  {
                    "id": "MP-3.4-003_smt",
                    "name": "statement",
                    "prose": "Delineate human proficiency tests from tests of AI capabilities."
                  }
                ]
              },
              {
                "id": "MP-3.4-004",
                "title": "Integrate human and other qualitative inputs to comprehensively assess content provenance.",
                "parts": [
                  {
                    "id": "MP-3.4-004_smt",
                    "name": "statement",
                    "prose": "Integrate human and other qualitative inputs to comprehensively assess content provenance."
                  }
                ]
              },
              {
                "id": "MP-3.4-005",
                "title": "Ensure that output provided to operators and practitioners is both interactive and well-defined, incorporating content provenance data that can be easily interpreted for effective downstream decision-making.",
                "parts": [
                  {
                    "id": "MP-3.4-005_smt",
                    "name": "statement",
                    "prose": "Ensure that output provided to operators and practitioners is both interactive and well-defined, incorporating content provenance data that can be easily interpreted for effective downstream decision-making."
                  }
                ]
              },
              {
                "id": "MP-3.4-006",
                "title": "Establish and adhere to design principles that ensure safe and ethical operation, taking into account the interpretation of content provenance information.",
                "parts": [
                  {
                    "id": "MP-3.4-006_smt",
                    "name": "statement",
                    "prose": "Establish and adhere to design principles that ensure safe and ethical operation, taking into account the interpretation of content provenance information."
                  }
                ]
              },
              {
                "id": "MP-3.4-007",
                "title": "Implement systems to continually monitor and track the outcomes of human-AI collaborations for future refinement and improvements, integrating a focus on content provenance wherever applicable.",
                "parts": [
                  {
                    "id": "MP-3.4-007_smt",
                    "name": "statement",
                    "prose": "Implement systems to continually monitor and track the outcomes of human-AI collaborations for future refinement and improvements, integrating a focus on content provenance wherever applicable."
                  }
                ]
              },
              {
                "id": "MP-3.4-008",
                "title": "Involve the end-users, practitioners, and operators in AI system prototyping and testing activities. Make sure these tests cover various scenarios where content provenance could play a critical role, such as crisis situations or ethically sensitive contexts.",
                "parts": [
                  {
                    "id": "MP-3.4-008_smt",
                    "name": "statement",
                    "prose": "Involve the end-users, practitioners, and operators in AI system prototyping and testing activities. Make sure these tests cover various scenarios where content provenance could play a critical role, such as crisis situations or ethically sensitive contexts."
                  }
                ]
              },
              {
                "id": "MP-3.4-009",
                "title": "Match the complexity of GAI system explanations and the provenance data to the level of the problem and contextual intricacy.",
                "parts": [
                  {
                    "id": "MP-3.4-009_smt",
                    "name": "statement",
                    "prose": "Match the complexity of GAI system explanations and the provenance data to the level of the problem and contextual intricacy."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-4.1",
            "title": "Approaches for mapping AI technology and legal risks of its components 窶 including the use of third-party data or software 窶 are in place, followed, and documented, as are risks of infringement of a third party窶冱 intellectual property or other rights.",
            "controls": [
              {
                "id": "MP-4.1-001",
                "title": "Conduct audits on third-party processes and personnel including an examination of the third-party窶冱 reputation.",
                "parts": [
                  {
                    "id": "MP-4.1-001_smt",
                    "name": "statement",
                    "prose": "Conduct audits on third-party processes and personnel including an examination of the third-party窶冱 reputation."
                  }
                ]
              },
              {
                "id": "MP-4.1-002",
                "title": "Conduct periodic audits and monitor AI generated content for privacy risks; address any possible instances of sensitive data exposure.",
                "parts": [
                  {
                    "id": "MP-4.1-002_smt",
                    "name": "statement",
                    "prose": "Conduct periodic audits and monitor AI generated content for privacy risks; address any possible instances of sensitive data exposure."
                  }
                ]
              },
              {
                "id": "MP-4.1-003",
                "title": "Consider using synthetic data as applicable to train AI models in place of real-world data to match the statistical properties of real-world data without disclosing personally identifiable information.",
                "parts": [
                  {
                    "id": "MP-4.1-003_smt",
                    "name": "statement",
                    "prose": "Consider using synthetic data as applicable to train AI models in place of real-world data to match the statistical properties of real-world data without disclosing personally identifiable information."
                  }
                ]
              },
              {
                "id": "MP-4.1-004",
                "title": "Develop practices for periodic monitoring of GAI outputs for possible intellectual property infringements and other risks and implement processes for responding to potential intellectual property infringement claims.",
                "parts": [
                  {
                    "id": "MP-4.1-004_smt",
                    "name": "statement",
                    "prose": "Develop practices for periodic monitoring of GAI outputs for possible intellectual property infringements and other risks and implement processes for responding to potential intellectual property infringement claims."
                  }
                ]
              },
              {
                "id": "MP-4.1-005",
                "title": "Document all aspects of the AI development process including data sources, model architectures and training procedures to support reproduction of results, identify any potential problems, and implement mitigation strategies.",
                "parts": [
                  {
                    "id": "MP-4.1-005_smt",
                    "name": "statement",
                    "prose": "Document all aspects of the AI development process including data sources, model architectures and training procedures to support reproduction of results, identify any potential problems, and implement mitigation strategies."
                  }
                ]
              },
              {
                "id": "MP-4.1-006",
                "title": "Document compliance with legal requirements across the AI lifecycle, including copyright concerns, privacy protections.",
                "parts": [
                  {
                    "id": "MP-4.1-006_smt",
                    "name": "statement",
                    "prose": "Document compliance with legal requirements across the AI lifecycle, including copyright concerns, privacy protections."
                  }
                ]
              },
              {
                "id": "MP-4.1-007",
                "title": "Document training data curation policies, including policies to verify that consent was obtained for the likeness or image of individuals.",
                "parts": [
                  {
                    "id": "MP-4.1-007_smt",
                    "name": "statement",
                    "prose": "Document training data curation policies, including policies to verify that consent was obtained for the likeness or image of individuals."
                  }
                ]
              },
              {
                "id": "MP-4.1-008",
                "title": "Employ encryption techniques and proper safeguards to ensure secure data storage and transfer to protect data privacy.",
                "parts": [
                  {
                    "id": "MP-4.1-008_smt",
                    "name": "statement",
                    "prose": "Employ encryption techniques and proper safeguards to ensure secure data storage and transfer to protect data privacy."
                  }
                ]
              },
              {
                "id": "MP-4.1-009",
                "title": "Establish policies for collection, retention, and minimum quality of data, in consideration of the following risks: Disclosure of CBRN information by removing CBRN information from training data, Use of Illegal or dangerous content; Training data imbalance across sub-groups by modality, such as languages for LLMs or skin tone for image generation; Leak of personally identifiable information, including facial likenesses of individuals unless consent is obtained for use of their images.",
                "parts": [
                  {
                    "id": "MP-4.1-009_smt",
                    "name": "statement",
                    "prose": "Establish policies for collection, retention, and minimum quality of data, in consideration of the following risks: Disclosure of CBRN information by removing CBRN information from training data, Use of Illegal or dangerous content; Training data imbalance across sub-groups by modality, such as languages for LLMs or skin tone for image generation; Leak of personally identifiable information, including facial likenesses of individuals unless consent is obtained for use of their images."
                  }
                ]
              },
              {
                "id": "MP-4.1-010",
                "title": "Implement bias mitigation approaches by addressing sources of bias in the training data and by evaluating AI models for bias periodically.",
                "parts": [
                  {
                    "id": "MP-4.1-010_smt",
                    "name": "statement",
                    "prose": "Implement bias mitigation approaches by addressing sources of bias in the training data and by evaluating AI models for bias periodically."
                  }
                ]
              },
              {
                "id": "MP-4.1-011",
                "title": "Implement policies and practices defining how third-party intellectual property and training data will be used, stored, and protected.",
                "parts": [
                  {
                    "id": "MP-4.1-011_smt",
                    "name": "statement",
                    "prose": "Implement policies and practices defining how third-party intellectual property and training data will be used, stored, and protected."
                  }
                ]
              },
              {
                "id": "MP-4.1-012",
                "title": "Implement reproducibility techniques, including: share data publicly or privately using license and citation; develop code according to standard software practices; track and document experiments and results; manage the software environment and dependencies; utilize virtual environments, version control, and maintain a requirements document; manage models and artifacts; tracking AI model versions and documenting model details along with parameters and experimental results; document data management processes and establish a testing/validation process to maintain reliable results.",
                "parts": [
                  {
                    "id": "MP-4.1-012_smt",
                    "name": "statement",
                    "prose": "Implement reproducibility techniques, including: share data publicly or privately using license and citation; develop code according to standard software practices; track and document experiments and results; manage the software environment and dependencies; utilize virtual environments, version control, and maintain a requirements document; manage models and artifacts; tracking AI model versions and documenting model details along with parameters and experimental results; document data management processes and establish a testing/validation process to maintain reliable results."
                  }
                ]
              },
              {
                "id": "MP-4.1-013",
                "title": "Re-evaluate models that were fine-tuned on top of third-party models.",
                "parts": [
                  {
                    "id": "MP-4.1-013_smt",
                    "name": "statement",
                    "prose": "Re-evaluate models that were fine-tuned on top of third-party models."
                  }
                ]
              },
              {
                "id": "MP-4.1-014",
                "title": "Re-evaluate risks when adapting GAI models to new domains.",
                "parts": [
                  {
                    "id": "MP-4.1-014_smt",
                    "name": "statement",
                    "prose": "Re-evaluate risks when adapting GAI models to new domains."
                  }
                ]
              },
              {
                "id": "MP-4.1-015",
                "title": "Review service level agreements and contracts, including license agreements and any legal documents associated with the third-party intellectual properties, technologies, and services.",
                "parts": [
                  {
                    "id": "MP-4.1-015_smt",
                    "name": "statement",
                    "prose": "Review service level agreements and contracts, including license agreements and any legal documents associated with the third-party intellectual properties, technologies, and services."
                  }
                ]
              },
              {
                "id": "MP-4.1-016",
                "title": "Use approaches to detect the presence of sensitive data in generated output text, image, video, or audio, and verify that the model will mask any detected sensitive data.",
                "parts": [
                  {
                    "id": "MP-4.1-016_smt",
                    "name": "statement",
                    "prose": "Use approaches to detect the presence of sensitive data in generated output text, image, video, or audio, and verify that the model will mask any detected sensitive data."
                  }
                ]
              },
              {
                "id": "MP-4.1-017",
                "title": "Use trusted sources for training data that are licensed or open source and ensure that the entity has the legal right for the use of proprietary training data.",
                "parts": [
                  {
                    "id": "MP-4.1-017_smt",
                    "name": "statement",
                    "prose": "Use trusted sources for training data that are licensed or open source and ensure that the entity has the legal right for the use of proprietary training data."
                  }
                ]
              },
              {
                "id": "MP-4.1-018",
                "title": "Apply strong anonymization and de-identification, and/or differential privacy techniques to protect the privacy of individuals in the training data.",
                "parts": [
                  {
                    "id": "MP-4.1-018_smt",
                    "name": "statement",
                    "prose": "Apply strong anonymization and de-identification, and/or differential privacy techniques to protect the privacy of individuals in the training data."
                  }
                ]
              },
              {
                "id": "MP-4.1-019",
                "title": "Verify that third-party models are in compliance with existing use licenses.",
                "parts": [
                  {
                    "id": "MP-4.1-019_smt",
                    "name": "statement",
                    "prose": "Verify that third-party models are in compliance with existing use licenses."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-5.1",
            "title": "Likelihood and magnitude of each identified impact (both potentially beneficial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identified and documented.",
            "controls": [
              {
                "id": "MP-5.1-001",
                "title": "Apply TEVV practices for content provenance (e.g., probing a system's synthetic data generation capabilities for potential misuse or vulnerabilities using zero-knowledge proof approaches).",
                "parts": [
                  {
                    "id": "MP-5.1-001_smt",
                    "name": "statement",
                    "prose": "Apply TEVV practices for content provenance (e.g., probing a system's synthetic data generation capabilities for potential misuse or vulnerabilities using zero-knowledge proof approaches)."
                  }
                ]
              },
              {
                "id": "MP-5.1-002",
                "title": "Assess and document risks related to content provenance. e.g., document the presence, absence, or effectiveness of tagging systems, cryptographic hashes, blockchain-based, or distributed ledger technology solutions that improve content tracking transparency and immutability.",
                "parts": [
                  {
                    "id": "MP-5.1-002_smt",
                    "name": "statement",
                    "prose": "Assess and document risks related to content provenance. e.g., document the presence, absence, or effectiveness of tagging systems, cryptographic hashes, blockchain-based, or distributed ledger technology solutions that improve content tracking transparency and immutability."
                  }
                ]
              },
              {
                "id": "MP-5.1-003",
                "title": "Consider GAI-specific mapped risks (e.g., complex security requirements, potential for emotional entanglement of users, large supply chains) in estimates for likelihood, magnitude of impact and risk.",
                "parts": [
                  {
                    "id": "MP-5.1-003_smt",
                    "name": "statement",
                    "prose": "Consider GAI-specific mapped risks (e.g., complex security requirements, potential for emotional entanglement of users, large supply chains) in estimates for likelihood, magnitude of impact and risk."
                  }
                ]
              },
              {
                "id": "MP-5.1-004",
                "title": "Document estimates of likelihood, magnitude of impact, and risk for GAI systems in a central repository (e.g., organizational AI inventory.).",
                "parts": [
                  {
                    "id": "MP-5.1-004_smt",
                    "name": "statement",
                    "prose": "Document estimates of likelihood, magnitude of impact, and risk for GAI systems in a central repository (e.g., organizational AI inventory.)."
                  }
                ]
              },
              {
                "id": "MP-5.1-005",
                "title": "Enumerate potential impacts related to content provenance, including best-case, average-case, and worst-case scenarios.",
                "parts": [
                  {
                    "id": "MP-5.1-005_smt",
                    "name": "statement",
                    "prose": "Enumerate potential impacts related to content provenance, including best-case, average-case, and worst-case scenarios."
                  }
                ]
              },
              {
                "id": "MP-5.1-006",
                "title": "Estimate likelihood of enumerated impact scenarios using past data or expert judgment, analysis of known public incidents, standard measurement, and structured human feedback results.",
                "parts": [
                  {
                    "id": "MP-5.1-006_smt",
                    "name": "statement",
                    "prose": "Estimate likelihood of enumerated impact scenarios using past data or expert judgment, analysis of known public incidents, standard measurement, and structured human feedback results."
                  }
                ]
              },
              {
                "id": "MP-5.1-007",
                "title": "Measure risk as the product of estimated likelihood and magnitude of impact of a GAI outcome.",
                "parts": [
                  {
                    "id": "MP-5.1-007_smt",
                    "name": "statement",
                    "prose": "Measure risk as the product of estimated likelihood and magnitude of impact of a GAI outcome."
                  }
                ]
              },
              {
                "id": "MP-5.1-008",
                "title": "Prioritize risk acceptance, management, or transfer activities based on risk estimates.",
                "parts": [
                  {
                    "id": "MP-5.1-008_smt",
                    "name": "statement",
                    "prose": "Prioritize risk acceptance, management, or transfer activities based on risk estimates."
                  }
                ]
              },
              {
                "id": "MP-5.1-009",
                "title": "Prioritize standard measurement and structured public feedback processes based on risk assessment estimates.",
                "parts": [
                  {
                    "id": "MP-5.1-009_smt",
                    "name": "statement",
                    "prose": "Prioritize standard measurement and structured public feedback processes based on risk assessment estimates."
                  }
                ]
              },
              {
                "id": "MP-5.1-010",
                "title": "Profile risks arising from GAI systems interacting with, manipulating, or generating content, and outlining known and potential vulnerabilities and the likelihood of their occurrence.",
                "parts": [
                  {
                    "id": "MP-5.1-010_smt",
                    "name": "statement",
                    "prose": "Profile risks arising from GAI systems interacting with, manipulating, or generating content, and outlining known and potential vulnerabilities and the likelihood of their occurrence."
                  }
                ]
              },
              {
                "id": "MP-5.1-011",
                "title": "Scope GAI applications narrowly to enable risk-based governance and controls.",
                "parts": [
                  {
                    "id": "MP-5.1-011_smt",
                    "name": "statement",
                    "prose": "Scope GAI applications narrowly to enable risk-based governance and controls."
                  }
                ]
              }
            ]
          },
          {
            "id": "MP-5.2",
            "title": "Practices and personnel for supporting regular engagement with relevant AI actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.",
            "controls": [
              {
                "id": "MP-5.2-001",
                "title": "Determine context-based measures to identify if new impacts are present due to the GAI system, including regular engagements with downstream AI actors to identify and quantify new contexts of unanticipated impacts of GAI systems.",
                "parts": [
                  {
                    "id": "MP-5.2-001_smt",
                    "name": "statement",
                    "prose": "Determine context-based measures to identify if new impacts are present due to the GAI system, including regular engagements with downstream AI actors to identify and quantify new contexts of unanticipated impacts of GAI systems."
                  }
                ]
              },
              {
                "id": "MP-5.2-002",
                "title": "Plan regular engagements with AI actors responsible for inputs to GAI systems, including third-party data and algorithms, to review and evaluate unanticipated impacts.",
                "parts": [
                  {
                    "id": "MP-5.2-002_smt",
                    "name": "statement",
                    "prose": "Plan regular engagements with AI actors responsible for inputs to GAI systems, including third-party data and algorithms, to review and evaluate unanticipated impacts."
                  }
                ]
              },
              {
                "id": "MP-5.2-003",
                "title": "Publish guidance for external AI actors to report unanticipated impacts of the GAI system and to engage with the organization in the event of GAI system impacts.",
                "parts": [
                  {
                    "id": "MP-5.2-003_smt",
                    "name": "statement",
                    "prose": "Publish guidance for external AI actors to report unanticipated impacts of the GAI system and to engage with the organization in the event of GAI system impacts."
                  }
                ]
              }
            ]
          }
        ]
      },
      {
        "id": "MS",
        "title": "MEASURE",
        "groups": [
          {
            "id": "MS-1.1",
            "title": "Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most significant AI risks.",
            "controls": [
              {
                "id": "MS-1.1-001",
                "title": "Assess the effectiveness of implemented methods and metrics at an ongoing cadence as part of continuous improvement activities.",
                "parts": [
                  {
                    "id": "MS-1.1-001_smt",
                    "name": "statement",
                    "prose": "Assess the effectiveness of implemented methods and metrics at an ongoing cadence as part of continuous improvement activities."
                  }
                ]
              },
              {
                "id": "MS-1.1-002",
                "title": "Collaborate with multidisciplinary experts to ensure the selected risk management approaches are robust and effective.",
                "parts": [
                  {
                    "id": "MS-1.1-002_smt",
                    "name": "statement",
                    "prose": "Collaborate with multidisciplinary experts to ensure the selected risk management approaches are robust and effective."
                  }
                ]
              },
              {
                "id": "MS-1.1-003",
                "title": "Conduct adversarial role-playing exercises, AI red-teaming, or chaos testing to identify anomalous or unforeseen failure modes.",
                "parts": [
                  {
                    "id": "MS-1.1-003_smt",
                    "name": "statement",
                    "prose": "Conduct adversarial role-playing exercises, AI red-teaming, or chaos testing to identify anomalous or unforeseen failure modes."
                  }
                ]
              },
              {
                "id": "MS-1.1-004",
                "title": "Conduct traditional assessment or TEVV exercises to measure the prevalence of known risks in deployment contexts.",
                "parts": [
                  {
                    "id": "MS-1.1-004_smt",
                    "name": "statement",
                    "prose": "Conduct traditional assessment or TEVV exercises to measure the prevalence of known risks in deployment contexts."
                  }
                ]
              },
              {
                "id": "MS-1.1-005",
                "title": "Document GAI risk measurement or tracking approaches, including tracking of risks that cannot be easily measured before deployment (e.g., ecosystem-level risks or risks that unfold over longer time scales).",
                "parts": [
                  {
                    "id": "MS-1.1-005_smt",
                    "name": "statement",
                    "prose": "Document GAI risk measurement or tracking approaches, including tracking of risks that cannot be easily measured before deployment (e.g., ecosystem-level risks or risks that unfold over longer time scales)."
                  }
                ]
              },
              {
                "id": "MS-1.1-006",
                "title": "Employ digital signatures, blockchain technology, and other methods to trace origin and modifications of digital content.",
                "parts": [
                  {
                    "id": "MS-1.1-006_smt",
                    "name": "statement",
                    "prose": "Employ digital signatures, blockchain technology, and other methods to trace origin and modifications of digital content."
                  }
                ]
              },
              {
                "id": "MS-1.1-007",
                "title": "Use similarity metrics, tampering indicators, blockchain confirmation, and other methods to measure content provenance risks.",
                "parts": [
                  {
                    "id": "MS-1.1-007_smt",
                    "name": "statement",
                    "prose": "Use similarity metrics, tampering indicators, blockchain confirmation, and other methods to measure content provenance risks."
                  }
                ]
              },
              {
                "id": "MS-1.1-008",
                "title": "Identify content provenance risks in the AI supply chain, including risks associated with data suppliers and contractors.",
                "parts": [
                  {
                    "id": "MS-1.1-008_smt",
                    "name": "statement",
                    "prose": "Identify content provenance risks in the AI supply chain, including risks associated with data suppliers and contractors."
                  }
                ]
              },
              {
                "id": "MS-1.1-009",
                "title": "Identify potential content provenance risks and harms, such as misinformation, deepfakes, or tampered content.",
                "parts": [
                  {
                    "id": "MS-1.1-009_smt",
                    "name": "statement",
                    "prose": "Identify potential content provenance risks and harms, such as misinformation, deepfakes, or tampered content."
                  }
                ]
              },
              {
                "id": "MS-1.1-010",
                "title": "Implement approaches for measuring AI-related content provenance risks.",
                "parts": [
                  {
                    "id": "MS-1.1-010_smt",
                    "name": "statement",
                    "prose": "Implement approaches for measuring AI-related content provenance risks."
                  }
                ]
              },
              {
                "id": "MS-1.1-011",
                "title": "Integrate tools to detect data anomalies and verify authenticity of digital content.",
                "parts": [
                  {
                    "id": "MS-1.1-011_smt",
                    "name": "statement",
                    "prose": "Integrate tools to detect data anomalies and verify authenticity of digital content."
                  }
                ]
              },
              {
                "id": "MS-1.1-012",
                "title": "Invest in R&D capabilities to evaluate new methods for measuring AI-related risks.",
                "parts": [
                  {
                    "id": "MS-1.1-012_smt",
                    "name": "statement",
                    "prose": "Invest in R&D capabilities to evaluate new methods for measuring AI-related risks."
                  }
                ]
              },
              {
                "id": "MS-1.1-013",
                "title": "Prioritize risk measurement according to risk severity.",
                "parts": [
                  {
                    "id": "MS-1.1-013_smt",
                    "name": "statement",
                    "prose": "Prioritize risk measurement according to risk severity."
                  }
                ]
              },
              {
                "id": "MS-1.1-014",
                "title": "Provide content provenance risk management education to AI actors and stakeholders.",
                "parts": [
                  {
                    "id": "MS-1.1-014_smt",
                    "name": "statement",
                    "prose": "Provide content provenance risk management education to AI actors and stakeholders."
                  }
                ]
              },
              {
                "id": "MS-1.1-015",
                "title": "Track and document risks or opportunities that cannot be measured quantitatively.",
                "parts": [
                  {
                    "id": "MS-1.1-015_smt",
                    "name": "statement",
                    "prose": "Track and document risks or opportunities that cannot be measured quantitatively."
                  }
                ]
              },
              {
                "id": "MS-1.1-016",
                "title": "Track the number of output data items with provenance information.",
                "parts": [
                  {
                    "id": "MS-1.1-016_smt",
                    "name": "statement",
                    "prose": "Track the number of output data items with provenance information."
                  }
                ]
              },
              {
                "id": "MS-1.1-017",
                "title": "Track the number of training and input data items with provenance records.",
                "parts": [
                  {
                    "id": "MS-1.1-017_smt",
                    "name": "statement",
                    "prose": "Track the number of training and input data items with provenance records."
                  }
                ]
              },
              {
                "id": "MS-1.1-018",
                "title": "Track training and input data covered by intellectual property rights.",
                "parts": [
                  {
                    "id": "MS-1.1-018_smt",
                    "name": "statement",
                    "prose": "Track training and input data covered by intellectual property rights."
                  }
                ]
              },
              {
                "id": "MS-1.1-019",
                "title": "Validate the reliability and integrity of the original data and measure dependence on training data.",
                "parts": [
                  {
                    "id": "MS-1.1-019_smt",
                    "name": "statement",
                    "prose": "Validate the reliability and integrity of the original data and measure dependence on training data."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-1.3",
            "title": "Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates.",
            "controls": [
              {
                "id": "MS-1.3-001",
                "title": "Define relevant groups of interest within the context of use as part of plans for gathering structured public feedback.",
                "parts": [
                  {
                    "id": "MS-1.3-001_smt",
                    "name": "statement",
                    "prose": "Define relevant groups of interest within the context of use as part of plans for gathering structured public feedback."
                  }
                ]
              },
              {
                "id": "MS-1.3-002",
                "title": "Define sequence of actions for AI red-teaming exercises and necessary documentation practices.",
                "parts": [
                  {
                    "id": "MS-1.3-002_smt",
                    "name": "statement",
                    "prose": "Define sequence of actions for AI red-teaming exercises and necessary documentation practices."
                  }
                ]
              },
              {
                "id": "MS-1.3-003",
                "title": "Define use cases where structured human feedback exercises would be most beneficial for AI risk measurement.",
                "parts": [
                  {
                    "id": "MS-1.3-003_smt",
                    "name": "statement",
                    "prose": "Define use cases where structured human feedback exercises would be most beneficial for AI risk measurement."
                  }
                ]
              },
              {
                "id": "MS-1.3-004",
                "title": "Develop metrics to evaluate structured feedback results.",
                "parts": [
                  {
                    "id": "MS-1.3-004_smt",
                    "name": "statement",
                    "prose": "Develop metrics to evaluate structured feedback results."
                  }
                ]
              },
              {
                "id": "MS-1.3-005",
                "title": "Execute independent audit, AI red-teaming, or impact assessments with representative AI actors.",
                "parts": [
                  {
                    "id": "MS-1.3-005_smt",
                    "name": "statement",
                    "prose": "Execute independent audit, AI red-teaming, or impact assessments with representative AI actors."
                  }
                ]
              },
              {
                "id": "MS-1.3-006",
                "title": "Identify methods for post-hoc evaluation of the effectiveness of structured feedback processes.",
                "parts": [
                  {
                    "id": "MS-1.3-006_smt",
                    "name": "statement",
                    "prose": "Identify methods for post-hoc evaluation of the effectiveness of structured feedback processes."
                  }
                ]
              },
              {
                "id": "MS-1.3-007",
                "title": "Identify methods for translating structured feedback into AI risk management and continuous improvement processes.",
                "parts": [
                  {
                    "id": "MS-1.3-007_smt",
                    "name": "statement",
                    "prose": "Identify methods for translating structured feedback into AI risk management and continuous improvement processes."
                  }
                ]
              },
              {
                "id": "MS-1.3-008",
                "title": "Identify criteria for determining when structured human feedback exercises are complete.",
                "parts": [
                  {
                    "id": "MS-1.3-008_smt",
                    "name": "statement",
                    "prose": "Identify criteria for determining when structured human feedback exercises are complete."
                  }
                ]
              },
              {
                "id": "MS-1.3-009",
                "title": "Identify mechanisms to evaluate structured human feedback outcomes.",
                "parts": [
                  {
                    "id": "MS-1.3-009_smt",
                    "name": "statement",
                    "prose": "Identify mechanisms to evaluate structured human feedback outcomes."
                  }
                ]
              },
              {
                "id": "MS-1.3-010",
                "title": "Recruit auditors and AI red-teams considering the socio-cultural environment of the expected user base.",
                "parts": [
                  {
                    "id": "MS-1.3-010_smt",
                    "name": "statement",
                    "prose": "Recruit auditors and AI red-teams considering the socio-cultural environment of the expected user base."
                  }
                ]
              },
              {
                "id": "MS-1.3-011",
                "title": "Share structured feedback with relevant AI actors to address identified risks.",
                "parts": [
                  {
                    "id": "MS-1.3-011_smt",
                    "name": "statement",
                    "prose": "Share structured feedback with relevant AI actors to address identified risks."
                  }
                ]
              },
              {
                "id": "MS-1.3-012",
                "title": "Verify demographic diversity in structured feedback exercises.",
                "parts": [
                  {
                    "id": "MS-1.3-012_smt",
                    "name": "statement",
                    "prose": "Verify demographic diversity in structured feedback exercises."
                  }
                ]
              },
              {
                "id": "MS-1.3-013",
                "title": "Verify those conducting structured human feedback exercises are not directly involved in system development.",
                "parts": [
                  {
                    "id": "MS-1.3-013_smt",
                    "name": "statement",
                    "prose": "Verify those conducting structured human feedback exercises are not directly involved in system development."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.10",
            "title": "AI system output and performance are transparent and can be explained and demonstrated to individuals and teams responsible for monitoring, testing, evaluating, validating, or auditing the AI system.",
            "controls": [
              {
                "id": "MS-2.10-001",
                "title": "Document the techniques, processes, and algorithms used in the AI system that affect its output performance for auditability and accountability.",
                "parts": [
                  {
                    "id": "MS-2.10-001_smt",
                    "name": "statement",
                    "prose": "Document the techniques, processes, and algorithms used in the AI system that affect its output performance for auditability and accountability."
                  }
                ]
              },
              {
                "id": "MS-2.10-002",
                "title": "Ensure human decision-makers have access to system-generated information, including explanations of why certain results or actions were suggested.",
                "parts": [
                  {
                    "id": "MS-2.10-002_smt",
                    "name": "statement",
                    "prose": "Ensure human decision-makers have access to system-generated information, including explanations of why certain results or actions were suggested."
                  }
                ]
              },
              {
                "id": "MS-2.10-003",
                "title": "Include explainability metrics in performance evaluations, ensuring that the AI system窶冱 outputs can be understood by relevant stakeholders.",
                "parts": [
                  {
                    "id": "MS-2.10-003_smt",
                    "name": "statement",
                    "prose": "Include explainability metrics in performance evaluations, ensuring that the AI system窶冱 outputs can be understood by relevant stakeholders."
                  }
                ]
              },
              {
                "id": "MS-2.10-004",
                "title": "Measure system transparency by testing how easily human reviewers can trace output decisions to specific inputs or rules.",
                "parts": [
                  {
                    "id": "MS-2.10-004_smt",
                    "name": "statement",
                    "prose": "Measure system transparency by testing how easily human reviewers can trace output decisions to specific inputs or rules."
                  }
                ]
              },
              {
                "id": "MS-2.10-005",
                "title": "Provide audit logs for any decision-making process implemented by the AI system to ensure accountability.",
                "parts": [
                  {
                    "id": "MS-2.10-005_smt",
                    "name": "statement",
                    "prose": "Provide audit logs for any decision-making process implemented by the AI system to ensure accountability."
                  }
                ]
              },
              {
                "id": "MS-2.10-006",
                "title": "Provide clear documentation on how AI system parameters and configurations affect performance and outcomes.",
                "parts": [
                  {
                    "id": "MS-2.10-006_smt",
                    "name": "statement",
                    "prose": "Provide clear documentation on how AI system parameters and configurations affect performance and outcomes."
                  }
                ]
              },
              {
                "id": "MS-2.10-007",
                "title": "Regularly test the AI system's ability to generate explanations that align with its decision-making processes.",
                "parts": [
                  {
                    "id": "MS-2.10-007_smt",
                    "name": "statement",
                    "prose": "Regularly test the AI system's ability to generate explanations that align with its decision-making processes."
                  }
                ]
              },
              {
                "id": "MS-2.10-008",
                "title": "Track the AI system's performance over time, comparing outcomes against explainability measures to identify discrepancies.",
                "parts": [
                  {
                    "id": "MS-2.10-008_smt",
                    "name": "statement",
                    "prose": "Track the AI system's performance over time, comparing outcomes against explainability measures to identify discrepancies."
                  }
                ]
              },
              {
                "id": "MS-2.10-009",
                "title": "Verify that the AI system can generate explanations in multiple formats to suit the needs of different stakeholders (e.g., technical and non-technical).",
                "parts": [
                  {
                    "id": "MS-2.10-009_smt",
                    "name": "statement",
                    "prose": "Verify that the AI system can generate explanations in multiple formats to suit the needs of different stakeholders (e.g., technical and non-technical)."
                  }
                ]
              },
              {
                "id": "MS-2.10-010",
                "title": "Verify that users can interrogate system outputs to understand why specific results were produced, including the role of inputs, parameters, and algorithms.",
                "parts": [
                  {
                    "id": "MS-2.10-010_smt",
                    "name": "statement",
                    "prose": "Verify that users can interrogate system outputs to understand why specific results were produced, including the role of inputs, parameters, and algorithms."
                  }
                ]
              },
              {
                "id": "MS-2.10-011",
                "title": "Work with domain experts to define appropriate explanations that align with the system's decision-making context and domain requirements.",
                "parts": [
                  {
                    "id": "MS-2.10-011_smt",
                    "name": "statement",
                    "prose": "Work with domain experts to define appropriate explanations that align with the system's decision-making context and domain requirements."
                  }
                ]
              },
              {
                "id": "MS-2.10-012",
                "title": "Work with relevant stakeholders to ensure that any explanations provided by the AI system are useful and actionable for system monitoring, auditing, and accountability purposes.",
                "parts": [
                  {
                    "id": "MS-2.10-012_smt",
                    "name": "statement",
                    "prose": "Work with relevant stakeholders to ensure that any explanations provided by the AI system are useful and actionable for system monitoring, auditing, and accountability purposes."
                  }
                ]
              },
              {
                "id": "MS-2.10-013",
                "title": "Use external assessments, including explainability benchmarks, to validate the quality and relevance of system explanations.",
                "parts": [
                  {
                    "id": "MS-2.10-013_smt",
                    "name": "statement",
                    "prose": "Use external assessments, including explainability benchmarks, to validate the quality and relevance of system explanations."
                  }
                ]
              },
              {
                "id": "MS-2.10-014",
                "title": "Verify that any changes in the AI system are accompanied by updated explanations and documentation to maintain transparency over time.",
                "parts": [
                  {
                    "id": "MS-2.10-014_smt",
                    "name": "statement",
                    "prose": "Verify that any changes in the AI system are accompanied by updated explanations and documentation to maintain transparency over time."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.11",
            "title": "Fairness and bias 窶 as identified in the MAP function 窶 are evaluated and results are documented.",
            "controls": [
              {
                "id": "MS-2.11-001",
                "title": "Apply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real Toxicity Prompts, Winogender) to quantify systemic bias, stereotyping, denigration, and toxicity in GAI system outputs; Document assumptions and limitations of benchmarks relative to in-context deployment environment.",
                "parts": [
                  {
                    "id": "MS-2.11-001_smt",
                    "name": "statement",
                    "prose": "Apply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real Toxicity Prompts, Winogender) to quantify systemic bias, stereotyping, denigration, and toxicity in GAI system outputs; Document assumptions and limitations of benchmarks relative to in-context deployment environment."
                  }
                ]
              },
              {
                "id": "MS-2.11-002",
                "title": "Assess content moderation and other output filtering technologies or processes for risks arising from human, systemic, and statistical/computational biases.",
                "parts": [
                  {
                    "id": "MS-2.11-002_smt",
                    "name": "statement",
                    "prose": "Assess content moderation and other output filtering technologies or processes for risks arising from human, systemic, and statistical/computational biases."
                  }
                ]
              },
              {
                "id": "MS-2.11-003",
                "title": "Conduct fairness assessments to measure systemic bias. Measure GAI system performance across demographic groups and subgroups, addressing both quality of service and any allocation of services and resources. Identify types of harms, including harms in resource allocation, representational, quality of service, stereotyping, or erasure.",
                "parts": [
                  {
                    "id": "MS-2.11-003_smt",
                    "name": "statement",
                    "prose": "Conduct fairness assessments to measure systemic bias. Measure GAI system performance across demographic groups and subgroups, addressing both quality of service and any allocation of services and resources. Identify types of harms, including harms in resource allocation, representational, quality of service, stereotyping, or erasure."
                  }
                ]
              },
              {
                "id": "MS-2.11-004",
                "title": "Evaluate practices along the lifecycle to identify potential sources of human-cognitive bias such as availability, observational, groupthink, funding, and confirmation bias, and to make implicit decision-making processes more explicit and open to investigation.",
                "parts": [
                  {
                    "id": "MS-2.11-004_smt",
                    "name": "statement",
                    "prose": "Evaluate practices along the lifecycle to identify potential sources of human-cognitive bias such as availability, observational, groupthink, funding, and confirmation bias, and to make implicit decision-making processes more explicit and open to investigation."
                  }
                ]
              },
              {
                "id": "MS-2.11-005",
                "title": "Identify the classes of individuals, groups, or environmental ecosystems which might be impacted by GAI systems through direct engagement with potentially impacted communities.",
                "parts": [
                  {
                    "id": "MS-2.11-005_smt",
                    "name": "statement",
                    "prose": "Identify the classes of individuals, groups, or environmental ecosystems which might be impacted by GAI systems through direct engagement with potentially impacted communities."
                  }
                ]
              },
              {
                "id": "MS-2.11-006",
                "title": "Monitor for representational, financial, or other harms after GAI systems are deployed.",
                "parts": [
                  {
                    "id": "MS-2.11-006_smt",
                    "name": "statement",
                    "prose": "Monitor for representational, financial, or other harms after GAI systems are deployed."
                  }
                ]
              },
              {
                "id": "MS-2.11-007",
                "title": "Review, document, and measure sources of bias in training and TEVV data: Differences in distributions of outcomes across and within groups, including intersecting groups.",
                "parts": [
                  {
                    "id": "MS-2.11-007_smt",
                    "name": "statement",
                    "prose": "Review, document, and measure sources of bias in training and TEVV data: Differences in distributions of outcomes across and within groups, including intersecting groups."
                  }
                ]
              },
              {
                "id": "MS-2.11-008",
                "title": "Track and document AI actor credentials and qualifications.",
                "parts": [
                  {
                    "id": "MS-2.11-008_smt",
                    "name": "statement",
                    "prose": "Track and document AI actor credentials and qualifications."
                  }
                ]
              },
              {
                "id": "MS-2.11-009",
                "title": "Verify accessibility functionality; verify functionality and timeliness of accommodations and opt-out functionality or processes.",
                "parts": [
                  {
                    "id": "MS-2.11-009_smt",
                    "name": "statement",
                    "prose": "Verify accessibility functionality; verify functionality and timeliness of accommodations and opt-out functionality or processes."
                  }
                ]
              },
              {
                "id": "MS-2.11-010",
                "title": "Verify bias management in periodic model updates; test and recalibrate with updated and more representative data to manage bias within acceptable tolerances.",
                "parts": [
                  {
                    "id": "MS-2.11-010_smt",
                    "name": "statement",
                    "prose": "Verify bias management in periodic model updates; test and recalibrate with updated and more representative data to manage bias within acceptable tolerances."
                  }
                ]
              },
              {
                "id": "MS-2.11-011",
                "title": "Verify training is not homogenous GAI-produced data in order to mitigate concerns of model collapse.",
                "parts": [
                  {
                    "id": "MS-2.11-011_smt",
                    "name": "statement",
                    "prose": "Verify training is not homogenous GAI-produced data in order to mitigate concerns of model collapse."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.12",
            "title": "Environmental impact and sustainability of AI model training and management activities 窶 as identified in the MAP function 窶 are assessed and documented.",
            "controls": [
              {
                "id": "MS-2.12-001",
                "title": "Assess safety to physical environments when deploying GAI systems.",
                "parts": [
                  {
                    "id": "MS-2.12-001_smt",
                    "name": "statement",
                    "prose": "Assess safety to physical environments when deploying GAI systems."
                  }
                ]
              },
              {
                "id": "MS-2.12-002",
                "title": "Document anticipated environmental impacts of model development, maintenance, and deployment in product design decisions.",
                "parts": [
                  {
                    "id": "MS-2.12-002_smt",
                    "name": "statement",
                    "prose": "Document anticipated environmental impacts of model development, maintenance, and deployment in product design decisions."
                  }
                ]
              },
              {
                "id": "MS-2.12-003",
                "title": "Measure or estimate environmental impacts (e.g., energy and water consumption) for training, fine tuning, and deploying models: Verify tradeoffs between resources used at inference time versus additional resources required at training time.",
                "parts": [
                  {
                    "id": "MS-2.12-003_smt",
                    "name": "statement",
                    "prose": "Measure or estimate environmental impacts (e.g., energy and water consumption) for training, fine tuning, and deploying models: Verify tradeoffs between resources used at inference time versus additional resources required at training time."
                  }
                ]
              },
              {
                "id": "MS-2.12-004",
                "title": "Track and document continuous improvement processes that enhance effectiveness of risk measurement for GAI environmental impacts and sustainability.",
                "parts": [
                  {
                    "id": "MS-2.12-004_smt",
                    "name": "statement",
                    "prose": "Track and document continuous improvement processes that enhance effectiveness of risk measurement for GAI environmental impacts and sustainability."
                  }
                ]
              },
              {
                "id": "MS-2.12-005",
                "title": "Verify effectiveness of carbon capture or offset programs, and address green-washing risks.",
                "parts": [
                  {
                    "id": "MS-2.12-005_smt",
                    "name": "statement",
                    "prose": "Verify effectiveness of carbon capture or offset programs, and address green-washing risks."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.13",
            "title": "Effectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented.",
            "controls": [
              {
                "id": "MS-2.13-001",
                "title": "Create measurement error models for pre-deployment metrics to demonstrate construct validity for each metric (i.e., does the metric effectively operationalize the desired concept): Measure or estimate, and document, biases or statistical variance in applied metrics or structured human feedback processes.",
                "parts": [
                  {
                    "id": "MS-2.13-001_smt",
                    "name": "statement",
                    "prose": "Create measurement error models for pre-deployment metrics to demonstrate construct validity for each metric (i.e., does the metric effectively operationalize the desired concept): Measure or estimate, and document, biases or statistical variance in applied metrics or structured human feedback processes."
                  }
                ]
              },
              {
                "id": "MS-2.13-002",
                "title": "Document measurement and structured public feedback processes applied to organizational GAI systems in a centralized repository (i.e., organizational AI inventory).",
                "parts": [
                  {
                    "id": "MS-2.13-002_smt",
                    "name": "statement",
                    "prose": "Document measurement and structured public feedback processes applied to organizational GAI systems in a centralized repository (i.e., organizational AI inventory)."
                  }
                ]
              },
              {
                "id": "MS-2.13-003",
                "title": "Review GAI system metrics and associated pre-deployment processes to determine their ability to sustain system improvements, including the identification and removal of errors, harms, and negative impacts.",
                "parts": [
                  {
                    "id": "MS-2.13-003_smt",
                    "name": "statement",
                    "prose": "Review GAI system metrics and associated pre-deployment processes to determine their ability to sustain system improvements, including the identification and removal of errors, harms, and negative impacts."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.2",
            "title": "Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.",
            "controls": [
              {
                "id": "MS-2.2-001",
                "title": "Assess and manage statistical biases related to GAI content provenance through techniques such as re-sampling, re-weighting, or adversarial training.",
                "parts": [
                  {
                    "id": "MS-2.2-001_smt",
                    "name": "statement",
                    "prose": "Assess and manage statistical biases related to GAI content provenance through techniques such as re-sampling, re-weighting, or adversarial training."
                  }
                ]
              },
              {
                "id": "MS-2.2-002",
                "title": "Disaggregate evaluation metrics by demographic factors to identify any discrepancies in how content provenance mechanisms work across diverse populations.",
                "parts": [
                  {
                    "id": "MS-2.2-002_smt",
                    "name": "statement",
                    "prose": "Disaggregate evaluation metrics by demographic factors to identify any discrepancies in how content provenance mechanisms work across diverse populations."
                  }
                ]
              },
              {
                "id": "MS-2.2-003",
                "title": "Document how content provenance mechanisms are operated in the context of privacy and security including: Anonymize data to protect the privacy of human subjects; Remove any personally identifiable information (PII) to prevent potential harm or misuse.",
                "parts": [
                  {
                    "id": "MS-2.2-003_smt",
                    "name": "statement",
                    "prose": "Document how content provenance mechanisms are operated in the context of privacy and security including: Anonymize data to protect the privacy of human subjects; Remove any personally identifiable information (PII) to prevent potential harm or misuse."
                  }
                ]
              },
              {
                "id": "MS-2.2-004",
                "title": "Employ techniques like chaos engineering and stakeholder feedback to evaluate the quality and integrity of data used in training and the provenance of AI-generated content.",
                "parts": [
                  {
                    "id": "MS-2.2-004_smt",
                    "name": "statement",
                    "prose": "Employ techniques like chaos engineering and stakeholder feedback to evaluate the quality and integrity of data used in training and the provenance of AI-generated content."
                  }
                ]
              },
              {
                "id": "MS-2.2-005",
                "title": "Identify biases present in the training data for downstream mitigation using available techniques (e.g., data visualization tools).",
                "parts": [
                  {
                    "id": "MS-2.2-005_smt",
                    "name": "statement",
                    "prose": "Identify biases present in the training data for downstream mitigation using available techniques (e.g., data visualization tools)."
                  }
                ]
              },
              {
                "id": "MS-2.2-006",
                "title": "Implement continuous monitoring of GAI system impacts to identify whether GAI outputs are equitable across various sub-populations. Seek active and direct feedback from affected communities to identify issues and improve GAI system fairness.",
                "parts": [
                  {
                    "id": "MS-2.2-006_smt",
                    "name": "statement",
                    "prose": "Implement continuous monitoring of GAI system impacts to identify whether GAI outputs are equitable across various sub-populations. Seek active and direct feedback from affected communities to identify issues and improve GAI system fairness."
                  }
                ]
              },
              {
                "id": "MS-2.2-007",
                "title": "Implement robust cybersecurity measures to protect both the research data, the GAI system and its content provenance from unauthorized access, breaches, or tampering and unauthorized disclosure of human subject information.",
                "parts": [
                  {
                    "id": "MS-2.2-007_smt",
                    "name": "statement",
                    "prose": "Implement robust cybersecurity measures to protect both the research data, the GAI system and its content provenance from unauthorized access, breaches, or tampering and unauthorized disclosure of human subject information."
                  }
                ]
              },
              {
                "id": "MS-2.2-008",
                "title": "Obtain informed consent from human subject evaluation participants. Informed consent should include: the nature of the study, information about the use of GAI related to content provenance, its purpose, and potential implications.",
                "parts": [
                  {
                    "id": "MS-2.2-008_smt",
                    "name": "statement",
                    "prose": "Obtain informed consent from human subject evaluation participants. Informed consent should include: the nature of the study, information about the use of GAI related to content provenance, its purpose, and potential implications."
                  }
                ]
              },
              {
                "id": "MS-2.2-010",
                "title": "Practice responsible disclosure of findings and report discovered vulnerabilities or biases related to GAI systems and its content provenance.",
                "parts": [
                  {
                    "id": "MS-2.2-010_smt",
                    "name": "statement",
                    "prose": "Practice responsible disclosure of findings and report discovered vulnerabilities or biases related to GAI systems and its content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.2-011",
                "title": "Provide human subjects with options to revoke their consent for future use of their data in GAI applications, particularly in content provenance aspects.",
                "parts": [
                  {
                    "id": "MS-2.2-011_smt",
                    "name": "statement",
                    "prose": "Provide human subjects with options to revoke their consent for future use of their data in GAI applications, particularly in content provenance aspects."
                  }
                ]
              },
              {
                "id": "MS-2.2-012",
                "title": "Use Institutional Review Boards as applicable for evaluations that involve human subjects.",
                "parts": [
                  {
                    "id": "MS-2.2-012_smt",
                    "name": "statement",
                    "prose": "Use Institutional Review Boards as applicable for evaluations that involve human subjects."
                  }
                ]
              },
              {
                "id": "MS-2.2-013",
                "title": "Use techniques such as anonymization or differential privacy to minimize the risks associated with linking AI-generated content back to individual human subjects.",
                "parts": [
                  {
                    "id": "MS-2.2-013_smt",
                    "name": "statement",
                    "prose": "Use techniques such as anonymization or differential privacy to minimize the risks associated with linking AI-generated content back to individual human subjects."
                  }
                ]
              },
              {
                "id": "MS-2.2-014",
                "title": "Verify accountability and fairness through documentation of the algorithms, parameters, and methodologies used in the evaluation to allow for external scrutiny.",
                "parts": [
                  {
                    "id": "MS-2.2-014_smt",
                    "name": "statement",
                    "prose": "Verify accountability and fairness through documentation of the algorithms, parameters, and methodologies used in the evaluation to allow for external scrutiny."
                  }
                ]
              },
              {
                "id": "MS-2.2-015",
                "title": "Verify that human subjects selected for evaluation are representative of the population for the relevant GAI use-case; Consider demographics such as age, gender, race, ethnicity, socioeconomic status, and geographical location to avoid biases in the AI system related to content provenance.",
                "parts": [
                  {
                    "id": "MS-2.2-015_smt",
                    "name": "statement",
                    "prose": "Verify that human subjects selected for evaluation are representative of the population for the relevant GAI use-case; Consider demographics such as age, gender, race, ethnicity, socioeconomic status, and geographical location to avoid biases in the AI system related to content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.2-016",
                "title": "Work in close collaboration with domain experts to understand the specific requirements and potential pitfalls related to content provenance in the GAI system's intended context of use.",
                "parts": [
                  {
                    "id": "MS-2.2-016_smt",
                    "name": "statement",
                    "prose": "Work in close collaboration with domain experts to understand the specific requirements and potential pitfalls related to content provenance in the GAI system's intended context of use."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.3",
            "title": "AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.",
            "controls": [
              {
                "id": "MS-2.3-001",
                "title": "Analyze differences between intended and actual population of users or data subjects, including likelihood for errors, incidents, or negative impacts.",
                "parts": [
                  {
                    "id": "MS-2.3-001_smt",
                    "name": "statement",
                    "prose": "Analyze differences between intended and actual population of users or data subjects, including likelihood for errors, incidents, or negative impacts."
                  }
                ]
              },
              {
                "id": "MS-2.3-002",
                "title": "Conduct field testing on sampled sub-populations prior to deployment to the entire population.",
                "parts": [
                  {
                    "id": "MS-2.3-002_smt",
                    "name": "statement",
                    "prose": "Conduct field testing on sampled sub-populations prior to deployment to the entire population."
                  }
                ]
              },
              {
                "id": "MS-2.3-003",
                "title": "Conduct TEVV in the operational environment in accordance with organizational policies and regulatory or disciplinary requirements (e.g., informed consent, institutional review board approval, human research protections, privacy requirements).",
                "parts": [
                  {
                    "id": "MS-2.3-003_smt",
                    "name": "statement",
                    "prose": "Conduct TEVV in the operational environment in accordance with organizational policies and regulatory or disciplinary requirements (e.g., informed consent, institutional review board approval, human research protections, privacy requirements)."
                  }
                ]
              },
              {
                "id": "MS-2.3-004",
                "title": "Consider baseline model performance on suites of benchmarks when selecting a model for fine tuning.",
                "parts": [
                  {
                    "id": "MS-2.3-004_smt",
                    "name": "statement",
                    "prose": "Consider baseline model performance on suites of benchmarks when selecting a model for fine tuning."
                  }
                ]
              },
              {
                "id": "MS-2.3-005",
                "title": "Evaluate claims of model capabilities using empirically validated methods.",
                "parts": [
                  {
                    "id": "MS-2.3-005_smt",
                    "name": "statement",
                    "prose": "Evaluate claims of model capabilities using empirically validated methods."
                  }
                ]
              },
              {
                "id": "MS-2.3-006",
                "title": "Include metrics measuring reporting rates for harmful or offensive content in field testing.",
                "parts": [
                  {
                    "id": "MS-2.3-006_smt",
                    "name": "statement",
                    "prose": "Include metrics measuring reporting rates for harmful or offensive content in field testing."
                  }
                ]
              },
              {
                "id": "MS-2.3-007",
                "title": "Share results of pre-deployment testing with relevant AI actors, such as those with system release approval authority.",
                "parts": [
                  {
                    "id": "MS-2.3-007_smt",
                    "name": "statement",
                    "prose": "Share results of pre-deployment testing with relevant AI actors, such as those with system release approval authority."
                  }
                ]
              },
              {
                "id": "MS-2.3-008",
                "title": "Use disaggregated evaluation methods (e.g., by race, age, gender, ethnicity, ability, region) to improve granularity of AI system performance measures.",
                "parts": [
                  {
                    "id": "MS-2.3-008_smt",
                    "name": "statement",
                    "prose": "Use disaggregated evaluation methods (e.g., by race, age, gender, ethnicity, ability, region) to improve granularity of AI system performance measures."
                  }
                ]
              },
              {
                "id": "MS-2.3-009",
                "title": "Utilize a purpose-built testing environment such as NIST Dioptra to empirically evaluate GAI trustworthy characteristics.",
                "parts": [
                  {
                    "id": "MS-2.3-009_smt",
                    "name": "statement",
                    "prose": "Utilize a purpose-built testing environment such as NIST Dioptra to empirically evaluate GAI trustworthy characteristics."
                  }
                ]
              },
              {
                "id": "MS-2.3-010",
                "title": "Verify that mechanisms to collect users窶 feedback are visible and traceable.",
                "parts": [
                  {
                    "id": "MS-2.3-010_smt",
                    "name": "statement",
                    "prose": "Verify that mechanisms to collect users窶 feedback are visible and traceable."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.5",
            "title": "The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented.",
            "controls": [
              {
                "id": "MS-2.5-001",
                "title": "Apply standard measurement and structured human feedback approaches to internally-developed and third-party GAI systems.",
                "parts": [
                  {
                    "id": "MS-2.5-001_smt",
                    "name": "statement",
                    "prose": "Apply standard measurement and structured human feedback approaches to internally-developed and third-party GAI systems."
                  }
                ]
              },
              {
                "id": "MS-2.5-002",
                "title": "Avoid extrapolating GAI system performance or capabilities from narrow, non-systematic, and anecdotal assessments.",
                "parts": [
                  {
                    "id": "MS-2.5-002_smt",
                    "name": "statement",
                    "prose": "Avoid extrapolating GAI system performance or capabilities from narrow, non-systematic, and anecdotal assessments."
                  }
                ]
              },
              {
                "id": "MS-2.5-003",
                "title": "Conduct security assessments and audits to measure the integrity of training data, system software, and system outputs.",
                "parts": [
                  {
                    "id": "MS-2.5-003_smt",
                    "name": "statement",
                    "prose": "Conduct security assessments and audits to measure the integrity of training data, system software, and system outputs."
                  }
                ]
              },
              {
                "id": "MS-2.5-004",
                "title": "Document the construct validity of methodologies employed in GAI systems relative to their context of use.",
                "parts": [
                  {
                    "id": "MS-2.5-004_smt",
                    "name": "statement",
                    "prose": "Document the construct validity of methodologies employed in GAI systems relative to their context of use."
                  }
                ]
              },
              {
                "id": "MS-2.5-005",
                "title": "Document the extent to which human domain knowledge is employed to improve GAI system performance, via, e.g., RLHF, fine-tuning, content moderation, business rules.",
                "parts": [
                  {
                    "id": "MS-2.5-005_smt",
                    "name": "statement",
                    "prose": "Document the extent to which human domain knowledge is employed to improve GAI system performance, via, e.g., RLHF, fine-tuning, content moderation, business rules."
                  }
                ]
              },
              {
                "id": "MS-2.5-006",
                "title": "Establish metrics or KPIs to determine whether GAI systems meet minimum performance standards for reliability and validity.",
                "parts": [
                  {
                    "id": "MS-2.5-006_smt",
                    "name": "statement",
                    "prose": "Establish metrics or KPIs to determine whether GAI systems meet minimum performance standards for reliability and validity."
                  }
                ]
              },
              {
                "id": "MS-2.5-007",
                "title": "Measure, monitor, and document prevalence of erroneous GAI output content, system availability, and reproducibility of outcomes via field testing or other randomized controlled experiments.",
                "parts": [
                  {
                    "id": "MS-2.5-007_smt",
                    "name": "statement",
                    "prose": "Measure, monitor, and document prevalence of erroneous GAI output content, system availability, and reproducibility of outcomes via field testing or other randomized controlled experiments."
                  }
                ]
              },
              {
                "id": "MS-2.5-008",
                "title": "Review and verify sources and citations in GAI system outputs during pre-deployment risk measurement and ongoing monitoring activities.",
                "parts": [
                  {
                    "id": "MS-2.5-008_smt",
                    "name": "statement",
                    "prose": "Review and verify sources and citations in GAI system outputs during pre-deployment risk measurement and ongoing monitoring activities."
                  }
                ]
              },
              {
                "id": "MS-2.5-009",
                "title": "Track and document instances of anthropomorphization (e.g., human images, mentions of human feelings, cyborg imagery or motifs) in GAI system interfaces.",
                "parts": [
                  {
                    "id": "MS-2.5-009_smt",
                    "name": "statement",
                    "prose": "Track and document instances of anthropomorphization (e.g., human images, mentions of human feelings, cyborg imagery or motifs) in GAI system interfaces."
                  }
                ]
              },
              {
                "id": "MS-2.5-010",
                "title": "Track and document relevant version numbers, planned updates, hotfixes, and other GAI system change management information.",
                "parts": [
                  {
                    "id": "MS-2.5-010_smt",
                    "name": "statement",
                    "prose": "Track and document relevant version numbers, planned updates, hotfixes, and other GAI system change management information."
                  }
                ]
              },
              {
                "id": "MS-2.5-011",
                "title": "Update standard train/test model evaluation processes for GAI systems. Consider: Unwanted or undocumented overlaps in train and TEVV data sources, including their negative spaces (i.e., what is not represented in both); Employ substring matching or embedding distance approaches to assess similarity across data partitions.",
                "parts": [
                  {
                    "id": "MS-2.5-011_smt",
                    "name": "statement",
                    "prose": "Update standard train/test model evaluation processes for GAI systems. Consider: Unwanted or undocumented overlaps in train and TEVV data sources, including their negative spaces (i.e., what is not represented in both); Employ substring matching or embedding distance approaches to assess similarity across data partitions."
                  }
                ]
              },
              {
                "id": "MS-2.5-012",
                "title": "Verify GAI system training data and TEVV data provenance, and that fine-tuning data is grounded.",
                "parts": [
                  {
                    "id": "MS-2.5-012_smt",
                    "name": "statement",
                    "prose": "Verify GAI system training data and TEVV data provenance, and that fine-tuning data is grounded."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.6",
            "title": "The AI system is evaluated regularly for safety risks 窶 as identified in the MAP function. The AI system to be deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits.",
            "controls": [
              {
                "id": "MS-2.6-001",
                "title": "Assess adverse impacts health and wellbeing impacts for supply chain or other AI actors that are exposed to obscene, toxic, or violent information during the course of GAI training and maintenance.",
                "parts": [
                  {
                    "id": "MS-2.6-001_smt",
                    "name": "statement",
                    "prose": "Assess adverse impacts health and wellbeing impacts for supply chain or other AI actors that are exposed to obscene, toxic, or violent information during the course of GAI training and maintenance."
                  }
                ]
              },
              {
                "id": "MS-2.6-002",
                "title": "Assess levels of toxicity, intellectual property infringement, data privacy violations, obscenity, extremism, violence, or CBRN information in system training data.",
                "parts": [
                  {
                    "id": "MS-2.6-002_smt",
                    "name": "statement",
                    "prose": "Assess levels of toxicity, intellectual property infringement, data privacy violations, obscenity, extremism, violence, or CBRN information in system training data."
                  }
                ]
              },
              {
                "id": "MS-2.6-003",
                "title": "Measure and document incident response times, system down times, and system availability: Perform standard measurement and structured human feedback on GAI systems to detect safety and reliability impacts and harms; Apply human subjects research protocols and other applicable safety controls when conducting A/B testing, AI red-teaming, focus groups, or human testbed measurements; Identify and document any applications related to robotics, RPA, and autonomous vehicles; Conduct AI red-teaming exercises to identify harms and impacts related to safety and validity, reliability, privacy, toxicity and other risks; Monitor high-risk GAI systems continually for safety and reliability risks once deployed; Monitor GAI systems to detect drift and anomalies relative to expected performance and training baselines.",
                "parts": [
                  {
                    "id": "MS-2.6-003_smt",
                    "name": "statement",
                    "prose": "Measure and document incident response times, system down times, and system availability: Perform standard measurement and structured human feedback on GAI systems to detect safety and reliability impacts and harms; Apply human subjects research protocols and other applicable safety controls when conducting A/B testing, AI red-teaming, focus groups, or human testbed measurements; Identify and document any applications related to robotics, RPA, and autonomous vehicles; Conduct AI red-teaming exercises to identify harms and impacts related to safety and validity, reliability, privacy, toxicity and other risks; Monitor high-risk GAI systems continually for safety and reliability risks once deployed; Monitor GAI systems to detect drift and anomalies relative to expected performance and training baselines."
                  }
                ]
              },
              {
                "id": "MS-2.6-004",
                "title": "Re-evaluate safety features of fine-tuned models when the risk of harm exceeds organizational risk tolerance.",
                "parts": [
                  {
                    "id": "MS-2.6-004_smt",
                    "name": "statement",
                    "prose": "Re-evaluate safety features of fine-tuned models when the risk of harm exceeds organizational risk tolerance."
                  }
                ]
              },
              {
                "id": "MS-2.6-005",
                "title": "Review GAI system outputs for validity and safety: Review generated code to assess risks that may arise from unreliable downstream decision-making.",
                "parts": [
                  {
                    "id": "MS-2.6-005_smt",
                    "name": "statement",
                    "prose": "Review GAI system outputs for validity and safety: Review generated code to assess risks that may arise from unreliable downstream decision-making."
                  }
                ]
              },
              {
                "id": "MS-2.6-006",
                "title": "Track and document past failed GAI system designs to inform risk measurement for safety and validity risks.",
                "parts": [
                  {
                    "id": "MS-2.6-006_smt",
                    "name": "statement",
                    "prose": "Track and document past failed GAI system designs to inform risk measurement for safety and validity risks."
                  }
                ]
              },
              {
                "id": "MS-2.6-007",
                "title": "Verify capabilities for limiting, pausing, updating, or terminating GAI systems quickly.",
                "parts": [
                  {
                    "id": "MS-2.6-007_smt",
                    "name": "statement",
                    "prose": "Verify capabilities for limiting, pausing, updating, or terminating GAI systems quickly."
                  }
                ]
              },
              {
                "id": "MS-2.6-008",
                "title": "Verify rollover, fallback, or redundancy capabilities for high-risk GAI systems.",
                "parts": [
                  {
                    "id": "MS-2.6-008_smt",
                    "name": "statement",
                    "prose": "Verify rollover, fallback, or redundancy capabilities for high-risk GAI systems."
                  }
                ]
              },
              {
                "id": "MS-2.6-009",
                "title": "Verify that GAI system architecture can monitor outputs and performance, and handle, recover from, and repair errors when security anomalies, threats and impacts are detected.",
                "parts": [
                  {
                    "id": "MS-2.6-009_smt",
                    "name": "statement",
                    "prose": "Verify that GAI system architecture can monitor outputs and performance, and handle, recover from, and repair errors when security anomalies, threats and impacts are detected."
                  }
                ]
              },
              {
                "id": "MS-2.6-010",
                "title": "Verify that systems properly handle queries that may give rise to inappropriate, malicious, or illegal usage, including facilitating manipulation, extortion, targeted impersonation, cyber-attacks, and weapons creation.",
                "parts": [
                  {
                    "id": "MS-2.6-010_smt",
                    "name": "statement",
                    "prose": "Verify that systems properly handle queries that may give rise to inappropriate, malicious, or illegal usage, including facilitating manipulation, extortion, targeted impersonation, cyber-attacks, and weapons creation."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.7",
            "title": "AI system security and resilience 窶 as identified in the MAP function 窶 are evaluated and documented.",
            "controls": [
              {
                "id": "MS-2.7-001",
                "title": "Apply established security measures to assess risks of backdoors, compromised dependencies, data breaches, eavesdropping, man-in-the-middle attacks, reverse engineering, and other baseline security concerns. Audit supply chains to identify risks arising from data poisoning, malware, software and hardware vulnerabilities, third-party personnel, and software.",
                "parts": [
                  {
                    "id": "MS-2.7-001_smt",
                    "name": "statement",
                    "prose": "Apply established security measures to assess risks of backdoors, compromised dependencies, data breaches, eavesdropping, man-in-the-middle attacks, reverse engineering, and other baseline security concerns. Audit supply chains to identify risks arising from data poisoning, malware, software and hardware vulnerabilities, third-party personnel, and software."
                  }
                ]
              },
              {
                "id": "MS-2.7-002",
                "title": "Assess the completeness of documentation related to data provenance, access controls, and incident response procedures. Verify GAI system content provenance documentation aligns with relevant regulations and standards.",
                "parts": [
                  {
                    "id": "MS-2.7-002_smt",
                    "name": "statement",
                    "prose": "Assess the completeness of documentation related to data provenance, access controls, and incident response procedures. Verify GAI system content provenance documentation aligns with relevant regulations and standards."
                  }
                ]
              },
              {
                "id": "MS-2.7-003",
                "title": "Benchmark GAI system security and resilience related to content provenance against industry standards and best practices. Compare GAI system security features and content provenance methods against industry state-of-the-art.",
                "parts": [
                  {
                    "id": "MS-2.7-003_smt",
                    "name": "statement",
                    "prose": "Benchmark GAI system security and resilience related to content provenance against industry standards and best practices. Compare GAI system security features and content provenance methods against industry state-of-the-art."
                  }
                ]
              },
              {
                "id": "MS-2.7-004",
                "title": "Conduct user surveys to gather user satisfaction with the AI-generated content and user perceptions of content authenticity. Analyze user feedback to identify concerns and/or current literacy levels related to content provenance.",
                "parts": [
                  {
                    "id": "MS-2.7-004_smt",
                    "name": "statement",
                    "prose": "Conduct user surveys to gather user satisfaction with the AI-generated content and user perceptions of content authenticity. Analyze user feedback to identify concerns and/or current literacy levels related to content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.7-005",
                "title": "Engage with security experts, developers, and researchers through information-sharing mechanisms to stay updated with the latest advancements in AI security related to content provenance. Contribute findings via information-sharing mechanisms, workshops, or publications.",
                "parts": [
                  {
                    "id": "MS-2.7-005_smt",
                    "name": "statement",
                    "prose": "Engage with security experts, developers, and researchers through information-sharing mechanisms to stay updated with the latest advancements in AI security related to content provenance. Contribute findings via information-sharing mechanisms, workshops, or publications."
                  }
                ]
              },
              {
                "id": "MS-2.7-006",
                "title": "Establish measures and evaluate GAI resiliency as part of pre-deployment testing to ensure GAI will function under adverse conditions and restore full functionality in a trustworthy manner.",
                "parts": [
                  {
                    "id": "MS-2.7-006_smt",
                    "name": "statement",
                    "prose": "Establish measures and evaluate GAI resiliency as part of pre-deployment testing to ensure GAI will function under adverse conditions and restore full functionality in a trustworthy manner."
                  }
                ]
              },
              {
                "id": "MS-2.7-007",
                "title": "Identify metrics that reflect the effectiveness of security measures, such as data provenance, the number of unauthorized access attempts, penetrations, or provenance verification.",
                "parts": [
                  {
                    "id": "MS-2.7-007_smt",
                    "name": "statement",
                    "prose": "Identify metrics that reflect the effectiveness of security measures, such as data provenance, the number of unauthorized access attempts, penetrations, or provenance verification."
                  }
                ]
              },
              {
                "id": "MS-2.7-008",
                "title": "Maintain awareness of emergent GAI security risks and associated countermeasures through community resources, official guidance, or research literature.",
                "parts": [
                  {
                    "id": "MS-2.7-008_smt",
                    "name": "statement",
                    "prose": "Maintain awareness of emergent GAI security risks and associated countermeasures through community resources, official guidance, or research literature."
                  }
                ]
              },
              {
                "id": "MS-2.7-009",
                "title": "Measure reliability of content provenance verification methods, such as watermarking, cryptographic signatures, hashing, blockchain, or other content provenance techniques. Evaluate the rate of false positives and false negatives.",
                "parts": [
                  {
                    "id": "MS-2.7-009_smt",
                    "name": "statement",
                    "prose": "Measure reliability of content provenance verification methods, such as watermarking, cryptographic signatures, hashing, blockchain, or other content provenance techniques. Evaluate the rate of false positives and false negatives."
                  }
                ]
              },
              {
                "id": "MS-2.7-010",
                "title": "Measure the average response time to security incidents related to content provenance and the proportion of incidents resolved with and without significant impact.",
                "parts": [
                  {
                    "id": "MS-2.7-010_smt",
                    "name": "statement",
                    "prose": "Measure the average response time to security incidents related to content provenance and the proportion of incidents resolved with and without significant impact."
                  }
                ]
              },
              {
                "id": "MS-2.7-011",
                "title": "Measure the rate at which recommendations from security audits and incidents are implemented related to content provenance.",
                "parts": [
                  {
                    "id": "MS-2.7-011_smt",
                    "name": "statement",
                    "prose": "Measure the rate at which recommendations from security audits and incidents are implemented related to content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.7-012",
                "title": "Monitor and review the completeness and validity of security documentation and verify it aligns with the current state of the GAI system and its content provenance.",
                "parts": [
                  {
                    "id": "MS-2.7-012_smt",
                    "name": "statement",
                    "prose": "Monitor and review the completeness and validity of security documentation and verify it aligns with the current state of the GAI system and its content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.7-013",
                "title": "Monitor GAI system downtime and measure its impact on operations.",
                "parts": [
                  {
                    "id": "MS-2.7-013_smt",
                    "name": "statement",
                    "prose": "Monitor GAI system downtime and measure its impact on operations."
                  }
                ]
              },
              {
                "id": "MS-2.7-014",
                "title": "Monitor GAI systems in deployment for anomalous use and security risks.",
                "parts": [
                  {
                    "id": "MS-2.7-014_smt",
                    "name": "statement",
                    "prose": "Monitor GAI systems in deployment for anomalous use and security risks."
                  }
                ]
              },
              {
                "id": "MS-2.7-015",
                "title": "Monitor the number of security-related incident reports from users, indicating their awareness and willingness to report issues.",
                "parts": [
                  {
                    "id": "MS-2.7-015_smt",
                    "name": "statement",
                    "prose": "Monitor the number of security-related incident reports from users, indicating their awareness and willingness to report issues."
                  }
                ]
              },
              {
                "id": "MS-2.7-016",
                "title": "Perform AI red-teaming to assess resilience against malicious behavior, including malicious code generation, prompt injection, adversarial examples, data poisoning, and model extraction.",
                "parts": [
                  {
                    "id": "MS-2.7-016_smt",
                    "name": "statement",
                    "prose": "Perform AI red-teaming to assess resilience against malicious behavior, including malicious code generation, prompt injection, adversarial examples, data poisoning, and model extraction."
                  }
                ]
              },
              {
                "id": "MS-2.7-017",
                "title": "Review deployment approval processes and verify that processes address relevant GAI security risks.",
                "parts": [
                  {
                    "id": "MS-2.7-017_smt",
                    "name": "statement",
                    "prose": "Review deployment approval processes and verify that processes address relevant GAI security risks."
                  }
                ]
              },
              {
                "id": "MS-2.7-018",
                "title": "Review incident response procedures and verify adequate functionality to identify, contain, eliminate, and recover from complex GAI system incidents.",
                "parts": [
                  {
                    "id": "MS-2.7-018_smt",
                    "name": "statement",
                    "prose": "Review incident response procedures and verify adequate functionality to identify, contain, eliminate, and recover from complex GAI system incidents."
                  }
                ]
              },
              {
                "id": "MS-2.7-019",
                "title": "Track and document access and updates to GAI system training data; verify appropriate security measures for training data at GAI vendors and service providers.",
                "parts": [
                  {
                    "id": "MS-2.7-019_smt",
                    "name": "statement",
                    "prose": "Track and document access and updates to GAI system training data; verify appropriate security measures for training data at GAI vendors and service providers."
                  }
                ]
              },
              {
                "id": "MS-2.7-020",
                "title": "Track GAI system performance metrics such as response time and throughput under different loads and usage patterns related to content provenance.",
                "parts": [
                  {
                    "id": "MS-2.7-020_smt",
                    "name": "statement",
                    "prose": "Track GAI system performance metrics such as response time and throughput under different loads and usage patterns related to content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.7-021",
                "title": "Track the number of users who have completed security training programs regarding the security of content provenance.",
                "parts": [
                  {
                    "id": "MS-2.7-021_smt",
                    "name": "statement",
                    "prose": "Track the number of users who have completed security training programs regarding the security of content provenance."
                  }
                ]
              },
              {
                "id": "MS-2.7-022",
                "title": "Verify fine-tuning does not compromise safety and security controls.",
                "parts": [
                  {
                    "id": "MS-2.7-022_smt",
                    "name": "statement",
                    "prose": "Verify fine-tuning does not compromise safety and security controls."
                  }
                ]
              },
              {
                "id": "MS-2.7-023",
                "title": "Verify organizational policies, procedures, and processes for treatment of GAI security and resiliency risks.",
                "parts": [
                  {
                    "id": "MS-2.7-023_smt",
                    "name": "statement",
                    "prose": "Verify organizational policies, procedures, and processes for treatment of GAI security and resiliency risks."
                  }
                ]
              },
              {
                "id": "MS-2.7-024",
                "title": "Verify vendor documentation for data and software security controls.",
                "parts": [
                  {
                    "id": "MS-2.7-024_smt",
                    "name": "statement",
                    "prose": "Verify vendor documentation for data and software security controls."
                  }
                ]
              },
              {
                "id": "MS-2.7-025",
                "title": "Work with domain experts to capture stakeholder confidence in GAI system security and perceived effectiveness related to content provenance.",
                "parts": [
                  {
                    "id": "MS-2.7-025_smt",
                    "name": "statement",
                    "prose": "Work with domain experts to capture stakeholder confidence in GAI system security and perceived effectiveness related to content provenance."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.8",
            "title": "The performance of the AI system is validated and demonstrated under known and anticipated conditions for the intended use and environment of deployment.",
            "controls": [
              {
                "id": "MS-2.8-001",
                "title": "Assess the AI system窶冱 expected performance under typical and edge case conditions to ensure consistent output quality and behavior.",
                "parts": [
                  {
                    "id": "MS-2.8-001_smt",
                    "name": "statement",
                    "prose": "Assess the AI system窶冱 expected performance under typical and edge case conditions to ensure consistent output quality and behavior."
                  }
                ]
              },
              {
                "id": "MS-2.8-002",
                "title": "Audit the system outputs to verify that the generated data meets intended accuracy and integrity levels across different deployment scenarios.",
                "parts": [
                  {
                    "id": "MS-2.8-002_smt",
                    "name": "statement",
                    "prose": "Audit the system outputs to verify that the generated data meets intended accuracy and integrity levels across different deployment scenarios."
                  }
                ]
              },
              {
                "id": "MS-2.8-003",
                "title": "Conduct simulation tests under extreme operating conditions to evaluate AI performance and failure modes, and document the results.",
                "parts": [
                  {
                    "id": "MS-2.8-003_smt",
                    "name": "statement",
                    "prose": "Conduct simulation tests under extreme operating conditions to evaluate AI performance and failure modes, and document the results."
                  }
                ]
              },
              {
                "id": "MS-2.8-004",
                "title": "Evaluate AI system robustness by measuring resilience in case of data corruption, noise, or incomplete inputs.",
                "parts": [
                  {
                    "id": "MS-2.8-004_smt",
                    "name": "statement",
                    "prose": "Evaluate AI system robustness by measuring resilience in case of data corruption, noise, or incomplete inputs."
                  }
                ]
              },
              {
                "id": "MS-2.8-005",
                "title": "Implement continuous field testing of deployed systems to ensure their performance matches the conditions identified during validation.",
                "parts": [
                  {
                    "id": "MS-2.8-005_smt",
                    "name": "statement",
                    "prose": "Implement continuous field testing of deployed systems to ensure their performance matches the conditions identified during validation."
                  }
                ]
              },
              {
                "id": "MS-2.8-006",
                "title": "Perform A/B testing to identify potential performance degradations or inconsistencies across different environments.",
                "parts": [
                  {
                    "id": "MS-2.8-006_smt",
                    "name": "statement",
                    "prose": "Perform A/B testing to identify potential performance degradations or inconsistencies across different environments."
                  }
                ]
              },
              {
                "id": "MS-2.8-007",
                "title": "Regularly test the AI system窶冱 decision-making capabilities and validate them against business logic or rules.",
                "parts": [
                  {
                    "id": "MS-2.8-007_smt",
                    "name": "statement",
                    "prose": "Regularly test the AI system窶冱 decision-making capabilities and validate them against business logic or rules."
                  }
                ]
              },
              {
                "id": "MS-2.8-008",
                "title": "Regularly validate the AI system outputs with domain experts to ensure correctness and applicability across varying conditions.",
                "parts": [
                  {
                    "id": "MS-2.8-008_smt",
                    "name": "statement",
                    "prose": "Regularly validate the AI system outputs with domain experts to ensure correctness and applicability across varying conditions."
                  }
                ]
              },
              {
                "id": "MS-2.8-009",
                "title": "Track and document AI system outputs under conditions of user fatigue, pressure, or other human factor influences.",
                "parts": [
                  {
                    "id": "MS-2.8-009_smt",
                    "name": "statement",
                    "prose": "Track and document AI system outputs under conditions of user fatigue, pressure, or other human factor influences."
                  }
                ]
              },
              {
                "id": "MS-2.8-010",
                "title": "Verify performance of the AI system when fine-tuned for specific use cases and environments.",
                "parts": [
                  {
                    "id": "MS-2.8-010_smt",
                    "name": "statement",
                    "prose": "Verify performance of the AI system when fine-tuned for specific use cases and environments."
                  }
                ]
              },
              {
                "id": "MS-2.8-011",
                "title": "Verify that AI system hardware is aligned to anticipated operating conditions and test for power constraints, environmental factors, etc.",
                "parts": [
                  {
                    "id": "MS-2.8-011_smt",
                    "name": "statement",
                    "prose": "Verify that AI system hardware is aligned to anticipated operating conditions and test for power constraints, environmental factors, etc."
                  }
                ]
              },
              {
                "id": "MS-2.8-012",
                "title": "Verify the system窶冱 ability to maintain performance with varying levels of user input quality (e.g., incomplete, erroneous, or ambiguous inputs).",
                "parts": [
                  {
                    "id": "MS-2.8-012_smt",
                    "name": "statement",
                    "prose": "Verify the system窶冱 ability to maintain performance with varying levels of user input quality (e.g., incomplete, erroneous, or ambiguous inputs)."
                  }
                ]
              },
              {
                "id": "MS-2.8-013",
                "title": "Verify the use of safe handling mechanisms for inputs that trigger failure scenarios.",
                "parts": [
                  {
                    "id": "MS-2.8-013_smt",
                    "name": "statement",
                    "prose": "Verify the use of safe handling mechanisms for inputs that trigger failure scenarios."
                  }
                ]
              },
              {
                "id": "MS-2.8-014",
                "title": "Work with domain experts to define the acceptable conditions for AI system validation across anticipated operating environments.",
                "parts": [
                  {
                    "id": "MS-2.8-014_smt",
                    "name": "statement",
                    "prose": "Work with domain experts to define the acceptable conditions for AI system validation across anticipated operating environments."
                  }
                ]
              },
              {
                "id": "MS-2.8-015",
                "title": "Work with developers to ensure that fallback or fail-safe mechanisms are in place to handle extreme operating conditions.",
                "parts": [
                  {
                    "id": "MS-2.8-015_smt",
                    "name": "statement",
                    "prose": "Work with developers to ensure that fallback or fail-safe mechanisms are in place to handle extreme operating conditions."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-2.9",
            "title": "The AI system to be deployed is demonstrated to operate as intended over time.",
            "controls": [
              {
                "id": "MS-2.9-001",
                "title": "Evaluate the AI system periodically during deployment to ensure performance remains aligned with the validation criteria over time.",
                "parts": [
                  {
                    "id": "MS-2.9-001_smt",
                    "name": "statement",
                    "prose": "Evaluate the AI system periodically during deployment to ensure performance remains aligned with the validation criteria over time."
                  }
                ]
              },
              {
                "id": "MS-2.9-002",
                "title": "Establish mechanisms to detect and address performance drift in AI system outputs after prolonged usage.",
                "parts": [
                  {
                    "id": "MS-2.9-002_smt",
                    "name": "statement",
                    "prose": "Establish mechanisms to detect and address performance drift in AI system outputs after prolonged usage."
                  }
                ]
              },
              {
                "id": "MS-2.9-003",
                "title": "Monitor and document updates and changes to AI systems over time, ensuring that version control is maintained and risks assessed.",
                "parts": [
                  {
                    "id": "MS-2.9-003_smt",
                    "name": "statement",
                    "prose": "Monitor and document updates and changes to AI systems over time, ensuring that version control is maintained and risks assessed."
                  }
                ]
              },
              {
                "id": "MS-2.9-004",
                "title": "Track GAI system performance to identify when models need retraining to address long-term risks or improvements.",
                "parts": [
                  {
                    "id": "MS-2.9-004_smt",
                    "name": "statement",
                    "prose": "Track GAI system performance to identify when models need retraining to address long-term risks or improvements."
                  }
                ]
              },
              {
                "id": "MS-2.9-005",
                "title": "Verify that AI system outputs and performance are stable during different time frames (e.g., hours, days, weeks) and under varying operational loads.",
                "parts": [
                  {
                    "id": "MS-2.9-005_smt",
                    "name": "statement",
                    "prose": "Verify that AI system outputs and performance are stable during different time frames (e.g., hours, days, weeks) and under varying operational loads."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-3.1",
            "title": "Approaches, personnel, and documentation are in place to regularly identify and track existing, unanticipated, and emergent AI risks based on factors such as intended and actual performance in deployed contexts.",
            "controls": [
              {
                "id": "MS-3.1-001",
                "title": "Assess completeness of known use cases and expected performance of inputs, such as third-party data or upstream AI systems, or the performance of downstream systems which use the outputs of the GAI system, directly or indirectly, through engagement and outreach with AI Actors.",
                "parts": [
                  {
                    "id": "MS-3.1-001_smt",
                    "name": "statement",
                    "prose": "Assess completeness of known use cases and expected performance of inputs, such as third-party data or upstream AI systems, or the performance of downstream systems which use the outputs of the GAI system, directly or indirectly, through engagement and outreach with AI Actors."
                  }
                ]
              },
              {
                "id": "MS-3.1-002",
                "title": "Compare intended use and expected performance of GAI systems across all relevant contexts.",
                "parts": [
                  {
                    "id": "MS-3.1-002_smt",
                    "name": "statement",
                    "prose": "Compare intended use and expected performance of GAI systems across all relevant contexts."
                  }
                ]
              },
              {
                "id": "MS-3.1-003",
                "title": "Elicit and track feedback for previously unknown uses of the GAI systems.",
                "parts": [
                  {
                    "id": "MS-3.1-003_smt",
                    "name": "statement",
                    "prose": "Elicit and track feedback for previously unknown uses of the GAI systems."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-3.2",
            "title": "Risk tracking approaches are considered for settings where AI risks are difficult to assess using currently available measurement techniques or where metrics are not yet available.",
            "controls": [
              {
                "id": "MS-3.2-001",
                "title": "Determine if available GAI system risk measurement approaches are applicable to the GAI system use contexts.",
                "parts": [
                  {
                    "id": "MS-3.2-001_smt",
                    "name": "statement",
                    "prose": "Determine if available GAI system risk measurement approaches are applicable to the GAI system use contexts."
                  }
                ]
              },
              {
                "id": "MS-3.2-002",
                "title": "Document the rate of occurrence and severity of GAI harms to the organization and to external AI actors.",
                "parts": [
                  {
                    "id": "MS-3.2-002_smt",
                    "name": "statement",
                    "prose": "Document the rate of occurrence and severity of GAI harms to the organization and to external AI actors."
                  }
                ]
              },
              {
                "id": "MS-3.2-003",
                "title": "Establish processes for identifying emergent GAI system risks with external AI actors.",
                "parts": [
                  {
                    "id": "MS-3.2-003_smt",
                    "name": "statement",
                    "prose": "Establish processes for identifying emergent GAI system risks with external AI actors."
                  }
                ]
              },
              {
                "id": "MS-3.2-004",
                "title": "Identify measurement approaches for tracking GAI system risks if none exist.",
                "parts": [
                  {
                    "id": "MS-3.2-004_smt",
                    "name": "statement",
                    "prose": "Identify measurement approaches for tracking GAI system risks if none exist."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-3.3",
            "title": "Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics.",
            "controls": [
              {
                "id": "MS-3.3-001",
                "title": "Conduct impact assessments on how AI-generated content might affect different social, economic, and cultural groups.",
                "parts": [
                  {
                    "id": "MS-3.3-001_smt",
                    "name": "statement",
                    "prose": "Conduct impact assessments on how AI-generated content might affect different social, economic, and cultural groups."
                  }
                ]
              },
              {
                "id": "MS-3.3-002",
                "title": "Conduct studies to understand how end users perceive and interact with GAI content related to content provenance within context of use. Assess whether the content aligns with their expectations and how they may act upon the information presented.",
                "parts": [
                  {
                    "id": "MS-3.3-002_smt",
                    "name": "statement",
                    "prose": "Conduct studies to understand how end users perceive and interact with GAI content related to content provenance within context of use. Assess whether the content aligns with their expectations and how they may act upon the information presented."
                  }
                ]
              },
              {
                "id": "MS-3.3-003",
                "title": "Design evaluation metrics that include parameters for content provenance quality, validity, reliability, authenticity or origin, and integrity of content.",
                "parts": [
                  {
                    "id": "MS-3.3-003_smt",
                    "name": "statement",
                    "prose": "Design evaluation metrics that include parameters for content provenance quality, validity, reliability, authenticity or origin, and integrity of content."
                  }
                ]
              },
              {
                "id": "MS-3.3-004",
                "title": "Evaluate GAI system evaluation metrics based on feedback from relevant AI actors.",
                "parts": [
                  {
                    "id": "MS-3.3-004_smt",
                    "name": "statement",
                    "prose": "Evaluate GAI system evaluation metrics based on feedback from relevant AI actors."
                  }
                ]
              },
              {
                "id": "MS-3.3-005",
                "title": "Evaluate potential biases and stereotypes that could emerge from the AI-generated content using appropriate methodologies including computational testing methods as well as evaluating structured feedback input.",
                "parts": [
                  {
                    "id": "MS-3.3-005_smt",
                    "name": "statement",
                    "prose": "Evaluate potential biases and stereotypes that could emerge from the AI-generated content using appropriate methodologies including computational testing methods as well as evaluating structured feedback input."
                  }
                ]
              },
              {
                "id": "MS-3.3-006",
                "title": "Implement continuous monitoring of AI-generated content and provenance after system deployment for various types of drift. Verify GAI systems are adaptive and able to iteratively improve models and algorithms over time.",
                "parts": [
                  {
                    "id": "MS-3.3-006_smt",
                    "name": "statement",
                    "prose": "Implement continuous monitoring of AI-generated content and provenance after system deployment for various types of drift. Verify GAI systems are adaptive and able to iteratively improve models and algorithms over time."
                  }
                ]
              },
              {
                "id": "MS-3.3-007",
                "title": "Integrate human evaluators to assess content quality and relevance.",
                "parts": [
                  {
                    "id": "MS-3.3-007_smt",
                    "name": "statement",
                    "prose": "Integrate human evaluators to assess content quality and relevance."
                  }
                ]
              },
              {
                "id": "MS-3.3-008",
                "title": "Provide input for training materials about the capabilities and limitations of GAI systems related to content provenance for AI actors, other professionals, and the public about the societal impacts of AI and the role of diverse and inclusive content generation.",
                "parts": [
                  {
                    "id": "MS-3.3-008_smt",
                    "name": "statement",
                    "prose": "Provide input for training materials about the capabilities and limitations of GAI systems related to content provenance for AI actors, other professionals, and the public about the societal impacts of AI and the role of diverse and inclusive content generation."
                  }
                ]
              },
              {
                "id": "MS-3.3-009",
                "title": "Record and integrate structured feedback about content provenance from operators, users, and potentially impacted communities through the use of methods such as user research studies, focus groups, or community forums. Actively seek feedback on generated content quality and potential biases.",
                "parts": [
                  {
                    "id": "MS-3.3-009_smt",
                    "name": "statement",
                    "prose": "Record and integrate structured feedback about content provenance from operators, users, and potentially impacted communities through the use of methods such as user research studies, focus groups, or community forums. Actively seek feedback on generated content quality and potential biases."
                  }
                ]
              },
              {
                "id": "MS-3.3-010",
                "title": "Regularly review structured human feedback and GAI system sensors and update based on the evolving needs and concerns of the impacted communities.",
                "parts": [
                  {
                    "id": "MS-3.3-010_smt",
                    "name": "statement",
                    "prose": "Regularly review structured human feedback and GAI system sensors and update based on the evolving needs and concerns of the impacted communities."
                  }
                ]
              },
              {
                "id": "MS-3.3-011",
                "title": "Utilize independent evaluations to assess content quality and types of potential biases and related negative impacts.",
                "parts": [
                  {
                    "id": "MS-3.3-011_smt",
                    "name": "statement",
                    "prose": "Utilize independent evaluations to assess content quality and types of potential biases and related negative impacts."
                  }
                ]
              },
              {
                "id": "MS-3.3-012",
                "title": "Verify effectiveness of content moderation strategies over time by monitoring content for bias and ensuring fairness in diverse contexts.",
                "parts": [
                  {
                    "id": "MS-3.3-012_smt",
                    "name": "statement",
                    "prose": "Verify effectiveness of content moderation strategies over time by monitoring content for bias and ensuring fairness in diverse contexts."
                  }
                ]
              }
            ]
          },
          {
            "id": "MS-4.2",
            "title": "Appropriate mechanisms are implemented to prevent, detect, and respond to AI risks during operations.",
            "controls": [
              {
                "id": "MS-4.2-001",
                "title": "Implement AI-specific monitoring to detect potential harms related to AI usage.",
                "parts": [
                  {
                    "id": "MS-4.2-001_smt",
                    "name": "statement",
                    "prose": "Implement AI-specific monitoring to detect potential harms related to AI usage."
                  }
                ]
              },
              {
                "id": "MS-4.2-002",
                "title": "Establish procedures to respond to identified risks or incidents related to AI systems.",
                "parts": [
                  {
                    "id": "MS-4.2-002_smt",
                    "name": "statement",
                    "prose": "Establish procedures to respond to identified risks or incidents related to AI systems."
                  }
                ]
              },
              {
                "id": "MS-4.2-003",
                "title": "Regularly test AI systems for compliance with privacy regulations and cybersecurity standards.",
                "parts": [
                  {
                    "id": "MS-4.2-003_smt",
                    "name": "statement",
                    "prose": "Regularly test AI systems for compliance with privacy regulations and cybersecurity standards."
                  }
                ]
              },
              {
                "id": "MS-4.2-004",
                "title": "Verify that AI-generated decisions are accurate and fair across different demographic groups.",
                "parts": [
                  {
                    "id": "MS-4.2-004_smt",
                    "name": "statement",
                    "prose": "Verify that AI-generated decisions are accurate and fair across different demographic groups."
                  }
                ]
              },
              {
                "id": "MS-4.2-005",
                "title": "Conduct security audits to ensure that AI systems are resistant to data breaches and attacks.",
                "parts": [
                  {
                    "id": "MS-4.2-005_smt",
                    "name": "statement",
                    "prose": "Conduct security audits to ensure that AI systems are resistant to data breaches and attacks."
                  }
                ]
              },
              {
                "id": "MS-4.2-006",
                "title": "Deploy logging and monitoring tools to continuously track AI system performance and flag abnormal behavior.",
                "parts": [
                  {
                    "id": "MS-4.2-006_smt",
                    "name": "statement",
                    "prose": "Deploy logging and monitoring tools to continuously track AI system performance and flag abnormal behavior."
                  }
                ]
              },
              {
                "id": "MS-4.2-007",
                "title": "Implement processes to handle user complaints and appeals related to AI system outcomes.",
                "parts": [
                  {
                    "id": "MS-4.2-007_smt",
                    "name": "statement",
                    "prose": "Implement processes to handle user complaints and appeals related to AI system outcomes."
                  }
                ]
              },
              {
                "id": "MS-4.2-008",
                "title": "Provide users with transparency into AI decision-making processes and system rationale.",
                "parts": [
                  {
                    "id": "MS-4.2-008_smt",
                    "name": "statement",
                    "prose": "Provide users with transparency into AI decision-making processes and system rationale."
                  }
                ]
              },
              {
                "id": "MS-4.2-009",
                "title": "Verify that AI decisions comply with organizational policies and applicable laws, including data privacy regulations.",
                "parts": [
                  {
                    "id": "MS-4.2-009_smt",
                    "name": "statement",
                    "prose": "Verify that AI decisions comply with organizational policies and applicable laws, including data privacy regulations."
                  }
                ]
              },
              {
                "id": "MS-4.2-010",
                "title": "Continuously update and refine AI system documentation to reflect new operational realities and risks.",
                "parts": [
                  {
                    "id": "MS-4.2-010_smt",
                    "name": "statement",
                    "prose": "Continuously update and refine AI system documentation to reflect new operational realities and risks."
                  }
                ]
              },
              {
                "id": "MS-4.2-011",
                "title": "Track and mitigate risks of unintended consequences from AI systems operating in new contexts or being repurposed for different tasks.",
                "parts": [
                  {
                    "id": "MS-4.2-011_smt",
                    "name": "statement",
                    "prose": "Track and mitigate risks of unintended consequences from AI systems operating in new contexts or being repurposed for different tasks."
                  }
                ]
              },
              {
                "id": "MS-4.2-012",
                "title": "Integrate feedback mechanisms from affected communities into the AI risk management process.",
                "parts": [
                  {
                    "id": "MS-4.2-012_smt",
                    "name": "statement",
                    "prose": "Integrate feedback mechanisms from affected communities into the AI risk management process."
                  }
                ]
              },
              {
                "id": "MS-4.2-013",
                "title": "Verify that AI systems can be safely shut down or paused in case of emergency or failure.",
                "parts": [
                  {
                    "id": "MS-4.2-013_smt",
                    "name": "statement",
                    "prose": "Verify that AI systems can be safely shut down or paused in case of emergency or failure."
                  }
                ]
              },
              {
                "id": "MS-4.2-014",
                "title": "Verify that AI systems maintain data integrity and confidentiality in accordance with industry best practices.",
                "parts": [
                  {
                    "id": "MS-4.2-014_smt",
                    "name": "statement",
                    "prose": "Verify that AI systems maintain data integrity and confidentiality in accordance with industry best practices."
                  }
                ]
              },
              {
                "id": "MS-4.2-015",
                "title": "Ensure that risk management strategies evolve as AI systems and their deployment contexts change.",
                "parts": [
                  {
                    "id": "MS-4.2-015_smt",
                    "name": "statement",
                    "prose": "Ensure that risk management strategies evolve as AI systems and their deployment contexts change."
                  }
                ]
              }
            ]
          }
        ]
      }
    ]
  }
}